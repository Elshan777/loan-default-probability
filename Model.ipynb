{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neural-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wrong-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outstanding-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['credit_line_utilization'] = df['credit_line_utilization'].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cosmetic-thesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'number_dependent_family_members', 'monthly_income',\n",
       "       'number_of_credit_lines', 'real_estate_loans',\n",
       "       'ratio_debt_payment_to_income', 'credit_line_utilization',\n",
       "       'number_of_previous_late_payments_up_to_59_days',\n",
       "       'number_of_previous_late_payments_up_to_89_days',\n",
       "       'number_of_previous_late_payments_90_days_or_more'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.iloc[:, 1:-1].columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceramic-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[columns], df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-investment",
   "metadata": {},
   "source": [
    "### Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amber-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp_mean = IterativeImputer(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "typical-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>number_dependent_family_members</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>number_of_credit_lines</th>\n",
       "      <th>real_estate_loans</th>\n",
       "      <th>ratio_debt_payment_to_income</th>\n",
       "      <th>credit_line_utilization</th>\n",
       "      <th>number_of_previous_late_payments_up_to_59_days</th>\n",
       "      <th>number_of_previous_late_payments_up_to_89_days</th>\n",
       "      <th>number_of_previous_late_payments_90_days_or_more</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.531495</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>9.435243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569108</td>\n",
       "      <td>0.054888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297176</td>\n",
       "      <td>0.101950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160145</td>\n",
       "      <td>1.227135</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10218.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067913</td>\n",
       "      <td>0.083278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4468.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328261</td>\n",
       "      <td>0.317446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  number_dependent_family_members  monthly_income  \\\n",
       "0  66.0                         0.531495          4000.0   \n",
       "1  61.0                         2.000000          4000.0   \n",
       "2  31.0                         2.000000          3040.0   \n",
       "3  54.0                         4.000000         10218.0   \n",
       "4  29.0                         0.000000          4468.0   \n",
       "\n",
       "   number_of_credit_lines  real_estate_loans  ratio_debt_payment_to_income  \\\n",
       "0                9.435243                1.0                      0.569108   \n",
       "1                6.000000                1.0                      0.297176   \n",
       "2                8.000000                0.0                      0.160145   \n",
       "3                5.000000                0.0                      0.067913   \n",
       "4                6.000000                0.0                      0.328261   \n",
       "\n",
       "   credit_line_utilization  number_of_previous_late_payments_up_to_59_days  \\\n",
       "0                 0.054888                                             0.0   \n",
       "1                 0.101950                                             0.0   \n",
       "2                 1.227135                                             4.0   \n",
       "3                 0.083278                                             0.0   \n",
       "4                 0.317446                                             0.0   \n",
       "\n",
       "   number_of_previous_late_payments_up_to_89_days  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   number_of_previous_late_payments_90_days_or_more  \n",
       "0                                               0.0  \n",
       "1                                               0.0  \n",
       "2                                               0.0  \n",
       "3                                               0.0  \n",
       "4                                               0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_mean = IterativeImputer(random_state=0)\n",
    "X_imputed = imp_mean.fit_transform(X)\n",
    "X_imputed = pd.DataFrame(X_imputed)\n",
    "X_imputed.columns = columns\n",
    "X_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-scale",
   "metadata": {},
   "source": [
    "### Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sixth-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "united-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = OneClassSVM(nu=.01)\n",
    "yhat = ee.fit_predict(X_imputed)\n",
    "mask = yhat != -1\n",
    "X_out, y_out = X_imputed[mask], y[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-holder",
   "metadata": {},
   "source": [
    "#### X_new and y_new are imputed and outlier free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "according-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, y_new = X_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-sheffield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-acrobat",
   "metadata": {},
   "source": [
    "Balance the dataset by undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "logical-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate imputed and \n",
    "data_new = pd.concat([X_new, y_new], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "swiss-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| number_of_1s: 4974\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>number_dependent_family_members</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>number_of_credit_lines</th>\n",
       "      <th>real_estate_loans</th>\n",
       "      <th>ratio_debt_payment_to_income</th>\n",
       "      <th>credit_line_utilization</th>\n",
       "      <th>number_of_previous_late_payments_up_to_59_days</th>\n",
       "      <th>number_of_previous_late_payments_up_to_89_days</th>\n",
       "      <th>number_of_previous_late_payments_90_days_or_more</th>\n",
       "      <th>defaulted_on_loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3040.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160145</td>\n",
       "      <td>1.227135</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10800.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.590316</td>\n",
       "      <td>0.975767</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>42.168606</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6448.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190107</td>\n",
       "      <td>0.865913</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4938.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3772.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.207312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72070</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.246024</td>\n",
       "      <td>3418.846084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72086</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10614.829761</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.485349</td>\n",
       "      <td>0.073525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72120</th>\n",
       "      <td>51.877978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.552579</td>\n",
       "      <td>0.465445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72129</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>945.000000</td>\n",
       "      <td>7.814023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707188</td>\n",
       "      <td>3.990244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72138</th>\n",
       "      <td>50.994057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044296</td>\n",
       "      <td>0.240083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4974 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  number_dependent_family_members  monthly_income  \\\n",
       "2      31.000000                         2.000000     3040.000000   \n",
       "20     48.000000                         1.000000    10800.000000   \n",
       "30     42.168606                         4.000000     6448.000000   \n",
       "44     45.000000                         0.000000     4938.000000   \n",
       "65     44.000000                         3.000000     3772.000000   \n",
       "...          ...                              ...             ...   \n",
       "72070  24.000000                         1.246024     3418.846084   \n",
       "72086  45.000000                         1.000000    10614.829761   \n",
       "72120  51.877978                         0.000000     2500.000000   \n",
       "72129  62.000000                         0.000000      945.000000   \n",
       "72138  50.994057                         0.000000    10000.000000   \n",
       "\n",
       "       number_of_credit_lines  real_estate_loans  \\\n",
       "2                    8.000000                0.0   \n",
       "20                  11.000000                3.0   \n",
       "30                  11.000000                0.0   \n",
       "44                   1.000000                0.0   \n",
       "65                   8.000000                1.0   \n",
       "...                       ...                ...   \n",
       "72070                0.000000                0.0   \n",
       "72086                8.000000                4.0   \n",
       "72120                4.000000                0.0   \n",
       "72129                7.814023                0.0   \n",
       "72138                3.000000                0.0   \n",
       "\n",
       "       ratio_debt_payment_to_income  credit_line_utilization  \\\n",
       "2                          0.160145                 1.227135   \n",
       "20                         0.590316                 0.975767   \n",
       "30                         0.190107                 0.865913   \n",
       "44                         0.068840                 1.000000   \n",
       "65                         0.537503                 0.207312   \n",
       "...                             ...                      ...   \n",
       "72070                      0.013540                 1.000000   \n",
       "72086                      0.485349                 0.073525   \n",
       "72120                      0.552579                 0.465445   \n",
       "72129                      0.707188                 3.990244   \n",
       "72138                      0.044296                 0.240083   \n",
       "\n",
       "       number_of_previous_late_payments_up_to_59_days  \\\n",
       "2                                                 4.0   \n",
       "20                                                3.0   \n",
       "30                                                3.0   \n",
       "44                                                0.0   \n",
       "65                                                0.0   \n",
       "...                                               ...   \n",
       "72070                                             1.0   \n",
       "72086                                             0.0   \n",
       "72120                                             0.0   \n",
       "72129                                             1.0   \n",
       "72138                                             0.0   \n",
       "\n",
       "       number_of_previous_late_payments_up_to_89_days  \\\n",
       "2                                                 0.0   \n",
       "20                                                0.0   \n",
       "30                                                1.0   \n",
       "44                                                1.0   \n",
       "65                                                0.0   \n",
       "...                                               ...   \n",
       "72070                                             0.0   \n",
       "72086                                             0.0   \n",
       "72120                                             1.0   \n",
       "72129                                             0.0   \n",
       "72138                                             0.0   \n",
       "\n",
       "       number_of_previous_late_payments_90_days_or_more  defaulted_on_loan  \n",
       "2                                                   0.0                  1  \n",
       "20                                                  0.0                  1  \n",
       "30                                                  0.0                  1  \n",
       "44                                                  2.0                  1  \n",
       "65                                                  0.0                  1  \n",
       "...                                                 ...                ...  \n",
       "72070                                               3.0                  1  \n",
       "72086                                               0.0                  1  \n",
       "72120                                               1.0                  1  \n",
       "72129                                               0.0                  1  \n",
       "72138                                               0.0                  1  \n",
       "\n",
       "[4974 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_1s = len(data_new[data_new['defaulted_on_loan'] == 1])\n",
    "ic(number_of_1s)\n",
    "ones = data_new[data_new['defaulted_on_loan'] == 1]\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spare-armor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>number_dependent_family_members</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>number_of_credit_lines</th>\n",
       "      <th>real_estate_loans</th>\n",
       "      <th>ratio_debt_payment_to_income</th>\n",
       "      <th>credit_line_utilization</th>\n",
       "      <th>number_of_previous_late_payments_up_to_59_days</th>\n",
       "      <th>number_of_previous_late_payments_up_to_89_days</th>\n",
       "      <th>number_of_previous_late_payments_90_days_or_more</th>\n",
       "      <th>defaulted_on_loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3040.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160145</td>\n",
       "      <td>1.227135</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10800.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.590316</td>\n",
       "      <td>0.975767</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>42.168606</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6448.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190107</td>\n",
       "      <td>0.865913</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4938.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3772.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.207312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9350.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.380957</td>\n",
       "      <td>0.378989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46753</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6388.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166223</td>\n",
       "      <td>0.087128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12434</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1320.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.294474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45337</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203159</td>\n",
       "      <td>0.562887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34491</th>\n",
       "      <td>56.508684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6535.257745</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.256532</td>\n",
       "      <td>0.875891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9948 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  number_dependent_family_members  monthly_income  \\\n",
       "2      31.000000                              2.0     3040.000000   \n",
       "20     48.000000                              1.0    10800.000000   \n",
       "30     42.168606                              4.0     6448.000000   \n",
       "44     45.000000                              0.0     4938.000000   \n",
       "65     44.000000                              3.0     3772.000000   \n",
       "...          ...                              ...             ...   \n",
       "4612   54.000000                              3.0     9350.000000   \n",
       "46753  52.000000                              1.0     6388.000000   \n",
       "12434  74.000000                              0.0     1320.000000   \n",
       "45337  30.000000                              0.0     5000.000000   \n",
       "34491  56.508684                              0.0     6535.257745   \n",
       "\n",
       "       number_of_credit_lines  real_estate_loans  \\\n",
       "2                         8.0                0.0   \n",
       "20                       11.0                3.0   \n",
       "30                       11.0                0.0   \n",
       "44                        1.0                0.0   \n",
       "65                        8.0                1.0   \n",
       "...                       ...                ...   \n",
       "4612                      5.0                1.0   \n",
       "46753                     8.0                0.0   \n",
       "12434                     8.0                1.0   \n",
       "45337                     7.0                0.0   \n",
       "34491                    13.0                1.0   \n",
       "\n",
       "       ratio_debt_payment_to_income  credit_line_utilization  \\\n",
       "2                          0.160145                 1.227135   \n",
       "20                         0.590316                 0.975767   \n",
       "30                         0.190107                 0.865913   \n",
       "44                         0.068840                 1.000000   \n",
       "65                         0.537503                 0.207312   \n",
       "...                             ...                      ...   \n",
       "4612                      32.380957                 0.378989   \n",
       "46753                      0.166223                 0.087128   \n",
       "12434                      1.294474                 0.000000   \n",
       "45337                      0.203159                 0.562887   \n",
       "34491                      0.256532                 0.875891   \n",
       "\n",
       "       number_of_previous_late_payments_up_to_59_days  \\\n",
       "2                                            4.000000   \n",
       "20                                           3.000000   \n",
       "30                                           3.000000   \n",
       "44                                           0.000000   \n",
       "65                                           0.000000   \n",
       "...                                               ...   \n",
       "4612                                         0.000000   \n",
       "46753                                        0.000000   \n",
       "12434                                        0.114449   \n",
       "45337                                        0.000000   \n",
       "34491                                        0.000000   \n",
       "\n",
       "       number_of_previous_late_payments_up_to_89_days  \\\n",
       "2                                                 0.0   \n",
       "20                                                0.0   \n",
       "30                                                1.0   \n",
       "44                                                1.0   \n",
       "65                                                0.0   \n",
       "...                                               ...   \n",
       "4612                                              0.0   \n",
       "46753                                             0.0   \n",
       "12434                                             0.0   \n",
       "45337                                             0.0   \n",
       "34491                                             0.0   \n",
       "\n",
       "       number_of_previous_late_payments_90_days_or_more  defaulted_on_loan  \n",
       "2                                              0.000000                  1  \n",
       "20                                             0.000000                  1  \n",
       "30                                             0.000000                  1  \n",
       "44                                             2.000000                  1  \n",
       "65                                             0.000000                  1  \n",
       "...                                                 ...                ...  \n",
       "4612                                           0.000000                  0  \n",
       "46753                                          0.014701                  0  \n",
       "12434                                          0.000000                  0  \n",
       "45337                                          0.000000                  0  \n",
       "34491                                          0.000000                  0  \n",
       "\n",
       "[9948 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = data_new[data_new['defaulted_on_loan'] == 0]\n",
    "zeros = zeros.sample(n=4974, replace=False)\n",
    "\n",
    "# data undersampled\n",
    "df_und = ones.append(zeros)\n",
    "df_und.reset_index(drop=True)\n",
    "df_und"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-persian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-mills",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "adjusted-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve, \\\n",
    "roc_auc_score,roc_curve,recall_score,classification_report, f1_score\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dated-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_und = df_und[columns]\n",
    "y_und = pd.DataFrame(df_und.iloc[:, -1])\n",
    "\n",
    "X_und = X_und.reset_index(drop=False)\n",
    "y_und = y_und.reset_index(drop=False)\n",
    "\n",
    "X_und = X_und.drop(['index'], axis=1)\n",
    "y_und = y_und.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "elegant-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(8, shuffle=True)\n",
    "skf = StratifiedKFold(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cardiovascular-tyler",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7062855603345252\n",
      "0.6928531515091951\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in kf.split(X_und):\n",
    "    X_train, X_test = X_und.iloc[train_idx], X_und.iloc[test_idx]\n",
    "    y_train, y_test = y_und.iloc[train_idx], y_und.iloc[test_idx]\n",
    "    \n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', VotingClassifier(estimators=[\n",
    "            ('tree3', DecisionTreeClassifier(max_depth=3)),\n",
    "            ('tree9', DecisionTreeClassifier(max_depth=9)),\n",
    "            ('tree15', DecisionTreeClassifier(max_depth=15)),\n",
    "            ('tree21', DecisionTreeClassifier(max_depth=21)),\n",
    "            ('tree35', DecisionTreeClassifier(max_depth=35)),\n",
    "        ], voting='hard'))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_predicted=pipe.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))\n",
    "# print(np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "headed-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "specified-sharp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7309655443939062\n",
      "0.6860645213588288\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in kf.split(X_und):\n",
    "    X_train, X_test = X_und.iloc[train_idx], X_und.iloc[test_idx]\n",
    "    y_train, y_test = y_und.iloc[train_idx], y_und.iloc[test_idx]\n",
    "    \n",
    "    pipe2 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                        n_estimators=10))\n",
    "    ])\n",
    "    pipe2.fit(X_train, y_train.values.ravel())\n",
    "    y_predicted=pipe2.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))\n",
    "# print(np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "floppy-frontier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8548294895277755\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_new) \n",
    "    y_predicted=pipe2.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-selling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "incorporated-polymer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7664302905851895\n",
      "0.7449503019700334\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in kf.split(X_und):\n",
    "    X_train, X_test = X_und.iloc[train_idx], X_und.iloc[test_idx]\n",
    "    y_train, y_test = y_und.iloc[train_idx], y_und.iloc[test_idx]\n",
    "    \n",
    "    pipe1 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', BaggingClassifier(base_estimator=RandomForestClassifier(),\n",
    "                                        n_estimators=10))\n",
    "    ])\n",
    "    pipe1.fit(X_train, y_train)\n",
    "    y_predicted=pipe1.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))\n",
    "# print(np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "destroyed-television",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852779037773152\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_new) \n",
    "    y_predicted=pipe1.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-consistency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-setting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-porter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "heated-delhi",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7480409964092062\n",
      "0.6952959885374963\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in kf.split(X_und):\n",
    "    X_train, X_test = X_und.iloc[train_idx], X_und.iloc[test_idx]\n",
    "    y_train, y_test = y_und.iloc[train_idx], y_und.iloc[test_idx]\n",
    "    \n",
    "    pipe4 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', BaggingClassifier(base_estimator=VotingClassifier(estimators=[\n",
    "            ('tree3', DecisionTreeClassifier(max_depth=3)),\n",
    "            ('tree9', DecisionTreeClassifier(max_depth=9)),\n",
    "            ('tree15', DecisionTreeClassifier(max_depth=15)),\n",
    "            ('tree21', DecisionTreeClassifier(max_depth=21)),\n",
    "            ('tree35', DecisionTreeClassifier(max_depth=35)),\n",
    "        ], voting='hard')) )\n",
    "    ])\n",
    "    pipe4.fit(X_train, y_train)\n",
    "    y_predicted=pipe4.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))\n",
    "# print(np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "worst-theorem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8313835174252251\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_new) \n",
    "    y_predicted=pipe4.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-rider",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-mistress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-wells",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mature-worst",
   "metadata": {},
   "source": [
    "## Let's try RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "threaded-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "graduate-beads",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 66461, 1: 4974})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "offshore-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "european-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus, y_rus = rus.fit_resample(X_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "legal-thesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4974, 1: 4974})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "healthy-israeli",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734524559721736\n",
      "0.6884159100226204\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in kf.split(X_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe7 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                        n_estimators=10))\n",
    "    ])\n",
    "    pipe7.fit(X_train, y_train)\n",
    "    y_predicted=pipe7.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))\n",
    "# print(np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "returning-pointer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8663647006775216\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_new) \n",
    "    y_predicted=pipe7.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-touch",
   "metadata": {},
   "source": [
    "### Pipe7 is the best so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-scoop",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "legal-recall",
   "metadata": {},
   "source": [
    "### Pipe 71 (random forest, undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "congressional-spyware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7602874961634885\n",
      "0.7380651204328005\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in kf.split(X_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe71 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ])\n",
    "    pipe71.fit(X_train, y_train)\n",
    "    y_predicted=pipe71.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))\n",
    "# print(np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "accomplished-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8821445737361475\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_new) \n",
    "    y_predicted=pipe71.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-payroll",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "caring-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "color-better",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 386ms\tremaining: 3m 12s\n",
      "1:\ttotal: 581ms\tremaining: 2m 24s\n",
      "2:\ttotal: 824ms\tremaining: 2m 16s\n",
      "3:\ttotal: 1.03s\tremaining: 2m 8s\n",
      "4:\ttotal: 1.25s\tremaining: 2m 3s\n",
      "5:\ttotal: 1.46s\tremaining: 2m\n",
      "6:\ttotal: 1.65s\tremaining: 1m 56s\n",
      "7:\ttotal: 1.86s\tremaining: 1m 54s\n",
      "8:\ttotal: 2.06s\tremaining: 1m 52s\n",
      "9:\ttotal: 2.28s\tremaining: 1m 51s\n",
      "10:\ttotal: 2.48s\tremaining: 1m 50s\n",
      "11:\ttotal: 2.69s\tremaining: 1m 49s\n",
      "12:\ttotal: 2.9s\tremaining: 1m 48s\n",
      "13:\ttotal: 3.11s\tremaining: 1m 48s\n",
      "14:\ttotal: 3.33s\tremaining: 1m 47s\n",
      "15:\ttotal: 3.54s\tremaining: 1m 46s\n",
      "16:\ttotal: 3.76s\tremaining: 1m 46s\n",
      "17:\ttotal: 4.02s\tremaining: 1m 47s\n",
      "18:\ttotal: 4.34s\tremaining: 1m 49s\n",
      "19:\ttotal: 4.56s\tremaining: 1m 49s\n",
      "20:\ttotal: 4.78s\tremaining: 1m 49s\n",
      "21:\ttotal: 5.01s\tremaining: 1m 48s\n",
      "22:\ttotal: 5.23s\tremaining: 1m 48s\n",
      "23:\ttotal: 5.46s\tremaining: 1m 48s\n",
      "24:\ttotal: 5.67s\tremaining: 1m 47s\n",
      "25:\ttotal: 5.68s\tremaining: 1m 43s\n",
      "26:\ttotal: 5.9s\tremaining: 1m 43s\n",
      "27:\ttotal: 6.11s\tremaining: 1m 43s\n",
      "28:\ttotal: 6.34s\tremaining: 1m 43s\n",
      "29:\ttotal: 6.55s\tremaining: 1m 42s\n",
      "30:\ttotal: 6.83s\tremaining: 1m 43s\n",
      "31:\ttotal: 7.04s\tremaining: 1m 42s\n",
      "32:\ttotal: 7.26s\tremaining: 1m 42s\n",
      "33:\ttotal: 7.49s\tremaining: 1m 42s\n",
      "34:\ttotal: 7.73s\tremaining: 1m 42s\n",
      "35:\ttotal: 7.95s\tremaining: 1m 42s\n",
      "36:\ttotal: 8.18s\tremaining: 1m 42s\n",
      "37:\ttotal: 8.41s\tremaining: 1m 42s\n",
      "38:\ttotal: 8.63s\tremaining: 1m 42s\n",
      "39:\ttotal: 8.98s\tremaining: 1m 43s\n",
      "40:\ttotal: 9.2s\tremaining: 1m 43s\n",
      "41:\ttotal: 9.43s\tremaining: 1m 42s\n",
      "42:\ttotal: 9.64s\tremaining: 1m 42s\n",
      "43:\ttotal: 9.87s\tremaining: 1m 42s\n",
      "44:\ttotal: 10.1s\tremaining: 1m 41s\n",
      "45:\ttotal: 10.3s\tremaining: 1m 42s\n",
      "46:\ttotal: 10.6s\tremaining: 1m 41s\n",
      "47:\ttotal: 10.8s\tremaining: 1m 41s\n",
      "48:\ttotal: 11.1s\tremaining: 1m 42s\n",
      "49:\ttotal: 11.3s\tremaining: 1m 41s\n",
      "50:\ttotal: 11.6s\tremaining: 1m 41s\n",
      "51:\ttotal: 11.8s\tremaining: 1m 41s\n",
      "52:\ttotal: 12.1s\tremaining: 1m 41s\n",
      "53:\ttotal: 12.3s\tremaining: 1m 41s\n",
      "54:\ttotal: 12.5s\tremaining: 1m 41s\n",
      "55:\ttotal: 12.7s\tremaining: 1m 40s\n",
      "56:\ttotal: 13s\tremaining: 1m 41s\n",
      "57:\ttotal: 13.3s\tremaining: 1m 41s\n",
      "58:\ttotal: 13.5s\tremaining: 1m 40s\n",
      "59:\ttotal: 13.7s\tremaining: 1m 40s\n",
      "60:\ttotal: 13.9s\tremaining: 1m 40s\n",
      "61:\ttotal: 14.1s\tremaining: 1m 39s\n",
      "62:\ttotal: 14.4s\tremaining: 1m 39s\n",
      "63:\ttotal: 14.6s\tremaining: 1m 39s\n",
      "64:\ttotal: 14.8s\tremaining: 1m 39s\n",
      "65:\ttotal: 15s\tremaining: 1m 38s\n",
      "66:\ttotal: 15.3s\tremaining: 1m 38s\n",
      "67:\ttotal: 15.5s\tremaining: 1m 38s\n",
      "68:\ttotal: 15.7s\tremaining: 1m 38s\n",
      "69:\ttotal: 16s\tremaining: 1m 38s\n",
      "70:\ttotal: 16.3s\tremaining: 1m 38s\n",
      "71:\ttotal: 16.6s\tremaining: 1m 38s\n",
      "72:\ttotal: 16.8s\tremaining: 1m 38s\n",
      "73:\ttotal: 17.1s\tremaining: 1m 38s\n",
      "74:\ttotal: 17.3s\tremaining: 1m 38s\n",
      "75:\ttotal: 17.5s\tremaining: 1m 37s\n",
      "76:\ttotal: 17.7s\tremaining: 1m 37s\n",
      "77:\ttotal: 18s\tremaining: 1m 37s\n",
      "78:\ttotal: 18.3s\tremaining: 1m 37s\n",
      "79:\ttotal: 18.6s\tremaining: 1m 37s\n",
      "80:\ttotal: 18.8s\tremaining: 1m 37s\n",
      "81:\ttotal: 19.1s\tremaining: 1m 37s\n",
      "82:\ttotal: 19.5s\tremaining: 1m 37s\n",
      "83:\ttotal: 19.8s\tremaining: 1m 38s\n",
      "84:\ttotal: 20.2s\tremaining: 1m 38s\n",
      "85:\ttotal: 20.5s\tremaining: 1m 38s\n",
      "86:\ttotal: 20.7s\tremaining: 1m 38s\n",
      "87:\ttotal: 21.1s\tremaining: 1m 38s\n",
      "88:\ttotal: 21.4s\tremaining: 1m 38s\n",
      "89:\ttotal: 21.7s\tremaining: 1m 38s\n",
      "90:\ttotal: 22s\tremaining: 1m 38s\n",
      "91:\ttotal: 22.2s\tremaining: 1m 38s\n",
      "92:\ttotal: 22.5s\tremaining: 1m 38s\n",
      "93:\ttotal: 22.8s\tremaining: 1m 38s\n",
      "94:\ttotal: 23.1s\tremaining: 1m 38s\n",
      "95:\ttotal: 23.3s\tremaining: 1m 37s\n",
      "96:\ttotal: 23.6s\tremaining: 1m 37s\n",
      "97:\ttotal: 23.9s\tremaining: 1m 37s\n",
      "98:\ttotal: 24.1s\tremaining: 1m 37s\n",
      "99:\ttotal: 24.3s\tremaining: 1m 37s\n",
      "100:\ttotal: 24.5s\tremaining: 1m 36s\n",
      "101:\ttotal: 24.7s\tremaining: 1m 36s\n",
      "102:\ttotal: 24.9s\tremaining: 1m 36s\n",
      "103:\ttotal: 25.1s\tremaining: 1m 35s\n",
      "104:\ttotal: 25.3s\tremaining: 1m 35s\n",
      "105:\ttotal: 25.5s\tremaining: 1m 34s\n",
      "106:\ttotal: 25.7s\tremaining: 1m 34s\n",
      "107:\ttotal: 25.9s\tremaining: 1m 34s\n",
      "108:\ttotal: 26.1s\tremaining: 1m 33s\n",
      "109:\ttotal: 26.3s\tremaining: 1m 33s\n",
      "110:\ttotal: 26.5s\tremaining: 1m 32s\n",
      "111:\ttotal: 26.7s\tremaining: 1m 32s\n",
      "112:\ttotal: 26.9s\tremaining: 1m 32s\n",
      "113:\ttotal: 27.1s\tremaining: 1m 31s\n",
      "114:\ttotal: 27.4s\tremaining: 1m 31s\n",
      "115:\ttotal: 27.6s\tremaining: 1m 31s\n",
      "116:\ttotal: 27.8s\tremaining: 1m 30s\n",
      "117:\ttotal: 28s\tremaining: 1m 30s\n",
      "118:\ttotal: 28.2s\tremaining: 1m 30s\n",
      "119:\ttotal: 28.4s\tremaining: 1m 30s\n",
      "120:\ttotal: 28.6s\tremaining: 1m 29s\n",
      "121:\ttotal: 28.9s\tremaining: 1m 29s\n",
      "122:\ttotal: 29.2s\tremaining: 1m 29s\n",
      "123:\ttotal: 29.4s\tremaining: 1m 29s\n",
      "124:\ttotal: 29.7s\tremaining: 1m 29s\n",
      "125:\ttotal: 30s\tremaining: 1m 29s\n",
      "126:\ttotal: 30.2s\tremaining: 1m 28s\n",
      "127:\ttotal: 30.5s\tremaining: 1m 28s\n",
      "128:\ttotal: 30.7s\tremaining: 1m 28s\n",
      "129:\ttotal: 30.9s\tremaining: 1m 27s\n",
      "130:\ttotal: 31.1s\tremaining: 1m 27s\n",
      "131:\ttotal: 31.3s\tremaining: 1m 27s\n",
      "132:\ttotal: 31.5s\tremaining: 1m 27s\n",
      "133:\ttotal: 31.7s\tremaining: 1m 26s\n",
      "134:\ttotal: 31.9s\tremaining: 1m 26s\n",
      "135:\ttotal: 32.1s\tremaining: 1m 25s\n",
      "136:\ttotal: 32.3s\tremaining: 1m 25s\n",
      "137:\ttotal: 32.5s\tremaining: 1m 25s\n",
      "138:\ttotal: 32.7s\tremaining: 1m 25s\n",
      "139:\ttotal: 33s\tremaining: 1m 24s\n",
      "140:\ttotal: 33.2s\tremaining: 1m 24s\n",
      "141:\ttotal: 33.4s\tremaining: 1m 24s\n",
      "142:\ttotal: 33.8s\tremaining: 1m 24s\n",
      "143:\ttotal: 34.2s\tremaining: 1m 24s\n",
      "144:\ttotal: 34.4s\tremaining: 1m 24s\n",
      "145:\ttotal: 34.7s\tremaining: 1m 24s\n",
      "146:\ttotal: 34.9s\tremaining: 1m 23s\n",
      "147:\ttotal: 35.1s\tremaining: 1m 23s\n",
      "148:\ttotal: 35.3s\tremaining: 1m 23s\n",
      "149:\ttotal: 35.6s\tremaining: 1m 23s\n",
      "150:\ttotal: 35.9s\tremaining: 1m 22s\n",
      "151:\ttotal: 36.2s\tremaining: 1m 22s\n",
      "152:\ttotal: 36.4s\tremaining: 1m 22s\n",
      "153:\ttotal: 36.7s\tremaining: 1m 22s\n",
      "154:\ttotal: 37s\tremaining: 1m 22s\n",
      "155:\ttotal: 37.3s\tremaining: 1m 22s\n",
      "156:\ttotal: 37.7s\tremaining: 1m 22s\n",
      "157:\ttotal: 37.9s\tremaining: 1m 22s\n",
      "158:\ttotal: 38.2s\tremaining: 1m 21s\n",
      "159:\ttotal: 38.4s\tremaining: 1m 21s\n",
      "160:\ttotal: 38.6s\tremaining: 1m 21s\n",
      "161:\ttotal: 38.9s\tremaining: 1m 21s\n",
      "162:\ttotal: 39.1s\tremaining: 1m 20s\n",
      "163:\ttotal: 39.4s\tremaining: 1m 20s\n",
      "164:\ttotal: 39.7s\tremaining: 1m 20s\n",
      "165:\ttotal: 40s\tremaining: 1m 20s\n",
      "166:\ttotal: 40.3s\tremaining: 1m 20s\n",
      "167:\ttotal: 40.6s\tremaining: 1m 20s\n",
      "168:\ttotal: 40.8s\tremaining: 1m 19s\n",
      "169:\ttotal: 41.1s\tremaining: 1m 19s\n",
      "170:\ttotal: 41.3s\tremaining: 1m 19s\n",
      "171:\ttotal: 41.6s\tremaining: 1m 19s\n",
      "172:\ttotal: 42s\tremaining: 1m 19s\n",
      "173:\ttotal: 42.2s\tremaining: 1m 19s\n",
      "174:\ttotal: 42.5s\tremaining: 1m 18s\n",
      "175:\ttotal: 42.9s\tremaining: 1m 18s\n",
      "176:\ttotal: 43.1s\tremaining: 1m 18s\n",
      "177:\ttotal: 43.5s\tremaining: 1m 18s\n",
      "178:\ttotal: 43.8s\tremaining: 1m 18s\n",
      "179:\ttotal: 44s\tremaining: 1m 18s\n",
      "180:\ttotal: 44.3s\tremaining: 1m 18s\n",
      "181:\ttotal: 44.5s\tremaining: 1m 17s\n",
      "182:\ttotal: 44.9s\tremaining: 1m 17s\n",
      "183:\ttotal: 45.1s\tremaining: 1m 17s\n",
      "184:\ttotal: 45.4s\tremaining: 1m 17s\n",
      "185:\ttotal: 45.7s\tremaining: 1m 17s\n",
      "186:\ttotal: 46.1s\tremaining: 1m 17s\n",
      "187:\ttotal: 46.3s\tremaining: 1m 16s\n",
      "188:\ttotal: 46.6s\tremaining: 1m 16s\n",
      "189:\ttotal: 46.9s\tremaining: 1m 16s\n",
      "190:\ttotal: 47.1s\tremaining: 1m 16s\n",
      "191:\ttotal: 47.5s\tremaining: 1m 16s\n",
      "192:\ttotal: 47.8s\tremaining: 1m 16s\n",
      "193:\ttotal: 48s\tremaining: 1m 15s\n",
      "194:\ttotal: 48.3s\tremaining: 1m 15s\n",
      "195:\ttotal: 48.6s\tremaining: 1m 15s\n",
      "196:\ttotal: 48.9s\tremaining: 1m 15s\n",
      "197:\ttotal: 49.2s\tremaining: 1m 15s\n",
      "198:\ttotal: 49.4s\tremaining: 1m 14s\n",
      "199:\ttotal: 49.6s\tremaining: 1m 14s\n",
      "200:\ttotal: 49.8s\tremaining: 1m 14s\n",
      "201:\ttotal: 50.1s\tremaining: 1m 13s\n",
      "202:\ttotal: 50.4s\tremaining: 1m 13s\n",
      "203:\ttotal: 50.7s\tremaining: 1m 13s\n",
      "204:\ttotal: 50.9s\tremaining: 1m 13s\n",
      "205:\ttotal: 51.1s\tremaining: 1m 12s\n",
      "206:\ttotal: 51.3s\tremaining: 1m 12s\n",
      "207:\ttotal: 51.5s\tremaining: 1m 12s\n",
      "208:\ttotal: 51.8s\tremaining: 1m 12s\n",
      "209:\ttotal: 52s\tremaining: 1m 11s\n",
      "210:\ttotal: 52.3s\tremaining: 1m 11s\n",
      "211:\ttotal: 52.5s\tremaining: 1m 11s\n",
      "212:\ttotal: 52.7s\tremaining: 1m 11s\n",
      "213:\ttotal: 52.9s\tremaining: 1m 10s\n",
      "214:\ttotal: 53.1s\tremaining: 1m 10s\n",
      "215:\ttotal: 53.3s\tremaining: 1m 10s\n",
      "216:\ttotal: 53.6s\tremaining: 1m 9s\n",
      "217:\ttotal: 53.8s\tremaining: 1m 9s\n",
      "218:\ttotal: 54.3s\tremaining: 1m 9s\n",
      "219:\ttotal: 54.6s\tremaining: 1m 9s\n",
      "220:\ttotal: 54.8s\tremaining: 1m 9s\n",
      "221:\ttotal: 55.3s\tremaining: 1m 9s\n",
      "222:\ttotal: 55.7s\tremaining: 1m 9s\n",
      "223:\ttotal: 55.9s\tremaining: 1m 8s\n",
      "224:\ttotal: 56.2s\tremaining: 1m 8s\n",
      "225:\ttotal: 56.5s\tremaining: 1m 8s\n",
      "226:\ttotal: 56.7s\tremaining: 1m 8s\n",
      "227:\ttotal: 57s\tremaining: 1m 7s\n",
      "228:\ttotal: 57.2s\tremaining: 1m 7s\n",
      "229:\ttotal: 57.5s\tremaining: 1m 7s\n",
      "230:\ttotal: 57.8s\tremaining: 1m 7s\n",
      "231:\ttotal: 58.1s\tremaining: 1m 7s\n",
      "232:\ttotal: 58.3s\tremaining: 1m 6s\n",
      "233:\ttotal: 58.6s\tremaining: 1m 6s\n",
      "234:\ttotal: 58.8s\tremaining: 1m 6s\n",
      "235:\ttotal: 59.1s\tremaining: 1m 6s\n",
      "236:\ttotal: 59.3s\tremaining: 1m 5s\n",
      "237:\ttotal: 59.6s\tremaining: 1m 5s\n",
      "238:\ttotal: 59.8s\tremaining: 1m 5s\n",
      "239:\ttotal: 1m\tremaining: 1m 5s\n",
      "240:\ttotal: 1m\tremaining: 1m 4s\n",
      "241:\ttotal: 1m\tremaining: 1m 4s\n",
      "242:\ttotal: 1m\tremaining: 1m 4s\n",
      "243:\ttotal: 1m 1s\tremaining: 1m 4s\n",
      "244:\ttotal: 1m 1s\tremaining: 1m 3s\n",
      "245:\ttotal: 1m 1s\tremaining: 1m 3s\n",
      "246:\ttotal: 1m 1s\tremaining: 1m 3s\n",
      "247:\ttotal: 1m 2s\tremaining: 1m 3s\n",
      "248:\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "249:\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "250:\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "251:\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "252:\ttotal: 1m 3s\tremaining: 1m 1s\n",
      "253:\ttotal: 1m 3s\tremaining: 1m 1s\n",
      "254:\ttotal: 1m 3s\tremaining: 1m 1s\n",
      "255:\ttotal: 1m 3s\tremaining: 1m\n",
      "256:\ttotal: 1m 3s\tremaining: 1m\n",
      "257:\ttotal: 1m 4s\tremaining: 1m\n",
      "258:\ttotal: 1m 4s\tremaining: 59.9s\n",
      "259:\ttotal: 1m 4s\tremaining: 59.6s\n",
      "260:\ttotal: 1m 4s\tremaining: 59.3s\n",
      "261:\ttotal: 1m 4s\tremaining: 59s\n",
      "262:\ttotal: 1m 5s\tremaining: 58.7s\n",
      "263:\ttotal: 1m 5s\tremaining: 58.4s\n",
      "264:\ttotal: 1m 5s\tremaining: 58.1s\n",
      "265:\ttotal: 1m 5s\tremaining: 57.8s\n",
      "266:\ttotal: 1m 5s\tremaining: 57.5s\n",
      "267:\ttotal: 1m 6s\tremaining: 57.2s\n",
      "268:\ttotal: 1m 6s\tremaining: 56.9s\n",
      "269:\ttotal: 1m 6s\tremaining: 56.7s\n",
      "270:\ttotal: 1m 6s\tremaining: 56.4s\n",
      "271:\ttotal: 1m 6s\tremaining: 56.1s\n",
      "272:\ttotal: 1m 7s\tremaining: 55.8s\n",
      "273:\ttotal: 1m 7s\tremaining: 55.5s\n",
      "274:\ttotal: 1m 7s\tremaining: 55.2s\n",
      "275:\ttotal: 1m 7s\tremaining: 55s\n",
      "276:\ttotal: 1m 7s\tremaining: 54.7s\n",
      "277:\ttotal: 1m 8s\tremaining: 54.4s\n",
      "278:\ttotal: 1m 8s\tremaining: 54.1s\n",
      "279:\ttotal: 1m 8s\tremaining: 53.8s\n",
      "280:\ttotal: 1m 8s\tremaining: 53.6s\n",
      "281:\ttotal: 1m 8s\tremaining: 53.3s\n",
      "282:\ttotal: 1m 9s\tremaining: 53s\n",
      "283:\ttotal: 1m 9s\tremaining: 52.7s\n",
      "284:\ttotal: 1m 9s\tremaining: 52.4s\n",
      "285:\ttotal: 1m 9s\tremaining: 52.2s\n",
      "286:\ttotal: 1m 9s\tremaining: 51.9s\n",
      "287:\ttotal: 1m 10s\tremaining: 51.6s\n",
      "288:\ttotal: 1m 10s\tremaining: 51.3s\n",
      "289:\ttotal: 1m 10s\tremaining: 51.1s\n",
      "290:\ttotal: 1m 10s\tremaining: 50.8s\n",
      "291:\ttotal: 1m 10s\tremaining: 50.5s\n",
      "292:\ttotal: 1m 11s\tremaining: 50.3s\n",
      "293:\ttotal: 1m 11s\tremaining: 50s\n",
      "294:\ttotal: 1m 11s\tremaining: 49.7s\n",
      "295:\ttotal: 1m 11s\tremaining: 49.5s\n",
      "296:\ttotal: 1m 11s\tremaining: 49.2s\n",
      "297:\ttotal: 1m 12s\tremaining: 48.9s\n",
      "298:\ttotal: 1m 12s\tremaining: 48.7s\n",
      "299:\ttotal: 1m 12s\tremaining: 48.4s\n",
      "300:\ttotal: 1m 12s\tremaining: 48.1s\n",
      "301:\ttotal: 1m 13s\tremaining: 47.9s\n",
      "302:\ttotal: 1m 13s\tremaining: 47.6s\n",
      "303:\ttotal: 1m 13s\tremaining: 47.3s\n",
      "304:\ttotal: 1m 13s\tremaining: 47.1s\n",
      "305:\ttotal: 1m 13s\tremaining: 46.8s\n",
      "306:\ttotal: 1m 14s\tremaining: 46.5s\n",
      "307:\ttotal: 1m 14s\tremaining: 46.3s\n",
      "308:\ttotal: 1m 14s\tremaining: 46s\n",
      "309:\ttotal: 1m 14s\tremaining: 45.7s\n",
      "310:\ttotal: 1m 14s\tremaining: 45.5s\n",
      "311:\ttotal: 1m 15s\tremaining: 45.2s\n",
      "312:\ttotal: 1m 15s\tremaining: 44.9s\n",
      "313:\ttotal: 1m 15s\tremaining: 44.7s\n",
      "314:\ttotal: 1m 15s\tremaining: 44.4s\n",
      "315:\ttotal: 1m 15s\tremaining: 44.2s\n",
      "316:\ttotal: 1m 16s\tremaining: 43.9s\n",
      "317:\ttotal: 1m 16s\tremaining: 43.7s\n",
      "318:\ttotal: 1m 16s\tremaining: 43.4s\n",
      "319:\ttotal: 1m 16s\tremaining: 43.2s\n",
      "320:\ttotal: 1m 16s\tremaining: 42.9s\n",
      "321:\ttotal: 1m 17s\tremaining: 42.6s\n",
      "322:\ttotal: 1m 17s\tremaining: 42.4s\n",
      "323:\ttotal: 1m 17s\tremaining: 42.1s\n",
      "324:\ttotal: 1m 17s\tremaining: 41.9s\n",
      "325:\ttotal: 1m 17s\tremaining: 41.6s\n",
      "326:\ttotal: 1m 18s\tremaining: 41.3s\n",
      "327:\ttotal: 1m 18s\tremaining: 41.1s\n",
      "328:\ttotal: 1m 18s\tremaining: 40.8s\n",
      "329:\ttotal: 1m 18s\tremaining: 40.6s\n",
      "330:\ttotal: 1m 18s\tremaining: 40.2s\n",
      "331:\ttotal: 1m 18s\tremaining: 40s\n",
      "332:\ttotal: 1m 19s\tremaining: 39.7s\n",
      "333:\ttotal: 1m 19s\tremaining: 39.5s\n",
      "334:\ttotal: 1m 19s\tremaining: 39.2s\n",
      "335:\ttotal: 1m 19s\tremaining: 39s\n",
      "336:\ttotal: 1m 20s\tremaining: 38.7s\n",
      "337:\ttotal: 1m 20s\tremaining: 38.4s\n",
      "338:\ttotal: 1m 20s\tremaining: 38.2s\n",
      "339:\ttotal: 1m 20s\tremaining: 37.9s\n",
      "340:\ttotal: 1m 20s\tremaining: 37.7s\n",
      "341:\ttotal: 1m 21s\tremaining: 37.4s\n",
      "342:\ttotal: 1m 21s\tremaining: 37.2s\n",
      "343:\ttotal: 1m 21s\tremaining: 36.9s\n",
      "344:\ttotal: 1m 21s\tremaining: 36.7s\n",
      "345:\ttotal: 1m 21s\tremaining: 36.4s\n",
      "346:\ttotal: 1m 22s\tremaining: 36.2s\n",
      "347:\ttotal: 1m 22s\tremaining: 35.9s\n",
      "348:\ttotal: 1m 22s\tremaining: 35.7s\n",
      "349:\ttotal: 1m 22s\tremaining: 35.4s\n",
      "350:\ttotal: 1m 22s\tremaining: 35.2s\n",
      "351:\ttotal: 1m 23s\tremaining: 34.9s\n",
      "352:\ttotal: 1m 23s\tremaining: 34.7s\n",
      "353:\ttotal: 1m 23s\tremaining: 34.4s\n",
      "354:\ttotal: 1m 23s\tremaining: 34.2s\n",
      "355:\ttotal: 1m 23s\tremaining: 33.9s\n",
      "356:\ttotal: 1m 24s\tremaining: 33.7s\n",
      "357:\ttotal: 1m 24s\tremaining: 33.4s\n",
      "358:\ttotal: 1m 24s\tremaining: 33.2s\n",
      "359:\ttotal: 1m 24s\tremaining: 32.9s\n",
      "360:\ttotal: 1m 24s\tremaining: 32.7s\n",
      "361:\ttotal: 1m 25s\tremaining: 32.4s\n",
      "362:\ttotal: 1m 25s\tremaining: 32.2s\n",
      "363:\ttotal: 1m 25s\tremaining: 31.9s\n",
      "364:\ttotal: 1m 25s\tremaining: 31.7s\n",
      "365:\ttotal: 1m 25s\tremaining: 31.5s\n",
      "366:\ttotal: 1m 26s\tremaining: 31.2s\n",
      "367:\ttotal: 1m 26s\tremaining: 31s\n",
      "368:\ttotal: 1m 26s\tremaining: 30.7s\n",
      "369:\ttotal: 1m 26s\tremaining: 30.5s\n",
      "370:\ttotal: 1m 26s\tremaining: 30.2s\n",
      "371:\ttotal: 1m 27s\tremaining: 30s\n",
      "372:\ttotal: 1m 27s\tremaining: 29.8s\n",
      "373:\ttotal: 1m 27s\tremaining: 29.5s\n",
      "374:\ttotal: 1m 27s\tremaining: 29.3s\n",
      "375:\ttotal: 1m 28s\tremaining: 29s\n",
      "376:\ttotal: 1m 28s\tremaining: 28.8s\n",
      "377:\ttotal: 1m 28s\tremaining: 28.6s\n",
      "378:\ttotal: 1m 28s\tremaining: 28.3s\n",
      "379:\ttotal: 1m 28s\tremaining: 28.1s\n",
      "380:\ttotal: 1m 29s\tremaining: 27.8s\n",
      "381:\ttotal: 1m 29s\tremaining: 27.6s\n",
      "382:\ttotal: 1m 29s\tremaining: 27.3s\n",
      "383:\ttotal: 1m 29s\tremaining: 27.1s\n",
      "384:\ttotal: 1m 29s\tremaining: 26.9s\n",
      "385:\ttotal: 1m 30s\tremaining: 26.6s\n",
      "386:\ttotal: 1m 30s\tremaining: 26.4s\n",
      "387:\ttotal: 1m 30s\tremaining: 26.1s\n",
      "388:\ttotal: 1m 30s\tremaining: 25.9s\n",
      "389:\ttotal: 1m 30s\tremaining: 25.7s\n",
      "390:\ttotal: 1m 31s\tremaining: 25.4s\n",
      "391:\ttotal: 1m 31s\tremaining: 25.2s\n",
      "392:\ttotal: 1m 31s\tremaining: 24.9s\n",
      "393:\ttotal: 1m 31s\tremaining: 24.7s\n",
      "394:\ttotal: 1m 31s\tremaining: 24.4s\n",
      "395:\ttotal: 1m 32s\tremaining: 24.2s\n",
      "396:\ttotal: 1m 32s\tremaining: 24s\n",
      "397:\ttotal: 1m 32s\tremaining: 23.7s\n",
      "398:\ttotal: 1m 32s\tremaining: 23.5s\n",
      "399:\ttotal: 1m 32s\tremaining: 23.2s\n",
      "400:\ttotal: 1m 33s\tremaining: 23s\n",
      "401:\ttotal: 1m 33s\tremaining: 22.8s\n",
      "402:\ttotal: 1m 33s\tremaining: 22.5s\n",
      "403:\ttotal: 1m 33s\tremaining: 22.3s\n",
      "404:\ttotal: 1m 34s\tremaining: 22.1s\n",
      "405:\ttotal: 1m 34s\tremaining: 21.8s\n",
      "406:\ttotal: 1m 34s\tremaining: 21.6s\n",
      "407:\ttotal: 1m 34s\tremaining: 21.3s\n",
      "408:\ttotal: 1m 34s\tremaining: 21.1s\n",
      "409:\ttotal: 1m 35s\tremaining: 20.9s\n",
      "410:\ttotal: 1m 35s\tremaining: 20.6s\n",
      "411:\ttotal: 1m 35s\tremaining: 20.4s\n",
      "412:\ttotal: 1m 35s\tremaining: 20.2s\n",
      "413:\ttotal: 1m 35s\tremaining: 19.9s\n",
      "414:\ttotal: 1m 36s\tremaining: 19.7s\n",
      "415:\ttotal: 1m 36s\tremaining: 19.5s\n",
      "416:\ttotal: 1m 36s\tremaining: 19.2s\n",
      "417:\ttotal: 1m 36s\tremaining: 19s\n",
      "418:\ttotal: 1m 36s\tremaining: 18.7s\n",
      "419:\ttotal: 1m 37s\tremaining: 18.5s\n",
      "420:\ttotal: 1m 37s\tremaining: 18.3s\n",
      "421:\ttotal: 1m 37s\tremaining: 18s\n",
      "422:\ttotal: 1m 37s\tremaining: 17.8s\n",
      "423:\ttotal: 1m 37s\tremaining: 17.6s\n",
      "424:\ttotal: 1m 38s\tremaining: 17.3s\n",
      "425:\ttotal: 1m 38s\tremaining: 17.1s\n",
      "426:\ttotal: 1m 38s\tremaining: 16.9s\n",
      "427:\ttotal: 1m 38s\tremaining: 16.6s\n",
      "428:\ttotal: 1m 39s\tremaining: 16.4s\n",
      "429:\ttotal: 1m 39s\tremaining: 16.2s\n",
      "430:\ttotal: 1m 39s\tremaining: 15.9s\n",
      "431:\ttotal: 1m 39s\tremaining: 15.7s\n",
      "432:\ttotal: 1m 40s\tremaining: 15.5s\n",
      "433:\ttotal: 1m 40s\tremaining: 15.3s\n",
      "434:\ttotal: 1m 40s\tremaining: 15s\n",
      "435:\ttotal: 1m 40s\tremaining: 14.8s\n",
      "436:\ttotal: 1m 41s\tremaining: 14.6s\n",
      "437:\ttotal: 1m 41s\tremaining: 14.4s\n",
      "438:\ttotal: 1m 41s\tremaining: 14.1s\n",
      "439:\ttotal: 1m 42s\tremaining: 13.9s\n",
      "440:\ttotal: 1m 42s\tremaining: 13.7s\n",
      "441:\ttotal: 1m 42s\tremaining: 13.5s\n",
      "442:\ttotal: 1m 42s\tremaining: 13.2s\n",
      "443:\ttotal: 1m 42s\tremaining: 13s\n",
      "444:\ttotal: 1m 43s\tremaining: 12.8s\n",
      "445:\ttotal: 1m 43s\tremaining: 12.5s\n",
      "446:\ttotal: 1m 43s\tremaining: 12.3s\n",
      "447:\ttotal: 1m 43s\tremaining: 12.1s\n",
      "448:\ttotal: 1m 44s\tremaining: 11.8s\n",
      "449:\ttotal: 1m 44s\tremaining: 11.6s\n",
      "450:\ttotal: 1m 44s\tremaining: 11.4s\n",
      "451:\ttotal: 1m 45s\tremaining: 11.2s\n",
      "452:\ttotal: 1m 45s\tremaining: 10.9s\n",
      "453:\ttotal: 1m 45s\tremaining: 10.7s\n",
      "454:\ttotal: 1m 46s\tremaining: 10.5s\n",
      "455:\ttotal: 1m 46s\tremaining: 10.3s\n",
      "456:\ttotal: 1m 46s\tremaining: 10s\n",
      "457:\ttotal: 1m 46s\tremaining: 9.8s\n",
      "458:\ttotal: 1m 47s\tremaining: 9.57s\n",
      "459:\ttotal: 1m 47s\tremaining: 9.35s\n",
      "460:\ttotal: 1m 47s\tremaining: 9.11s\n",
      "461:\ttotal: 1m 48s\tremaining: 8.89s\n",
      "462:\ttotal: 1m 48s\tremaining: 8.65s\n",
      "463:\ttotal: 1m 48s\tremaining: 8.43s\n",
      "464:\ttotal: 1m 48s\tremaining: 8.2s\n",
      "465:\ttotal: 1m 49s\tremaining: 7.97s\n",
      "466:\ttotal: 1m 49s\tremaining: 7.74s\n",
      "467:\ttotal: 1m 49s\tremaining: 7.5s\n",
      "468:\ttotal: 1m 50s\tremaining: 7.27s\n",
      "469:\ttotal: 1m 50s\tremaining: 7.04s\n",
      "470:\ttotal: 1m 50s\tremaining: 6.81s\n",
      "471:\ttotal: 1m 50s\tremaining: 6.58s\n",
      "472:\ttotal: 1m 51s\tremaining: 6.35s\n",
      "473:\ttotal: 1m 51s\tremaining: 6.12s\n",
      "474:\ttotal: 1m 51s\tremaining: 5.88s\n",
      "475:\ttotal: 1m 51s\tremaining: 5.64s\n",
      "476:\ttotal: 1m 52s\tremaining: 5.41s\n",
      "477:\ttotal: 1m 52s\tremaining: 5.18s\n",
      "478:\ttotal: 1m 52s\tremaining: 4.94s\n",
      "479:\ttotal: 1m 52s\tremaining: 4.71s\n",
      "480:\ttotal: 1m 53s\tremaining: 4.47s\n",
      "481:\ttotal: 1m 53s\tremaining: 4.24s\n",
      "482:\ttotal: 1m 53s\tremaining: 4s\n",
      "483:\ttotal: 1m 53s\tremaining: 3.76s\n",
      "484:\ttotal: 1m 54s\tremaining: 3.53s\n",
      "485:\ttotal: 1m 54s\tremaining: 3.29s\n",
      "486:\ttotal: 1m 54s\tremaining: 3.06s\n",
      "487:\ttotal: 1m 54s\tremaining: 2.82s\n",
      "488:\ttotal: 1m 55s\tremaining: 2.59s\n",
      "489:\ttotal: 1m 55s\tremaining: 2.35s\n",
      "490:\ttotal: 1m 55s\tremaining: 2.12s\n",
      "491:\ttotal: 1m 55s\tremaining: 1.88s\n",
      "492:\ttotal: 1m 56s\tremaining: 1.65s\n",
      "493:\ttotal: 1m 56s\tremaining: 1.41s\n",
      "494:\ttotal: 1m 56s\tremaining: 1.18s\n",
      "495:\ttotal: 1m 56s\tremaining: 942ms\n",
      "496:\ttotal: 1m 57s\tremaining: 707ms\n",
      "497:\ttotal: 1m 57s\tremaining: 471ms\n",
      "498:\ttotal: 1m 57s\tremaining: 236ms\n",
      "499:\ttotal: 1m 57s\tremaining: 0us\n",
      "0:\ttotal: 328ms\tremaining: 2m 43s\n",
      "1:\ttotal: 646ms\tremaining: 2m 40s\n",
      "2:\ttotal: 870ms\tremaining: 2m 24s\n",
      "3:\ttotal: 1.11s\tremaining: 2m 17s\n",
      "4:\ttotal: 1.34s\tremaining: 2m 12s\n",
      "5:\ttotal: 1.56s\tremaining: 2m 8s\n",
      "6:\ttotal: 1.79s\tremaining: 2m 6s\n",
      "7:\ttotal: 2.02s\tremaining: 2m 4s\n",
      "8:\ttotal: 2.26s\tremaining: 2m 3s\n",
      "9:\ttotal: 2.52s\tremaining: 2m 3s\n",
      "10:\ttotal: 2.75s\tremaining: 2m 2s\n",
      "11:\ttotal: 3.01s\tremaining: 2m 2s\n",
      "12:\ttotal: 3.28s\tremaining: 2m 2s\n",
      "13:\ttotal: 3.51s\tremaining: 2m 2s\n",
      "14:\ttotal: 3.75s\tremaining: 2m 1s\n",
      "15:\ttotal: 3.97s\tremaining: 2m\n",
      "16:\ttotal: 4.21s\tremaining: 1m 59s\n",
      "17:\ttotal: 4.44s\tremaining: 1m 58s\n",
      "18:\ttotal: 4.67s\tremaining: 1m 58s\n",
      "19:\ttotal: 4.94s\tremaining: 1m 58s\n",
      "20:\ttotal: 5.29s\tremaining: 2m\n",
      "21:\ttotal: 5.65s\tremaining: 2m 2s\n",
      "22:\ttotal: 6.02s\tremaining: 2m 4s\n",
      "23:\ttotal: 6.36s\tremaining: 2m 6s\n",
      "24:\ttotal: 6.67s\tremaining: 2m 6s\n",
      "25:\ttotal: 6.69s\tremaining: 2m 1s\n",
      "26:\ttotal: 7s\tremaining: 2m 2s\n",
      "27:\ttotal: 7.34s\tremaining: 2m 3s\n",
      "28:\ttotal: 7.65s\tremaining: 2m 4s\n",
      "29:\ttotal: 7.99s\tremaining: 2m 5s\n",
      "30:\ttotal: 8.29s\tremaining: 2m 5s\n",
      "31:\ttotal: 8.63s\tremaining: 2m 6s\n",
      "32:\ttotal: 9.01s\tremaining: 2m 7s\n",
      "33:\ttotal: 9.34s\tremaining: 2m 7s\n",
      "34:\ttotal: 9.66s\tremaining: 2m 8s\n",
      "35:\ttotal: 9.97s\tremaining: 2m 8s\n",
      "36:\ttotal: 10.3s\tremaining: 2m 8s\n",
      "37:\ttotal: 10.5s\tremaining: 2m 8s\n",
      "38:\ttotal: 10.9s\tremaining: 2m 8s\n",
      "39:\ttotal: 11.1s\tremaining: 2m 7s\n",
      "40:\ttotal: 11.3s\tremaining: 2m 7s\n",
      "41:\ttotal: 11.6s\tremaining: 2m 6s\n",
      "42:\ttotal: 11.8s\tremaining: 2m 5s\n",
      "43:\ttotal: 12.1s\tremaining: 2m 4s\n",
      "44:\ttotal: 12.3s\tremaining: 2m 4s\n",
      "45:\ttotal: 12.6s\tremaining: 2m 3s\n",
      "46:\ttotal: 12.9s\tremaining: 2m 4s\n",
      "47:\ttotal: 13.1s\tremaining: 2m 3s\n",
      "48:\ttotal: 13.4s\tremaining: 2m 3s\n",
      "49:\ttotal: 13.7s\tremaining: 2m 2s\n",
      "50:\ttotal: 13.9s\tremaining: 2m 2s\n",
      "51:\ttotal: 14.1s\tremaining: 2m 1s\n",
      "52:\ttotal: 14.4s\tremaining: 2m 1s\n",
      "53:\ttotal: 14.6s\tremaining: 2m\n",
      "54:\ttotal: 14.8s\tremaining: 2m\n",
      "55:\ttotal: 15s\tremaining: 1m 59s\n",
      "56:\ttotal: 15.3s\tremaining: 1m 58s\n",
      "57:\ttotal: 15.5s\tremaining: 1m 58s\n",
      "58:\ttotal: 15.9s\tremaining: 1m 58s\n",
      "59:\ttotal: 16.1s\tremaining: 1m 58s\n",
      "60:\ttotal: 16.3s\tremaining: 1m 57s\n",
      "61:\ttotal: 16.5s\tremaining: 1m 56s\n",
      "62:\ttotal: 16.7s\tremaining: 1m 56s\n",
      "63:\ttotal: 16.9s\tremaining: 1m 55s\n",
      "64:\ttotal: 17.2s\tremaining: 1m 54s\n",
      "65:\ttotal: 17.4s\tremaining: 1m 54s\n",
      "66:\ttotal: 17.6s\tremaining: 1m 53s\n",
      "67:\ttotal: 17.8s\tremaining: 1m 52s\n",
      "68:\ttotal: 18s\tremaining: 1m 52s\n",
      "69:\ttotal: 18.2s\tremaining: 1m 51s\n",
      "70:\ttotal: 18.4s\tremaining: 1m 51s\n",
      "71:\ttotal: 18.7s\tremaining: 1m 51s\n",
      "72:\ttotal: 19s\tremaining: 1m 50s\n",
      "73:\ttotal: 19.2s\tremaining: 1m 50s\n",
      "74:\ttotal: 19.4s\tremaining: 1m 49s\n",
      "75:\ttotal: 19.6s\tremaining: 1m 49s\n",
      "76:\ttotal: 19.8s\tremaining: 1m 48s\n",
      "77:\ttotal: 20s\tremaining: 1m 48s\n",
      "78:\ttotal: 20.2s\tremaining: 1m 47s\n",
      "79:\ttotal: 20.4s\tremaining: 1m 47s\n",
      "80:\ttotal: 20.6s\tremaining: 1m 46s\n",
      "81:\ttotal: 20.8s\tremaining: 1m 46s\n",
      "82:\ttotal: 21.1s\tremaining: 1m 45s\n",
      "83:\ttotal: 21.3s\tremaining: 1m 45s\n",
      "84:\ttotal: 21.5s\tremaining: 1m 44s\n",
      "85:\ttotal: 21.7s\tremaining: 1m 44s\n",
      "86:\ttotal: 21.9s\tremaining: 1m 44s\n",
      "87:\ttotal: 22.2s\tremaining: 1m 43s\n",
      "88:\ttotal: 22.4s\tremaining: 1m 43s\n",
      "89:\ttotal: 22.7s\tremaining: 1m 43s\n",
      "90:\ttotal: 23s\tremaining: 1m 43s\n",
      "91:\ttotal: 23.2s\tremaining: 1m 42s\n",
      "92:\ttotal: 23.4s\tremaining: 1m 42s\n",
      "93:\ttotal: 23.6s\tremaining: 1m 41s\n",
      "94:\ttotal: 23.8s\tremaining: 1m 41s\n",
      "95:\ttotal: 24s\tremaining: 1m 40s\n",
      "96:\ttotal: 24.2s\tremaining: 1m 40s\n",
      "97:\ttotal: 24.4s\tremaining: 1m 40s\n",
      "98:\ttotal: 24.6s\tremaining: 1m 39s\n",
      "99:\ttotal: 24.8s\tremaining: 1m 39s\n",
      "100:\ttotal: 25s\tremaining: 1m 38s\n",
      "101:\ttotal: 25.2s\tremaining: 1m 38s\n",
      "102:\ttotal: 25.4s\tremaining: 1m 38s\n",
      "103:\ttotal: 25.6s\tremaining: 1m 37s\n",
      "104:\ttotal: 25.9s\tremaining: 1m 37s\n",
      "105:\ttotal: 26.1s\tremaining: 1m 36s\n",
      "106:\ttotal: 26.3s\tremaining: 1m 36s\n",
      "107:\ttotal: 26.5s\tremaining: 1m 36s\n",
      "108:\ttotal: 26.7s\tremaining: 1m 35s\n",
      "109:\ttotal: 26.9s\tremaining: 1m 35s\n",
      "110:\ttotal: 27.1s\tremaining: 1m 34s\n",
      "111:\ttotal: 27.3s\tremaining: 1m 34s\n",
      "112:\ttotal: 27.5s\tremaining: 1m 34s\n",
      "113:\ttotal: 27.7s\tremaining: 1m 33s\n",
      "114:\ttotal: 27.9s\tremaining: 1m 33s\n",
      "115:\ttotal: 28.1s\tremaining: 1m 33s\n",
      "116:\ttotal: 28.3s\tremaining: 1m 32s\n",
      "117:\ttotal: 28.5s\tremaining: 1m 32s\n",
      "118:\ttotal: 28.7s\tremaining: 1m 31s\n",
      "119:\ttotal: 28.9s\tremaining: 1m 31s\n",
      "120:\ttotal: 29.2s\tremaining: 1m 31s\n",
      "121:\ttotal: 29.5s\tremaining: 1m 31s\n",
      "122:\ttotal: 29.7s\tremaining: 1m 30s\n",
      "123:\ttotal: 29.9s\tremaining: 1m 30s\n",
      "124:\ttotal: 30.1s\tremaining: 1m 30s\n",
      "125:\ttotal: 30.3s\tremaining: 1m 29s\n",
      "126:\ttotal: 30.5s\tremaining: 1m 29s\n",
      "127:\ttotal: 30.7s\tremaining: 1m 29s\n",
      "128:\ttotal: 30.9s\tremaining: 1m 28s\n",
      "129:\ttotal: 31.1s\tremaining: 1m 28s\n",
      "130:\ttotal: 31.4s\tremaining: 1m 28s\n",
      "131:\ttotal: 31.6s\tremaining: 1m 28s\n",
      "132:\ttotal: 31.8s\tremaining: 1m 27s\n",
      "133:\ttotal: 32s\tremaining: 1m 27s\n",
      "134:\ttotal: 32.2s\tremaining: 1m 27s\n",
      "135:\ttotal: 32.4s\tremaining: 1m 26s\n",
      "136:\ttotal: 32.7s\tremaining: 1m 26s\n",
      "137:\ttotal: 32.9s\tremaining: 1m 26s\n",
      "138:\ttotal: 33.1s\tremaining: 1m 25s\n",
      "139:\ttotal: 33.3s\tremaining: 1m 25s\n",
      "140:\ttotal: 33.6s\tremaining: 1m 25s\n",
      "141:\ttotal: 33.8s\tremaining: 1m 25s\n",
      "142:\ttotal: 34s\tremaining: 1m 24s\n",
      "143:\ttotal: 34.2s\tremaining: 1m 24s\n",
      "144:\ttotal: 34.5s\tremaining: 1m 24s\n",
      "145:\ttotal: 34.7s\tremaining: 1m 24s\n",
      "146:\ttotal: 35s\tremaining: 1m 23s\n",
      "147:\ttotal: 35.2s\tremaining: 1m 23s\n",
      "148:\ttotal: 35.4s\tremaining: 1m 23s\n",
      "149:\ttotal: 35.7s\tremaining: 1m 23s\n",
      "150:\ttotal: 35.9s\tremaining: 1m 22s\n",
      "151:\ttotal: 36.1s\tremaining: 1m 22s\n",
      "152:\ttotal: 36.4s\tremaining: 1m 22s\n",
      "153:\ttotal: 36.6s\tremaining: 1m 22s\n",
      "154:\ttotal: 36.8s\tremaining: 1m 22s\n",
      "155:\ttotal: 37.1s\tremaining: 1m 21s\n",
      "156:\ttotal: 37.3s\tremaining: 1m 21s\n",
      "157:\ttotal: 37.5s\tremaining: 1m 21s\n",
      "158:\ttotal: 37.7s\tremaining: 1m 20s\n",
      "159:\ttotal: 37.9s\tremaining: 1m 20s\n",
      "160:\ttotal: 38.1s\tremaining: 1m 20s\n",
      "161:\ttotal: 38.3s\tremaining: 1m 19s\n",
      "162:\ttotal: 38.5s\tremaining: 1m 19s\n",
      "163:\ttotal: 38.8s\tremaining: 1m 19s\n",
      "164:\ttotal: 39s\tremaining: 1m 19s\n",
      "165:\ttotal: 39.2s\tremaining: 1m 18s\n",
      "166:\ttotal: 39.4s\tremaining: 1m 18s\n",
      "167:\ttotal: 39.7s\tremaining: 1m 18s\n",
      "168:\ttotal: 40s\tremaining: 1m 18s\n",
      "169:\ttotal: 40.2s\tremaining: 1m 17s\n",
      "170:\ttotal: 40.4s\tremaining: 1m 17s\n",
      "171:\ttotal: 40.6s\tremaining: 1m 17s\n",
      "172:\ttotal: 40.8s\tremaining: 1m 17s\n",
      "173:\ttotal: 41s\tremaining: 1m 16s\n",
      "174:\ttotal: 41.2s\tremaining: 1m 16s\n",
      "175:\ttotal: 41.5s\tremaining: 1m 16s\n",
      "176:\ttotal: 41.7s\tremaining: 1m 16s\n",
      "177:\ttotal: 41.9s\tremaining: 1m 15s\n",
      "178:\ttotal: 42.1s\tremaining: 1m 15s\n",
      "179:\ttotal: 42.3s\tremaining: 1m 15s\n",
      "180:\ttotal: 42.5s\tremaining: 1m 14s\n",
      "181:\ttotal: 42.8s\tremaining: 1m 14s\n",
      "182:\ttotal: 43s\tremaining: 1m 14s\n",
      "183:\ttotal: 43.2s\tremaining: 1m 14s\n",
      "184:\ttotal: 43.4s\tremaining: 1m 13s\n",
      "185:\ttotal: 43.6s\tremaining: 1m 13s\n",
      "186:\ttotal: 43.8s\tremaining: 1m 13s\n",
      "187:\ttotal: 44s\tremaining: 1m 13s\n",
      "188:\ttotal: 44.2s\tremaining: 1m 12s\n",
      "189:\ttotal: 44.5s\tremaining: 1m 12s\n",
      "190:\ttotal: 44.7s\tremaining: 1m 12s\n",
      "191:\ttotal: 44.9s\tremaining: 1m 11s\n",
      "192:\ttotal: 45.1s\tremaining: 1m 11s\n",
      "193:\ttotal: 45.3s\tremaining: 1m 11s\n",
      "194:\ttotal: 45.5s\tremaining: 1m 11s\n",
      "195:\ttotal: 45.7s\tremaining: 1m 10s\n",
      "196:\ttotal: 45.9s\tremaining: 1m 10s\n",
      "197:\ttotal: 46.1s\tremaining: 1m 10s\n",
      "198:\ttotal: 46.4s\tremaining: 1m 10s\n",
      "199:\ttotal: 46.6s\tremaining: 1m 9s\n",
      "200:\ttotal: 46.8s\tremaining: 1m 9s\n",
      "201:\ttotal: 47s\tremaining: 1m 9s\n",
      "202:\ttotal: 47.3s\tremaining: 1m 9s\n",
      "203:\ttotal: 47.6s\tremaining: 1m 9s\n",
      "204:\ttotal: 47.8s\tremaining: 1m 8s\n",
      "205:\ttotal: 48s\tremaining: 1m 8s\n",
      "206:\ttotal: 48.2s\tremaining: 1m 8s\n",
      "207:\ttotal: 48.5s\tremaining: 1m 8s\n",
      "208:\ttotal: 48.7s\tremaining: 1m 7s\n",
      "209:\ttotal: 48.9s\tremaining: 1m 7s\n",
      "210:\ttotal: 49.1s\tremaining: 1m 7s\n",
      "211:\ttotal: 49.4s\tremaining: 1m 7s\n",
      "212:\ttotal: 49.6s\tremaining: 1m 6s\n",
      "213:\ttotal: 49.8s\tremaining: 1m 6s\n",
      "214:\ttotal: 50s\tremaining: 1m 6s\n",
      "215:\ttotal: 50.3s\tremaining: 1m 6s\n",
      "216:\ttotal: 50.5s\tremaining: 1m 5s\n",
      "217:\ttotal: 50.7s\tremaining: 1m 5s\n",
      "218:\ttotal: 50.9s\tremaining: 1m 5s\n",
      "219:\ttotal: 51.1s\tremaining: 1m 5s\n",
      "220:\ttotal: 51.4s\tremaining: 1m 4s\n",
      "221:\ttotal: 51.6s\tremaining: 1m 4s\n",
      "222:\ttotal: 51.8s\tremaining: 1m 4s\n",
      "223:\ttotal: 52s\tremaining: 1m 4s\n",
      "224:\ttotal: 52.2s\tremaining: 1m 3s\n",
      "225:\ttotal: 52.4s\tremaining: 1m 3s\n",
      "226:\ttotal: 52.7s\tremaining: 1m 3s\n",
      "227:\ttotal: 52.9s\tremaining: 1m 3s\n",
      "228:\ttotal: 53.1s\tremaining: 1m 2s\n",
      "229:\ttotal: 53.3s\tremaining: 1m 2s\n",
      "230:\ttotal: 53.5s\tremaining: 1m 2s\n",
      "231:\ttotal: 53.7s\tremaining: 1m 2s\n",
      "232:\ttotal: 54s\tremaining: 1m 1s\n",
      "233:\ttotal: 54.2s\tremaining: 1m 1s\n",
      "234:\ttotal: 54.4s\tremaining: 1m 1s\n",
      "235:\ttotal: 54.6s\tremaining: 1m 1s\n",
      "236:\ttotal: 54.8s\tremaining: 1m\n",
      "237:\ttotal: 55s\tremaining: 1m\n",
      "238:\ttotal: 55.2s\tremaining: 1m\n",
      "239:\ttotal: 55.5s\tremaining: 1m\n",
      "240:\ttotal: 55.7s\tremaining: 59.8s\n",
      "241:\ttotal: 55.9s\tremaining: 59.6s\n",
      "242:\ttotal: 56.1s\tremaining: 59.3s\n",
      "243:\ttotal: 56.3s\tremaining: 59.1s\n",
      "244:\ttotal: 56.5s\tremaining: 58.8s\n",
      "245:\ttotal: 56.8s\tremaining: 58.6s\n",
      "246:\ttotal: 57s\tremaining: 58.4s\n",
      "247:\ttotal: 57.2s\tremaining: 58.1s\n",
      "248:\ttotal: 57.4s\tremaining: 57.9s\n",
      "249:\ttotal: 57.6s\tremaining: 57.6s\n",
      "250:\ttotal: 57.9s\tremaining: 57.4s\n",
      "251:\ttotal: 58.1s\tremaining: 57.1s\n",
      "252:\ttotal: 58.3s\tremaining: 56.9s\n",
      "253:\ttotal: 58.5s\tremaining: 56.6s\n",
      "254:\ttotal: 58.7s\tremaining: 56.4s\n",
      "255:\ttotal: 58.9s\tremaining: 56.1s\n",
      "256:\ttotal: 59.1s\tremaining: 55.9s\n",
      "257:\ttotal: 59.3s\tremaining: 55.6s\n",
      "258:\ttotal: 59.5s\tremaining: 55.4s\n",
      "259:\ttotal: 59.7s\tremaining: 55.1s\n",
      "260:\ttotal: 59.9s\tremaining: 54.9s\n",
      "261:\ttotal: 1m\tremaining: 54.6s\n",
      "262:\ttotal: 1m\tremaining: 54.4s\n",
      "263:\ttotal: 1m\tremaining: 54.1s\n",
      "264:\ttotal: 1m\tremaining: 53.9s\n",
      "265:\ttotal: 1m\tremaining: 53.6s\n",
      "266:\ttotal: 1m 1s\tremaining: 53.4s\n",
      "267:\ttotal: 1m 1s\tremaining: 53.1s\n",
      "268:\ttotal: 1m 1s\tremaining: 52.9s\n",
      "269:\ttotal: 1m 1s\tremaining: 52.6s\n",
      "270:\ttotal: 1m 1s\tremaining: 52.4s\n",
      "271:\ttotal: 1m 2s\tremaining: 52.1s\n",
      "272:\ttotal: 1m 2s\tremaining: 51.9s\n",
      "273:\ttotal: 1m 2s\tremaining: 51.6s\n",
      "274:\ttotal: 1m 2s\tremaining: 51.4s\n",
      "275:\ttotal: 1m 3s\tremaining: 51.1s\n",
      "276:\ttotal: 1m 3s\tremaining: 50.9s\n",
      "277:\ttotal: 1m 3s\tremaining: 50.6s\n",
      "278:\ttotal: 1m 3s\tremaining: 50.4s\n",
      "279:\ttotal: 1m 3s\tremaining: 50.1s\n",
      "280:\ttotal: 1m 4s\tremaining: 49.9s\n",
      "281:\ttotal: 1m 4s\tremaining: 49.7s\n",
      "282:\ttotal: 1m 4s\tremaining: 49.4s\n",
      "283:\ttotal: 1m 4s\tremaining: 49.2s\n",
      "284:\ttotal: 1m 4s\tremaining: 48.9s\n",
      "285:\ttotal: 1m 5s\tremaining: 48.7s\n",
      "286:\ttotal: 1m 5s\tremaining: 48.5s\n",
      "287:\ttotal: 1m 5s\tremaining: 48.2s\n",
      "288:\ttotal: 1m 5s\tremaining: 48s\n",
      "289:\ttotal: 1m 5s\tremaining: 47.7s\n",
      "290:\ttotal: 1m 6s\tremaining: 47.5s\n",
      "291:\ttotal: 1m 6s\tremaining: 47.2s\n",
      "292:\ttotal: 1m 6s\tremaining: 47s\n",
      "293:\ttotal: 1m 6s\tremaining: 46.8s\n",
      "294:\ttotal: 1m 6s\tremaining: 46.5s\n",
      "295:\ttotal: 1m 7s\tremaining: 46.3s\n",
      "296:\ttotal: 1m 7s\tremaining: 46s\n",
      "297:\ttotal: 1m 7s\tremaining: 45.8s\n",
      "298:\ttotal: 1m 7s\tremaining: 45.5s\n",
      "299:\ttotal: 1m 7s\tremaining: 45.3s\n",
      "300:\ttotal: 1m 8s\tremaining: 45.1s\n",
      "301:\ttotal: 1m 8s\tremaining: 44.8s\n",
      "302:\ttotal: 1m 8s\tremaining: 44.6s\n",
      "303:\ttotal: 1m 8s\tremaining: 44.3s\n",
      "304:\ttotal: 1m 8s\tremaining: 44.1s\n",
      "305:\ttotal: 1m 9s\tremaining: 43.8s\n",
      "306:\ttotal: 1m 9s\tremaining: 43.6s\n",
      "307:\ttotal: 1m 9s\tremaining: 43.4s\n",
      "308:\ttotal: 1m 9s\tremaining: 43.1s\n",
      "309:\ttotal: 1m 9s\tremaining: 42.9s\n",
      "310:\ttotal: 1m 10s\tremaining: 42.7s\n",
      "311:\ttotal: 1m 10s\tremaining: 42.4s\n",
      "312:\ttotal: 1m 10s\tremaining: 42.2s\n",
      "313:\ttotal: 1m 10s\tremaining: 41.9s\n",
      "314:\ttotal: 1m 11s\tremaining: 41.7s\n",
      "315:\ttotal: 1m 11s\tremaining: 41.5s\n",
      "316:\ttotal: 1m 11s\tremaining: 41.2s\n",
      "317:\ttotal: 1m 11s\tremaining: 41s\n",
      "318:\ttotal: 1m 11s\tremaining: 40.8s\n",
      "319:\ttotal: 1m 12s\tremaining: 40.5s\n",
      "320:\ttotal: 1m 12s\tremaining: 40.3s\n",
      "321:\ttotal: 1m 12s\tremaining: 40s\n",
      "322:\ttotal: 1m 12s\tremaining: 39.8s\n",
      "323:\ttotal: 1m 12s\tremaining: 39.6s\n",
      "324:\ttotal: 1m 13s\tremaining: 39.3s\n",
      "325:\ttotal: 1m 13s\tremaining: 39.1s\n",
      "326:\ttotal: 1m 13s\tremaining: 38.9s\n",
      "327:\ttotal: 1m 13s\tremaining: 38.6s\n",
      "328:\ttotal: 1m 13s\tremaining: 38.4s\n",
      "329:\ttotal: 1m 14s\tremaining: 38.2s\n",
      "330:\ttotal: 1m 14s\tremaining: 37.9s\n",
      "331:\ttotal: 1m 14s\tremaining: 37.7s\n",
      "332:\ttotal: 1m 14s\tremaining: 37.5s\n",
      "333:\ttotal: 1m 14s\tremaining: 37.2s\n",
      "334:\ttotal: 1m 15s\tremaining: 37s\n",
      "335:\ttotal: 1m 15s\tremaining: 36.8s\n",
      "336:\ttotal: 1m 15s\tremaining: 36.5s\n",
      "337:\ttotal: 1m 15s\tremaining: 36.3s\n",
      "338:\ttotal: 1m 15s\tremaining: 36.1s\n",
      "339:\ttotal: 1m 16s\tremaining: 35.8s\n",
      "340:\ttotal: 1m 16s\tremaining: 35.6s\n",
      "341:\ttotal: 1m 16s\tremaining: 35.4s\n",
      "342:\ttotal: 1m 16s\tremaining: 35.1s\n",
      "343:\ttotal: 1m 16s\tremaining: 34.9s\n",
      "344:\ttotal: 1m 17s\tremaining: 34.7s\n",
      "345:\ttotal: 1m 17s\tremaining: 34.5s\n",
      "346:\ttotal: 1m 17s\tremaining: 34.2s\n",
      "347:\ttotal: 1m 17s\tremaining: 34s\n",
      "348:\ttotal: 1m 18s\tremaining: 33.8s\n",
      "349:\ttotal: 1m 18s\tremaining: 33.5s\n",
      "350:\ttotal: 1m 18s\tremaining: 33.3s\n",
      "351:\ttotal: 1m 18s\tremaining: 33.1s\n",
      "352:\ttotal: 1m 18s\tremaining: 32.8s\n",
      "353:\ttotal: 1m 19s\tremaining: 32.6s\n",
      "354:\ttotal: 1m 19s\tremaining: 32.4s\n",
      "355:\ttotal: 1m 19s\tremaining: 32.1s\n",
      "356:\ttotal: 1m 19s\tremaining: 31.9s\n",
      "357:\ttotal: 1m 19s\tremaining: 31.7s\n",
      "358:\ttotal: 1m 20s\tremaining: 31.5s\n",
      "359:\ttotal: 1m 20s\tremaining: 31.2s\n",
      "360:\ttotal: 1m 20s\tremaining: 31s\n",
      "361:\ttotal: 1m 20s\tremaining: 30.8s\n",
      "362:\ttotal: 1m 20s\tremaining: 30.5s\n",
      "363:\ttotal: 1m 21s\tremaining: 30.3s\n",
      "364:\ttotal: 1m 21s\tremaining: 30.1s\n",
      "365:\ttotal: 1m 21s\tremaining: 29.8s\n",
      "366:\ttotal: 1m 21s\tremaining: 29.6s\n",
      "367:\ttotal: 1m 21s\tremaining: 29.4s\n",
      "368:\ttotal: 1m 22s\tremaining: 29.2s\n",
      "369:\ttotal: 1m 22s\tremaining: 28.9s\n",
      "370:\ttotal: 1m 22s\tremaining: 28.7s\n",
      "371:\ttotal: 1m 22s\tremaining: 28.5s\n",
      "372:\ttotal: 1m 22s\tremaining: 28.2s\n",
      "373:\ttotal: 1m 23s\tremaining: 28s\n",
      "374:\ttotal: 1m 23s\tremaining: 27.8s\n",
      "375:\ttotal: 1m 23s\tremaining: 27.6s\n",
      "376:\ttotal: 1m 23s\tremaining: 27.3s\n",
      "377:\ttotal: 1m 23s\tremaining: 27.1s\n",
      "378:\ttotal: 1m 24s\tremaining: 26.9s\n",
      "379:\ttotal: 1m 24s\tremaining: 26.6s\n",
      "380:\ttotal: 1m 24s\tremaining: 26.4s\n",
      "381:\ttotal: 1m 24s\tremaining: 26.2s\n",
      "382:\ttotal: 1m 24s\tremaining: 26s\n",
      "383:\ttotal: 1m 25s\tremaining: 25.7s\n",
      "384:\ttotal: 1m 25s\tremaining: 25.5s\n",
      "385:\ttotal: 1m 25s\tremaining: 25.3s\n",
      "386:\ttotal: 1m 25s\tremaining: 25.1s\n",
      "387:\ttotal: 1m 26s\tremaining: 24.8s\n",
      "388:\ttotal: 1m 26s\tremaining: 24.6s\n",
      "389:\ttotal: 1m 26s\tremaining: 24.4s\n",
      "390:\ttotal: 1m 26s\tremaining: 24.1s\n",
      "391:\ttotal: 1m 26s\tremaining: 23.9s\n",
      "392:\ttotal: 1m 27s\tremaining: 23.7s\n",
      "393:\ttotal: 1m 27s\tremaining: 23.5s\n",
      "394:\ttotal: 1m 27s\tremaining: 23.2s\n",
      "395:\ttotal: 1m 27s\tremaining: 23s\n",
      "396:\ttotal: 1m 27s\tremaining: 22.8s\n",
      "397:\ttotal: 1m 28s\tremaining: 22.6s\n",
      "398:\ttotal: 1m 28s\tremaining: 22.3s\n",
      "399:\ttotal: 1m 28s\tremaining: 22.1s\n",
      "400:\ttotal: 1m 28s\tremaining: 21.9s\n",
      "401:\ttotal: 1m 28s\tremaining: 21.7s\n",
      "402:\ttotal: 1m 29s\tremaining: 21.4s\n",
      "403:\ttotal: 1m 29s\tremaining: 21.2s\n",
      "404:\ttotal: 1m 29s\tremaining: 21s\n",
      "405:\ttotal: 1m 29s\tremaining: 20.8s\n",
      "406:\ttotal: 1m 29s\tremaining: 20.5s\n",
      "407:\ttotal: 1m 30s\tremaining: 20.3s\n",
      "408:\ttotal: 1m 30s\tremaining: 20.1s\n",
      "409:\ttotal: 1m 30s\tremaining: 19.9s\n",
      "410:\ttotal: 1m 30s\tremaining: 19.6s\n",
      "411:\ttotal: 1m 30s\tremaining: 19.4s\n",
      "412:\ttotal: 1m 31s\tremaining: 19.2s\n",
      "413:\ttotal: 1m 31s\tremaining: 19s\n",
      "414:\ttotal: 1m 31s\tremaining: 18.7s\n",
      "415:\ttotal: 1m 31s\tremaining: 18.5s\n",
      "416:\ttotal: 1m 31s\tremaining: 18.3s\n",
      "417:\ttotal: 1m 32s\tremaining: 18.1s\n",
      "418:\ttotal: 1m 32s\tremaining: 17.9s\n",
      "419:\ttotal: 1m 32s\tremaining: 17.6s\n",
      "420:\ttotal: 1m 32s\tremaining: 17.4s\n",
      "421:\ttotal: 1m 32s\tremaining: 17.2s\n",
      "422:\ttotal: 1m 33s\tremaining: 17s\n",
      "423:\ttotal: 1m 33s\tremaining: 16.7s\n",
      "424:\ttotal: 1m 33s\tremaining: 16.5s\n",
      "425:\ttotal: 1m 33s\tremaining: 16.3s\n",
      "426:\ttotal: 1m 33s\tremaining: 16.1s\n",
      "427:\ttotal: 1m 34s\tremaining: 15.8s\n",
      "428:\ttotal: 1m 34s\tremaining: 15.6s\n",
      "429:\ttotal: 1m 34s\tremaining: 15.4s\n",
      "430:\ttotal: 1m 34s\tremaining: 15.2s\n",
      "431:\ttotal: 1m 35s\tremaining: 15s\n",
      "432:\ttotal: 1m 35s\tremaining: 14.7s\n",
      "433:\ttotal: 1m 35s\tremaining: 14.5s\n",
      "434:\ttotal: 1m 35s\tremaining: 14.3s\n",
      "435:\ttotal: 1m 35s\tremaining: 14.1s\n",
      "436:\ttotal: 1m 36s\tremaining: 13.8s\n",
      "437:\ttotal: 1m 36s\tremaining: 13.6s\n",
      "438:\ttotal: 1m 36s\tremaining: 13.4s\n",
      "439:\ttotal: 1m 36s\tremaining: 13.2s\n",
      "440:\ttotal: 1m 36s\tremaining: 13s\n",
      "441:\ttotal: 1m 37s\tremaining: 12.7s\n",
      "442:\ttotal: 1m 37s\tremaining: 12.5s\n",
      "443:\ttotal: 1m 37s\tremaining: 12.3s\n",
      "444:\ttotal: 1m 37s\tremaining: 12.1s\n",
      "445:\ttotal: 1m 37s\tremaining: 11.8s\n",
      "446:\ttotal: 1m 38s\tremaining: 11.6s\n",
      "447:\ttotal: 1m 38s\tremaining: 11.4s\n",
      "448:\ttotal: 1m 38s\tremaining: 11.2s\n",
      "449:\ttotal: 1m 38s\tremaining: 11s\n",
      "450:\ttotal: 1m 38s\tremaining: 10.7s\n",
      "451:\ttotal: 1m 39s\tremaining: 10.5s\n",
      "452:\ttotal: 1m 39s\tremaining: 10.3s\n",
      "453:\ttotal: 1m 39s\tremaining: 10.1s\n",
      "454:\ttotal: 1m 39s\tremaining: 9.86s\n",
      "455:\ttotal: 1m 39s\tremaining: 9.64s\n",
      "456:\ttotal: 1m 40s\tremaining: 9.42s\n",
      "457:\ttotal: 1m 40s\tremaining: 9.2s\n",
      "458:\ttotal: 1m 40s\tremaining: 8.98s\n",
      "459:\ttotal: 1m 40s\tremaining: 8.76s\n",
      "460:\ttotal: 1m 40s\tremaining: 8.54s\n",
      "461:\ttotal: 1m 41s\tremaining: 8.32s\n",
      "462:\ttotal: 1m 41s\tremaining: 8.1s\n",
      "463:\ttotal: 1m 41s\tremaining: 7.88s\n",
      "464:\ttotal: 1m 41s\tremaining: 7.66s\n",
      "465:\ttotal: 1m 42s\tremaining: 7.44s\n",
      "466:\ttotal: 1m 42s\tremaining: 7.22s\n",
      "467:\ttotal: 1m 42s\tremaining: 7s\n",
      "468:\ttotal: 1m 42s\tremaining: 6.78s\n",
      "469:\ttotal: 1m 42s\tremaining: 6.57s\n",
      "470:\ttotal: 1m 43s\tremaining: 6.35s\n",
      "471:\ttotal: 1m 43s\tremaining: 6.13s\n",
      "472:\ttotal: 1m 43s\tremaining: 5.91s\n",
      "473:\ttotal: 1m 43s\tremaining: 5.69s\n",
      "474:\ttotal: 1m 43s\tremaining: 5.47s\n",
      "475:\ttotal: 1m 44s\tremaining: 5.25s\n",
      "476:\ttotal: 1m 44s\tremaining: 5.03s\n",
      "477:\ttotal: 1m 44s\tremaining: 4.81s\n",
      "478:\ttotal: 1m 44s\tremaining: 4.59s\n",
      "479:\ttotal: 1m 44s\tremaining: 4.37s\n",
      "480:\ttotal: 1m 45s\tremaining: 4.16s\n",
      "481:\ttotal: 1m 45s\tremaining: 3.94s\n",
      "482:\ttotal: 1m 45s\tremaining: 3.72s\n",
      "483:\ttotal: 1m 45s\tremaining: 3.5s\n",
      "484:\ttotal: 1m 46s\tremaining: 3.28s\n",
      "485:\ttotal: 1m 46s\tremaining: 3.06s\n",
      "486:\ttotal: 1m 46s\tremaining: 2.84s\n",
      "487:\ttotal: 1m 46s\tremaining: 2.62s\n",
      "488:\ttotal: 1m 46s\tremaining: 2.4s\n",
      "489:\ttotal: 1m 47s\tremaining: 2.18s\n",
      "490:\ttotal: 1m 47s\tremaining: 1.97s\n",
      "491:\ttotal: 1m 47s\tremaining: 1.75s\n",
      "492:\ttotal: 1m 47s\tremaining: 1.53s\n",
      "493:\ttotal: 1m 47s\tremaining: 1.31s\n",
      "494:\ttotal: 1m 48s\tremaining: 1.09s\n",
      "495:\ttotal: 1m 48s\tremaining: 873ms\n",
      "496:\ttotal: 1m 48s\tremaining: 655ms\n",
      "497:\ttotal: 1m 48s\tremaining: 436ms\n",
      "498:\ttotal: 1m 48s\tremaining: 218ms\n",
      "499:\ttotal: 1m 49s\tremaining: 0us\n",
      "0:\ttotal: 216ms\tremaining: 1m 48s\n",
      "1:\ttotal: 448ms\tremaining: 1m 51s\n",
      "2:\ttotal: 667ms\tremaining: 1m 50s\n",
      "3:\ttotal: 873ms\tremaining: 1m 48s\n",
      "4:\ttotal: 1.07s\tremaining: 1m 46s\n",
      "5:\ttotal: 1.28s\tremaining: 1m 45s\n",
      "6:\ttotal: 1.48s\tremaining: 1m 44s\n",
      "7:\ttotal: 1.68s\tremaining: 1m 43s\n",
      "8:\ttotal: 1.89s\tremaining: 1m 42s\n",
      "9:\ttotal: 2.09s\tremaining: 1m 42s\n",
      "10:\ttotal: 2.29s\tremaining: 1m 42s\n",
      "11:\ttotal: 2.5s\tremaining: 1m 41s\n",
      "12:\ttotal: 2.7s\tremaining: 1m 41s\n",
      "13:\ttotal: 2.92s\tremaining: 1m 41s\n",
      "14:\ttotal: 3.14s\tremaining: 1m 41s\n",
      "15:\ttotal: 3.35s\tremaining: 1m 41s\n",
      "16:\ttotal: 3.56s\tremaining: 1m 41s\n",
      "17:\ttotal: 3.78s\tremaining: 1m 41s\n",
      "18:\ttotal: 3.99s\tremaining: 1m 40s\n",
      "19:\ttotal: 4.19s\tremaining: 1m 40s\n",
      "20:\ttotal: 4.4s\tremaining: 1m 40s\n",
      "21:\ttotal: 4.59s\tremaining: 1m 39s\n",
      "22:\ttotal: 4.79s\tremaining: 1m 39s\n",
      "23:\ttotal: 4.99s\tremaining: 1m 38s\n",
      "24:\ttotal: 5.2s\tremaining: 1m 38s\n",
      "25:\ttotal: 5.21s\tremaining: 1m 34s\n",
      "26:\ttotal: 5.41s\tremaining: 1m 34s\n",
      "27:\ttotal: 5.61s\tremaining: 1m 34s\n",
      "28:\ttotal: 5.82s\tremaining: 1m 34s\n",
      "29:\ttotal: 6.01s\tremaining: 1m 34s\n",
      "30:\ttotal: 6.22s\tremaining: 1m 34s\n",
      "31:\ttotal: 6.42s\tremaining: 1m 33s\n",
      "32:\ttotal: 6.62s\tremaining: 1m 33s\n",
      "33:\ttotal: 6.82s\tremaining: 1m 33s\n",
      "34:\ttotal: 7.04s\tremaining: 1m 33s\n",
      "35:\ttotal: 7.24s\tremaining: 1m 33s\n",
      "36:\ttotal: 7.45s\tremaining: 1m 33s\n",
      "37:\ttotal: 7.64s\tremaining: 1m 32s\n",
      "38:\ttotal: 7.84s\tremaining: 1m 32s\n",
      "39:\ttotal: 8.08s\tremaining: 1m 32s\n",
      "40:\ttotal: 8.28s\tremaining: 1m 32s\n",
      "41:\ttotal: 8.49s\tremaining: 1m 32s\n",
      "42:\ttotal: 8.69s\tremaining: 1m 32s\n",
      "43:\ttotal: 8.9s\tremaining: 1m 32s\n",
      "44:\ttotal: 9.1s\tremaining: 1m 31s\n",
      "45:\ttotal: 9.3s\tremaining: 1m 31s\n",
      "46:\ttotal: 9.5s\tremaining: 1m 31s\n",
      "47:\ttotal: 9.71s\tremaining: 1m 31s\n",
      "48:\ttotal: 9.91s\tremaining: 1m 31s\n",
      "49:\ttotal: 10.1s\tremaining: 1m 31s\n",
      "50:\ttotal: 10.3s\tremaining: 1m 31s\n",
      "51:\ttotal: 10.6s\tremaining: 1m 30s\n",
      "52:\ttotal: 10.8s\tremaining: 1m 30s\n",
      "53:\ttotal: 11s\tremaining: 1m 30s\n",
      "54:\ttotal: 11.2s\tremaining: 1m 30s\n",
      "55:\ttotal: 11.4s\tremaining: 1m 30s\n",
      "56:\ttotal: 11.6s\tremaining: 1m 29s\n",
      "57:\ttotal: 11.8s\tremaining: 1m 29s\n",
      "58:\ttotal: 12s\tremaining: 1m 29s\n",
      "59:\ttotal: 12.2s\tremaining: 1m 29s\n",
      "60:\ttotal: 12.4s\tremaining: 1m 29s\n",
      "61:\ttotal: 12.6s\tremaining: 1m 28s\n",
      "62:\ttotal: 12.8s\tremaining: 1m 28s\n",
      "63:\ttotal: 13s\tremaining: 1m 28s\n",
      "64:\ttotal: 13.2s\tremaining: 1m 28s\n",
      "65:\ttotal: 13.4s\tremaining: 1m 28s\n",
      "66:\ttotal: 13.6s\tremaining: 1m 27s\n",
      "67:\ttotal: 13.8s\tremaining: 1m 27s\n",
      "68:\ttotal: 14s\tremaining: 1m 27s\n",
      "69:\ttotal: 14.2s\tremaining: 1m 27s\n",
      "70:\ttotal: 14.4s\tremaining: 1m 27s\n",
      "71:\ttotal: 14.6s\tremaining: 1m 26s\n",
      "72:\ttotal: 14.8s\tremaining: 1m 26s\n",
      "73:\ttotal: 15s\tremaining: 1m 26s\n",
      "74:\ttotal: 15.2s\tremaining: 1m 26s\n",
      "75:\ttotal: 15.5s\tremaining: 1m 26s\n",
      "76:\ttotal: 15.7s\tremaining: 1m 26s\n",
      "77:\ttotal: 15.9s\tremaining: 1m 25s\n",
      "78:\ttotal: 16.1s\tremaining: 1m 25s\n",
      "79:\ttotal: 16.3s\tremaining: 1m 25s\n",
      "80:\ttotal: 16.5s\tremaining: 1m 25s\n",
      "81:\ttotal: 16.7s\tremaining: 1m 25s\n",
      "82:\ttotal: 16.9s\tremaining: 1m 25s\n",
      "83:\ttotal: 17.1s\tremaining: 1m 24s\n",
      "84:\ttotal: 17.3s\tremaining: 1m 24s\n",
      "85:\ttotal: 17.6s\tremaining: 1m 24s\n",
      "86:\ttotal: 17.8s\tremaining: 1m 24s\n",
      "87:\ttotal: 18s\tremaining: 1m 24s\n",
      "88:\ttotal: 18.2s\tremaining: 1m 23s\n",
      "89:\ttotal: 18.4s\tremaining: 1m 23s\n",
      "90:\ttotal: 18.6s\tremaining: 1m 23s\n",
      "91:\ttotal: 18.8s\tremaining: 1m 23s\n",
      "92:\ttotal: 19s\tremaining: 1m 23s\n",
      "93:\ttotal: 19.2s\tremaining: 1m 22s\n",
      "94:\ttotal: 19.4s\tremaining: 1m 22s\n",
      "95:\ttotal: 19.6s\tremaining: 1m 22s\n",
      "96:\ttotal: 19.8s\tremaining: 1m 22s\n",
      "97:\ttotal: 20s\tremaining: 1m 22s\n",
      "98:\ttotal: 20.2s\tremaining: 1m 21s\n",
      "99:\ttotal: 20.4s\tremaining: 1m 21s\n",
      "100:\ttotal: 20.6s\tremaining: 1m 21s\n",
      "101:\ttotal: 20.8s\tremaining: 1m 21s\n",
      "102:\ttotal: 21.1s\tremaining: 1m 21s\n",
      "103:\ttotal: 21.3s\tremaining: 1m 20s\n",
      "104:\ttotal: 21.5s\tremaining: 1m 20s\n",
      "105:\ttotal: 21.7s\tremaining: 1m 20s\n",
      "106:\ttotal: 21.9s\tremaining: 1m 20s\n",
      "107:\ttotal: 22.1s\tremaining: 1m 20s\n",
      "108:\ttotal: 22.3s\tremaining: 1m 20s\n",
      "109:\ttotal: 22.5s\tremaining: 1m 19s\n",
      "110:\ttotal: 22.7s\tremaining: 1m 19s\n",
      "111:\ttotal: 23s\tremaining: 1m 19s\n",
      "112:\ttotal: 23.2s\tremaining: 1m 19s\n",
      "113:\ttotal: 23.4s\tremaining: 1m 19s\n",
      "114:\ttotal: 23.6s\tremaining: 1m 18s\n",
      "115:\ttotal: 23.8s\tremaining: 1m 18s\n",
      "116:\ttotal: 24s\tremaining: 1m 18s\n",
      "117:\ttotal: 24.2s\tremaining: 1m 18s\n",
      "118:\ttotal: 24.4s\tremaining: 1m 18s\n",
      "119:\ttotal: 24.6s\tremaining: 1m 17s\n",
      "120:\ttotal: 24.8s\tremaining: 1m 17s\n",
      "121:\ttotal: 25s\tremaining: 1m 17s\n",
      "122:\ttotal: 25.2s\tremaining: 1m 17s\n",
      "123:\ttotal: 25.4s\tremaining: 1m 17s\n",
      "124:\ttotal: 25.4s\tremaining: 1m 16s\n",
      "125:\ttotal: 25.6s\tremaining: 1m 16s\n",
      "126:\ttotal: 25.9s\tremaining: 1m 16s\n",
      "127:\ttotal: 26.1s\tremaining: 1m 15s\n",
      "128:\ttotal: 26.3s\tremaining: 1m 15s\n",
      "129:\ttotal: 26.5s\tremaining: 1m 15s\n",
      "130:\ttotal: 26.7s\tremaining: 1m 15s\n",
      "131:\ttotal: 26.9s\tremaining: 1m 15s\n",
      "132:\ttotal: 27.2s\tremaining: 1m 14s\n",
      "133:\ttotal: 27.3s\tremaining: 1m 14s\n",
      "134:\ttotal: 27.5s\tremaining: 1m 14s\n",
      "135:\ttotal: 27.8s\tremaining: 1m 14s\n",
      "136:\ttotal: 28s\tremaining: 1m 14s\n",
      "137:\ttotal: 28.2s\tremaining: 1m 13s\n",
      "138:\ttotal: 28.4s\tremaining: 1m 13s\n",
      "139:\ttotal: 28.6s\tremaining: 1m 13s\n",
      "140:\ttotal: 28.8s\tremaining: 1m 13s\n",
      "141:\ttotal: 29s\tremaining: 1m 13s\n",
      "142:\ttotal: 29.2s\tremaining: 1m 12s\n",
      "143:\ttotal: 29.4s\tremaining: 1m 12s\n",
      "144:\ttotal: 29.6s\tremaining: 1m 12s\n",
      "145:\ttotal: 29.8s\tremaining: 1m 12s\n",
      "146:\ttotal: 30s\tremaining: 1m 12s\n",
      "147:\ttotal: 30.2s\tremaining: 1m 11s\n",
      "148:\ttotal: 30.4s\tremaining: 1m 11s\n",
      "149:\ttotal: 30.6s\tremaining: 1m 11s\n",
      "150:\ttotal: 30.9s\tremaining: 1m 11s\n",
      "151:\ttotal: 31.1s\tremaining: 1m 11s\n",
      "152:\ttotal: 31.3s\tremaining: 1m 10s\n",
      "153:\ttotal: 31.5s\tremaining: 1m 10s\n",
      "154:\ttotal: 31.7s\tremaining: 1m 10s\n",
      "155:\ttotal: 31.9s\tremaining: 1m 10s\n",
      "156:\ttotal: 32.1s\tremaining: 1m 10s\n",
      "157:\ttotal: 32.3s\tremaining: 1m 9s\n",
      "158:\ttotal: 32.5s\tremaining: 1m 9s\n",
      "159:\ttotal: 32.7s\tremaining: 1m 9s\n",
      "160:\ttotal: 32.9s\tremaining: 1m 9s\n",
      "161:\ttotal: 33.1s\tremaining: 1m 9s\n",
      "162:\ttotal: 33.3s\tremaining: 1m 8s\n",
      "163:\ttotal: 33.5s\tremaining: 1m 8s\n",
      "164:\ttotal: 33.7s\tremaining: 1m 8s\n",
      "165:\ttotal: 33.9s\tremaining: 1m 8s\n",
      "166:\ttotal: 34.1s\tremaining: 1m 7s\n",
      "167:\ttotal: 34.3s\tremaining: 1m 7s\n",
      "168:\ttotal: 34.5s\tremaining: 1m 7s\n",
      "169:\ttotal: 34.7s\tremaining: 1m 7s\n",
      "170:\ttotal: 34.9s\tremaining: 1m 7s\n",
      "171:\ttotal: 35.1s\tremaining: 1m 6s\n",
      "172:\ttotal: 35.3s\tremaining: 1m 6s\n",
      "173:\ttotal: 35.5s\tremaining: 1m 6s\n",
      "174:\ttotal: 35.7s\tremaining: 1m 6s\n",
      "175:\ttotal: 35.9s\tremaining: 1m 6s\n",
      "176:\ttotal: 36.1s\tremaining: 1m 5s\n",
      "177:\ttotal: 36.3s\tremaining: 1m 5s\n",
      "178:\ttotal: 36.5s\tremaining: 1m 5s\n",
      "179:\ttotal: 36.7s\tremaining: 1m 5s\n",
      "180:\ttotal: 37s\tremaining: 1m 5s\n",
      "181:\ttotal: 37.2s\tremaining: 1m 4s\n",
      "182:\ttotal: 37.4s\tremaining: 1m 4s\n",
      "183:\ttotal: 37.6s\tremaining: 1m 4s\n",
      "184:\ttotal: 37.8s\tremaining: 1m 4s\n",
      "185:\ttotal: 38s\tremaining: 1m 4s\n",
      "186:\ttotal: 38.2s\tremaining: 1m 3s\n",
      "187:\ttotal: 38.4s\tremaining: 1m 3s\n",
      "188:\ttotal: 38.6s\tremaining: 1m 3s\n",
      "189:\ttotal: 38.8s\tremaining: 1m 3s\n",
      "190:\ttotal: 39s\tremaining: 1m 3s\n",
      "191:\ttotal: 39.2s\tremaining: 1m 2s\n",
      "192:\ttotal: 39.4s\tremaining: 1m 2s\n",
      "193:\ttotal: 39.6s\tremaining: 1m 2s\n",
      "194:\ttotal: 39.8s\tremaining: 1m 2s\n",
      "195:\ttotal: 40s\tremaining: 1m 2s\n",
      "196:\ttotal: 40.2s\tremaining: 1m 1s\n",
      "197:\ttotal: 40.5s\tremaining: 1m 1s\n",
      "198:\ttotal: 40.7s\tremaining: 1m 1s\n",
      "199:\ttotal: 40.9s\tremaining: 1m 1s\n",
      "200:\ttotal: 41.1s\tremaining: 1m 1s\n",
      "201:\ttotal: 41.3s\tremaining: 1m\n",
      "202:\ttotal: 41.5s\tremaining: 1m\n",
      "203:\ttotal: 41.7s\tremaining: 1m\n",
      "204:\ttotal: 41.9s\tremaining: 1m\n",
      "205:\ttotal: 42.1s\tremaining: 1m\n",
      "206:\ttotal: 42.3s\tremaining: 59.9s\n",
      "207:\ttotal: 42.5s\tremaining: 59.7s\n",
      "208:\ttotal: 42.7s\tremaining: 59.5s\n",
      "209:\ttotal: 42.9s\tremaining: 59.3s\n",
      "210:\ttotal: 43.1s\tremaining: 59.1s\n",
      "211:\ttotal: 43.3s\tremaining: 58.9s\n",
      "212:\ttotal: 43.5s\tremaining: 58.7s\n",
      "213:\ttotal: 43.7s\tremaining: 58.5s\n",
      "214:\ttotal: 43.9s\tremaining: 58.2s\n",
      "215:\ttotal: 44.1s\tremaining: 58s\n",
      "216:\ttotal: 44.3s\tremaining: 57.8s\n",
      "217:\ttotal: 44.5s\tremaining: 57.6s\n",
      "218:\ttotal: 44.8s\tremaining: 57.4s\n",
      "219:\ttotal: 44.9s\tremaining: 57.2s\n",
      "220:\ttotal: 45.2s\tremaining: 57s\n",
      "221:\ttotal: 45.4s\tremaining: 56.8s\n",
      "222:\ttotal: 45.6s\tremaining: 56.6s\n",
      "223:\ttotal: 45.8s\tremaining: 56.4s\n",
      "224:\ttotal: 46s\tremaining: 56.2s\n",
      "225:\ttotal: 46.2s\tremaining: 56s\n",
      "226:\ttotal: 46.4s\tremaining: 55.8s\n",
      "227:\ttotal: 46.6s\tremaining: 55.6s\n",
      "228:\ttotal: 46.8s\tremaining: 55.4s\n",
      "229:\ttotal: 47s\tremaining: 55.2s\n",
      "230:\ttotal: 47.2s\tremaining: 55s\n",
      "231:\ttotal: 47.4s\tremaining: 54.7s\n",
      "232:\ttotal: 47.6s\tremaining: 54.5s\n",
      "233:\ttotal: 47.8s\tremaining: 54.3s\n",
      "234:\ttotal: 48s\tremaining: 54.1s\n",
      "235:\ttotal: 48.2s\tremaining: 53.9s\n",
      "236:\ttotal: 48.4s\tremaining: 53.7s\n",
      "237:\ttotal: 48.6s\tremaining: 53.5s\n",
      "238:\ttotal: 48.8s\tremaining: 53.3s\n",
      "239:\ttotal: 49s\tremaining: 53.1s\n",
      "240:\ttotal: 49.2s\tremaining: 52.9s\n",
      "241:\ttotal: 49.4s\tremaining: 52.7s\n",
      "242:\ttotal: 49.6s\tremaining: 52.5s\n",
      "243:\ttotal: 49.8s\tremaining: 52.3s\n",
      "244:\ttotal: 50.1s\tremaining: 52.1s\n",
      "245:\ttotal: 50.3s\tremaining: 52s\n",
      "246:\ttotal: 50.6s\tremaining: 51.8s\n",
      "247:\ttotal: 50.8s\tremaining: 51.6s\n",
      "248:\ttotal: 51s\tremaining: 51.4s\n",
      "249:\ttotal: 51.2s\tremaining: 51.2s\n",
      "250:\ttotal: 51.4s\tremaining: 51s\n",
      "251:\ttotal: 51.6s\tremaining: 50.8s\n",
      "252:\ttotal: 51.8s\tremaining: 50.6s\n",
      "253:\ttotal: 52.1s\tremaining: 50.4s\n",
      "254:\ttotal: 52.3s\tremaining: 50.2s\n",
      "255:\ttotal: 52.5s\tremaining: 50s\n",
      "256:\ttotal: 52.7s\tremaining: 49.8s\n",
      "257:\ttotal: 52.9s\tremaining: 49.6s\n",
      "258:\ttotal: 53.1s\tremaining: 49.4s\n",
      "259:\ttotal: 53.3s\tremaining: 49.2s\n",
      "260:\ttotal: 53.5s\tremaining: 49s\n",
      "261:\ttotal: 53.7s\tremaining: 48.8s\n",
      "262:\ttotal: 53.9s\tremaining: 48.6s\n",
      "263:\ttotal: 54.1s\tremaining: 48.4s\n",
      "264:\ttotal: 54.3s\tremaining: 48.2s\n",
      "265:\ttotal: 54.5s\tremaining: 48s\n",
      "266:\ttotal: 54.7s\tremaining: 47.8s\n",
      "267:\ttotal: 54.9s\tremaining: 47.6s\n",
      "268:\ttotal: 55.1s\tremaining: 47.3s\n",
      "269:\ttotal: 55.3s\tremaining: 47.1s\n",
      "270:\ttotal: 55.5s\tremaining: 46.9s\n",
      "271:\ttotal: 55.7s\tremaining: 46.7s\n",
      "272:\ttotal: 56s\tremaining: 46.5s\n",
      "273:\ttotal: 56.2s\tremaining: 46.3s\n",
      "274:\ttotal: 56.4s\tremaining: 46.1s\n",
      "275:\ttotal: 56.5s\tremaining: 45.9s\n",
      "276:\ttotal: 56.8s\tremaining: 45.7s\n",
      "277:\ttotal: 57s\tremaining: 45.5s\n",
      "278:\ttotal: 57.2s\tremaining: 45.3s\n",
      "279:\ttotal: 57.4s\tremaining: 45.1s\n",
      "280:\ttotal: 57.6s\tremaining: 44.9s\n",
      "281:\ttotal: 57.8s\tremaining: 44.6s\n",
      "282:\ttotal: 58s\tremaining: 44.4s\n",
      "283:\ttotal: 58.2s\tremaining: 44.2s\n",
      "284:\ttotal: 58.4s\tremaining: 44s\n",
      "285:\ttotal: 58.6s\tremaining: 43.8s\n",
      "286:\ttotal: 58.8s\tremaining: 43.6s\n",
      "287:\ttotal: 59s\tremaining: 43.4s\n",
      "288:\ttotal: 59.2s\tremaining: 43.2s\n",
      "289:\ttotal: 59.4s\tremaining: 43s\n",
      "290:\ttotal: 59.6s\tremaining: 42.8s\n",
      "291:\ttotal: 59.8s\tremaining: 42.6s\n",
      "292:\ttotal: 1m\tremaining: 42.4s\n",
      "293:\ttotal: 1m\tremaining: 42.2s\n",
      "294:\ttotal: 1m\tremaining: 42s\n",
      "295:\ttotal: 1m\tremaining: 41.8s\n",
      "296:\ttotal: 1m\tremaining: 41.6s\n",
      "297:\ttotal: 1m 1s\tremaining: 41.4s\n",
      "298:\ttotal: 1m 1s\tremaining: 41.2s\n",
      "299:\ttotal: 1m 1s\tremaining: 41s\n",
      "300:\ttotal: 1m 1s\tremaining: 40.8s\n",
      "301:\ttotal: 1m 1s\tremaining: 40.6s\n",
      "302:\ttotal: 1m 2s\tremaining: 40.4s\n",
      "303:\ttotal: 1m 2s\tremaining: 40.2s\n",
      "304:\ttotal: 1m 2s\tremaining: 40s\n",
      "305:\ttotal: 1m 2s\tremaining: 39.7s\n",
      "306:\ttotal: 1m 2s\tremaining: 39.6s\n",
      "307:\ttotal: 1m 3s\tremaining: 39.4s\n",
      "308:\ttotal: 1m 3s\tremaining: 39.2s\n",
      "309:\ttotal: 1m 3s\tremaining: 39s\n",
      "310:\ttotal: 1m 3s\tremaining: 38.8s\n",
      "311:\ttotal: 1m 3s\tremaining: 38.5s\n",
      "312:\ttotal: 1m 4s\tremaining: 38.3s\n",
      "313:\ttotal: 1m 4s\tremaining: 38.1s\n",
      "314:\ttotal: 1m 4s\tremaining: 37.9s\n",
      "315:\ttotal: 1m 4s\tremaining: 37.7s\n",
      "316:\ttotal: 1m 4s\tremaining: 37.5s\n",
      "317:\ttotal: 1m 5s\tremaining: 37.3s\n",
      "318:\ttotal: 1m 5s\tremaining: 37.1s\n",
      "319:\ttotal: 1m 5s\tremaining: 36.9s\n",
      "320:\ttotal: 1m 5s\tremaining: 36.7s\n",
      "321:\ttotal: 1m 6s\tremaining: 36.5s\n",
      "322:\ttotal: 1m 6s\tremaining: 36.3s\n",
      "323:\ttotal: 1m 6s\tremaining: 36.1s\n",
      "324:\ttotal: 1m 6s\tremaining: 35.9s\n",
      "325:\ttotal: 1m 6s\tremaining: 35.7s\n",
      "326:\ttotal: 1m 7s\tremaining: 35.5s\n",
      "327:\ttotal: 1m 7s\tremaining: 35.3s\n",
      "328:\ttotal: 1m 7s\tremaining: 35.1s\n",
      "329:\ttotal: 1m 7s\tremaining: 34.9s\n",
      "330:\ttotal: 1m 7s\tremaining: 34.7s\n",
      "331:\ttotal: 1m 8s\tremaining: 34.5s\n",
      "332:\ttotal: 1m 8s\tremaining: 34.3s\n",
      "333:\ttotal: 1m 8s\tremaining: 34.1s\n",
      "334:\ttotal: 1m 8s\tremaining: 33.9s\n",
      "335:\ttotal: 1m 9s\tremaining: 33.7s\n",
      "336:\ttotal: 1m 9s\tremaining: 33.5s\n",
      "337:\ttotal: 1m 9s\tremaining: 33.3s\n",
      "338:\ttotal: 1m 9s\tremaining: 33.1s\n",
      "339:\ttotal: 1m 9s\tremaining: 32.9s\n",
      "340:\ttotal: 1m 10s\tremaining: 32.7s\n",
      "341:\ttotal: 1m 10s\tremaining: 32.5s\n",
      "342:\ttotal: 1m 10s\tremaining: 32.4s\n",
      "343:\ttotal: 1m 10s\tremaining: 32.2s\n",
      "344:\ttotal: 1m 11s\tremaining: 32s\n",
      "345:\ttotal: 1m 11s\tremaining: 31.8s\n",
      "346:\ttotal: 1m 11s\tremaining: 31.6s\n",
      "347:\ttotal: 1m 11s\tremaining: 31.3s\n",
      "348:\ttotal: 1m 11s\tremaining: 31.1s\n",
      "349:\ttotal: 1m 12s\tremaining: 30.9s\n",
      "350:\ttotal: 1m 12s\tremaining: 30.7s\n",
      "351:\ttotal: 1m 12s\tremaining: 30.5s\n",
      "352:\ttotal: 1m 12s\tremaining: 30.3s\n",
      "353:\ttotal: 1m 13s\tremaining: 30.1s\n",
      "354:\ttotal: 1m 13s\tremaining: 29.9s\n",
      "355:\ttotal: 1m 13s\tremaining: 29.7s\n",
      "356:\ttotal: 1m 13s\tremaining: 29.5s\n",
      "357:\ttotal: 1m 13s\tremaining: 29.3s\n",
      "358:\ttotal: 1m 14s\tremaining: 29.1s\n",
      "359:\ttotal: 1m 14s\tremaining: 28.9s\n",
      "360:\ttotal: 1m 14s\tremaining: 28.7s\n",
      "361:\ttotal: 1m 14s\tremaining: 28.5s\n",
      "362:\ttotal: 1m 14s\tremaining: 28.3s\n",
      "363:\ttotal: 1m 15s\tremaining: 28.1s\n",
      "364:\ttotal: 1m 15s\tremaining: 27.9s\n",
      "365:\ttotal: 1m 15s\tremaining: 27.7s\n",
      "366:\ttotal: 1m 15s\tremaining: 27.5s\n",
      "367:\ttotal: 1m 15s\tremaining: 27.2s\n",
      "368:\ttotal: 1m 16s\tremaining: 27s\n",
      "369:\ttotal: 1m 16s\tremaining: 26.8s\n",
      "370:\ttotal: 1m 16s\tremaining: 26.6s\n",
      "371:\ttotal: 1m 16s\tremaining: 26.4s\n",
      "372:\ttotal: 1m 16s\tremaining: 26.2s\n",
      "373:\ttotal: 1m 17s\tremaining: 26s\n",
      "374:\ttotal: 1m 17s\tremaining: 25.8s\n",
      "375:\ttotal: 1m 17s\tremaining: 25.6s\n",
      "376:\ttotal: 1m 17s\tremaining: 25.4s\n",
      "377:\ttotal: 1m 17s\tremaining: 25.2s\n",
      "378:\ttotal: 1m 18s\tremaining: 25s\n",
      "379:\ttotal: 1m 18s\tremaining: 24.8s\n",
      "380:\ttotal: 1m 18s\tremaining: 24.6s\n",
      "381:\ttotal: 1m 18s\tremaining: 24.3s\n",
      "382:\ttotal: 1m 19s\tremaining: 24.1s\n",
      "383:\ttotal: 1m 19s\tremaining: 23.9s\n",
      "384:\ttotal: 1m 19s\tremaining: 23.7s\n",
      "385:\ttotal: 1m 19s\tremaining: 23.5s\n",
      "386:\ttotal: 1m 19s\tremaining: 23.3s\n",
      "387:\ttotal: 1m 20s\tremaining: 23.1s\n",
      "388:\ttotal: 1m 20s\tremaining: 22.9s\n",
      "389:\ttotal: 1m 20s\tremaining: 22.7s\n",
      "390:\ttotal: 1m 20s\tremaining: 22.5s\n",
      "391:\ttotal: 1m 20s\tremaining: 22.3s\n",
      "392:\ttotal: 1m 21s\tremaining: 22.1s\n",
      "393:\ttotal: 1m 21s\tremaining: 21.9s\n",
      "394:\ttotal: 1m 21s\tremaining: 21.7s\n",
      "395:\ttotal: 1m 21s\tremaining: 21.4s\n",
      "396:\ttotal: 1m 21s\tremaining: 21.2s\n",
      "397:\ttotal: 1m 22s\tremaining: 21s\n",
      "398:\ttotal: 1m 22s\tremaining: 20.8s\n",
      "399:\ttotal: 1m 22s\tremaining: 20.6s\n",
      "400:\ttotal: 1m 22s\tremaining: 20.4s\n",
      "401:\ttotal: 1m 22s\tremaining: 20.2s\n",
      "402:\ttotal: 1m 23s\tremaining: 20s\n",
      "403:\ttotal: 1m 23s\tremaining: 19.8s\n",
      "404:\ttotal: 1m 23s\tremaining: 19.6s\n",
      "405:\ttotal: 1m 23s\tremaining: 19.4s\n",
      "406:\ttotal: 1m 23s\tremaining: 19.2s\n",
      "407:\ttotal: 1m 24s\tremaining: 19s\n",
      "408:\ttotal: 1m 24s\tremaining: 18.8s\n",
      "409:\ttotal: 1m 24s\tremaining: 18.6s\n",
      "410:\ttotal: 1m 24s\tremaining: 18.4s\n",
      "411:\ttotal: 1m 24s\tremaining: 18.1s\n",
      "412:\ttotal: 1m 25s\tremaining: 17.9s\n",
      "413:\ttotal: 1m 25s\tremaining: 17.7s\n",
      "414:\ttotal: 1m 25s\tremaining: 17.5s\n",
      "415:\ttotal: 1m 25s\tremaining: 17.3s\n",
      "416:\ttotal: 1m 26s\tremaining: 17.1s\n",
      "417:\ttotal: 1m 26s\tremaining: 16.9s\n",
      "418:\ttotal: 1m 26s\tremaining: 16.7s\n",
      "419:\ttotal: 1m 26s\tremaining: 16.5s\n",
      "420:\ttotal: 1m 26s\tremaining: 16.3s\n",
      "421:\ttotal: 1m 27s\tremaining: 16.1s\n",
      "422:\ttotal: 1m 27s\tremaining: 15.9s\n",
      "423:\ttotal: 1m 27s\tremaining: 15.7s\n",
      "424:\ttotal: 1m 27s\tremaining: 15.5s\n",
      "425:\ttotal: 1m 28s\tremaining: 15.3s\n",
      "426:\ttotal: 1m 28s\tremaining: 15.1s\n",
      "427:\ttotal: 1m 28s\tremaining: 14.9s\n",
      "428:\ttotal: 1m 29s\tremaining: 14.7s\n",
      "429:\ttotal: 1m 29s\tremaining: 14.5s\n",
      "430:\ttotal: 1m 29s\tremaining: 14.3s\n",
      "431:\ttotal: 1m 29s\tremaining: 14.2s\n",
      "432:\ttotal: 1m 30s\tremaining: 14s\n",
      "433:\ttotal: 1m 30s\tremaining: 13.8s\n",
      "434:\ttotal: 1m 30s\tremaining: 13.6s\n",
      "435:\ttotal: 1m 31s\tremaining: 13.4s\n",
      "436:\ttotal: 1m 31s\tremaining: 13.2s\n",
      "437:\ttotal: 1m 31s\tremaining: 13s\n",
      "438:\ttotal: 1m 32s\tremaining: 12.8s\n",
      "439:\ttotal: 1m 32s\tremaining: 12.6s\n",
      "440:\ttotal: 1m 32s\tremaining: 12.4s\n",
      "441:\ttotal: 1m 33s\tremaining: 12.2s\n",
      "442:\ttotal: 1m 33s\tremaining: 12s\n",
      "443:\ttotal: 1m 33s\tremaining: 11.8s\n",
      "444:\ttotal: 1m 34s\tremaining: 11.6s\n",
      "445:\ttotal: 1m 34s\tremaining: 11.4s\n",
      "446:\ttotal: 1m 34s\tremaining: 11.2s\n",
      "447:\ttotal: 1m 35s\tremaining: 11s\n",
      "448:\ttotal: 1m 35s\tremaining: 10.8s\n",
      "449:\ttotal: 1m 35s\tremaining: 10.6s\n",
      "450:\ttotal: 1m 36s\tremaining: 10.4s\n",
      "451:\ttotal: 1m 36s\tremaining: 10.2s\n",
      "452:\ttotal: 1m 36s\tremaining: 10s\n",
      "453:\ttotal: 1m 37s\tremaining: 9.83s\n",
      "454:\ttotal: 1m 37s\tremaining: 9.62s\n",
      "455:\ttotal: 1m 37s\tremaining: 9.41s\n",
      "456:\ttotal: 1m 37s\tremaining: 9.2s\n",
      "457:\ttotal: 1m 38s\tremaining: 9s\n",
      "458:\ttotal: 1m 38s\tremaining: 8.79s\n",
      "459:\ttotal: 1m 38s\tremaining: 8.59s\n",
      "460:\ttotal: 1m 39s\tremaining: 8.38s\n",
      "461:\ttotal: 1m 39s\tremaining: 8.18s\n",
      "462:\ttotal: 1m 39s\tremaining: 7.97s\n",
      "463:\ttotal: 1m 40s\tremaining: 7.76s\n",
      "464:\ttotal: 1m 40s\tremaining: 7.55s\n",
      "465:\ttotal: 1m 40s\tremaining: 7.34s\n",
      "466:\ttotal: 1m 40s\tremaining: 7.13s\n",
      "467:\ttotal: 1m 41s\tremaining: 6.93s\n",
      "468:\ttotal: 1m 41s\tremaining: 6.72s\n",
      "469:\ttotal: 1m 41s\tremaining: 6.51s\n",
      "470:\ttotal: 1m 42s\tremaining: 6.3s\n",
      "471:\ttotal: 1m 42s\tremaining: 6.08s\n",
      "472:\ttotal: 1m 42s\tremaining: 5.87s\n",
      "473:\ttotal: 1m 43s\tremaining: 5.65s\n",
      "474:\ttotal: 1m 43s\tremaining: 5.44s\n",
      "475:\ttotal: 1m 43s\tremaining: 5.22s\n",
      "476:\ttotal: 1m 43s\tremaining: 5.01s\n",
      "477:\ttotal: 1m 44s\tremaining: 4.79s\n",
      "478:\ttotal: 1m 44s\tremaining: 4.58s\n",
      "479:\ttotal: 1m 44s\tremaining: 4.36s\n",
      "480:\ttotal: 1m 44s\tremaining: 4.14s\n",
      "481:\ttotal: 1m 45s\tremaining: 3.93s\n",
      "482:\ttotal: 1m 45s\tremaining: 3.71s\n",
      "483:\ttotal: 1m 45s\tremaining: 3.49s\n",
      "484:\ttotal: 1m 45s\tremaining: 3.27s\n",
      "485:\ttotal: 1m 46s\tremaining: 3.06s\n",
      "486:\ttotal: 1m 46s\tremaining: 2.84s\n",
      "487:\ttotal: 1m 46s\tremaining: 2.62s\n",
      "488:\ttotal: 1m 46s\tremaining: 2.4s\n",
      "489:\ttotal: 1m 47s\tremaining: 2.19s\n",
      "490:\ttotal: 1m 47s\tremaining: 1.97s\n",
      "491:\ttotal: 1m 47s\tremaining: 1.75s\n",
      "492:\ttotal: 1m 47s\tremaining: 1.53s\n",
      "493:\ttotal: 1m 48s\tremaining: 1.31s\n",
      "494:\ttotal: 1m 48s\tremaining: 1.09s\n",
      "495:\ttotal: 1m 48s\tremaining: 876ms\n",
      "496:\ttotal: 1m 48s\tremaining: 657ms\n",
      "497:\ttotal: 1m 49s\tremaining: 438ms\n",
      "498:\ttotal: 1m 49s\tremaining: 219ms\n",
      "499:\ttotal: 1m 49s\tremaining: 0us\n",
      "0:\ttotal: 334ms\tremaining: 2m 46s\n",
      "1:\ttotal: 629ms\tremaining: 2m 36s\n",
      "2:\ttotal: 877ms\tremaining: 2m 25s\n",
      "3:\ttotal: 1.13s\tremaining: 2m 20s\n",
      "4:\ttotal: 1.38s\tremaining: 2m 16s\n",
      "5:\ttotal: 1.63s\tremaining: 2m 14s\n",
      "6:\ttotal: 1.89s\tremaining: 2m 13s\n",
      "7:\ttotal: 2.15s\tremaining: 2m 12s\n",
      "8:\ttotal: 2.4s\tremaining: 2m 11s\n",
      "9:\ttotal: 2.68s\tremaining: 2m 11s\n",
      "10:\ttotal: 2.94s\tremaining: 2m 10s\n",
      "11:\ttotal: 3.17s\tremaining: 2m 8s\n",
      "12:\ttotal: 3.37s\tremaining: 2m 6s\n",
      "13:\ttotal: 3.6s\tremaining: 2m 5s\n",
      "14:\ttotal: 3.88s\tremaining: 2m 5s\n",
      "15:\ttotal: 4.26s\tremaining: 2m 8s\n",
      "16:\ttotal: 4.59s\tremaining: 2m 10s\n",
      "17:\ttotal: 4.91s\tremaining: 2m 11s\n",
      "18:\ttotal: 5.19s\tremaining: 2m 11s\n",
      "19:\ttotal: 5.41s\tremaining: 2m 9s\n",
      "20:\ttotal: 5.62s\tremaining: 2m 8s\n",
      "21:\ttotal: 5.85s\tremaining: 2m 7s\n",
      "22:\ttotal: 6.06s\tremaining: 2m 5s\n",
      "23:\ttotal: 6.27s\tremaining: 2m 4s\n",
      "24:\ttotal: 6.48s\tremaining: 2m 3s\n",
      "25:\ttotal: 6.69s\tremaining: 2m 1s\n",
      "26:\ttotal: 6.89s\tremaining: 2m\n",
      "27:\ttotal: 7.1s\tremaining: 1m 59s\n",
      "28:\ttotal: 7.32s\tremaining: 1m 58s\n",
      "29:\ttotal: 7.69s\tremaining: 2m\n",
      "30:\ttotal: 7.95s\tremaining: 2m\n",
      "31:\ttotal: 8.16s\tremaining: 1m 59s\n",
      "32:\ttotal: 8.38s\tremaining: 1m 58s\n",
      "33:\ttotal: 8.6s\tremaining: 1m 57s\n",
      "34:\ttotal: 8.81s\tremaining: 1m 57s\n",
      "35:\ttotal: 9.02s\tremaining: 1m 56s\n",
      "36:\ttotal: 9.23s\tremaining: 1m 55s\n",
      "37:\ttotal: 9.43s\tremaining: 1m 54s\n",
      "38:\ttotal: 9.64s\tremaining: 1m 53s\n",
      "39:\ttotal: 9.84s\tremaining: 1m 53s\n",
      "40:\ttotal: 10s\tremaining: 1m 52s\n",
      "41:\ttotal: 10.3s\tremaining: 1m 51s\n",
      "42:\ttotal: 10.5s\tremaining: 1m 51s\n",
      "43:\ttotal: 10.7s\tremaining: 1m 50s\n",
      "44:\ttotal: 10.9s\tremaining: 1m 49s\n",
      "45:\ttotal: 11.1s\tremaining: 1m 49s\n",
      "46:\ttotal: 11.3s\tremaining: 1m 48s\n",
      "47:\ttotal: 11.5s\tremaining: 1m 48s\n",
      "48:\ttotal: 11.7s\tremaining: 1m 47s\n",
      "49:\ttotal: 11.9s\tremaining: 1m 47s\n",
      "50:\ttotal: 12.1s\tremaining: 1m 46s\n",
      "51:\ttotal: 12.3s\tremaining: 1m 46s\n",
      "52:\ttotal: 12.6s\tremaining: 1m 46s\n",
      "53:\ttotal: 12.9s\tremaining: 1m 46s\n",
      "54:\ttotal: 13.3s\tremaining: 1m 47s\n",
      "55:\ttotal: 13.6s\tremaining: 1m 47s\n",
      "56:\ttotal: 13.8s\tremaining: 1m 47s\n",
      "57:\ttotal: 14s\tremaining: 1m 46s\n",
      "58:\ttotal: 14.2s\tremaining: 1m 46s\n",
      "59:\ttotal: 14.4s\tremaining: 1m 45s\n",
      "60:\ttotal: 14.6s\tremaining: 1m 45s\n",
      "61:\ttotal: 14.8s\tremaining: 1m 44s\n",
      "62:\ttotal: 15.1s\tremaining: 1m 44s\n",
      "63:\ttotal: 15.4s\tremaining: 1m 44s\n",
      "64:\ttotal: 15.6s\tremaining: 1m 44s\n",
      "65:\ttotal: 15.8s\tremaining: 1m 43s\n",
      "66:\ttotal: 16s\tremaining: 1m 43s\n",
      "67:\ttotal: 16.2s\tremaining: 1m 43s\n",
      "68:\ttotal: 16.4s\tremaining: 1m 42s\n",
      "69:\ttotal: 16.6s\tremaining: 1m 42s\n",
      "70:\ttotal: 16.9s\tremaining: 1m 41s\n",
      "71:\ttotal: 17.1s\tremaining: 1m 41s\n",
      "72:\ttotal: 17.3s\tremaining: 1m 40s\n",
      "73:\ttotal: 17.5s\tremaining: 1m 40s\n",
      "74:\ttotal: 17.7s\tremaining: 1m 40s\n",
      "75:\ttotal: 17.9s\tremaining: 1m 39s\n",
      "76:\ttotal: 18.1s\tremaining: 1m 39s\n",
      "77:\ttotal: 18.3s\tremaining: 1m 39s\n",
      "78:\ttotal: 18.5s\tremaining: 1m 38s\n",
      "79:\ttotal: 18.7s\tremaining: 1m 38s\n",
      "80:\ttotal: 19s\tremaining: 1m 38s\n",
      "81:\ttotal: 19.2s\tremaining: 1m 37s\n",
      "82:\ttotal: 19.4s\tremaining: 1m 37s\n",
      "83:\ttotal: 19.6s\tremaining: 1m 36s\n",
      "84:\ttotal: 19.8s\tremaining: 1m 36s\n",
      "85:\ttotal: 20s\tremaining: 1m 36s\n",
      "86:\ttotal: 20.2s\tremaining: 1m 35s\n",
      "87:\ttotal: 20.4s\tremaining: 1m 35s\n",
      "88:\ttotal: 20.6s\tremaining: 1m 35s\n",
      "89:\ttotal: 20.8s\tremaining: 1m 34s\n",
      "90:\ttotal: 21s\tremaining: 1m 34s\n",
      "91:\ttotal: 21.2s\tremaining: 1m 34s\n",
      "92:\ttotal: 21.4s\tremaining: 1m 33s\n",
      "93:\ttotal: 21.7s\tremaining: 1m 33s\n",
      "94:\ttotal: 21.9s\tremaining: 1m 33s\n",
      "95:\ttotal: 22.1s\tremaining: 1m 33s\n",
      "96:\ttotal: 22.3s\tremaining: 1m 32s\n",
      "97:\ttotal: 22.5s\tremaining: 1m 32s\n",
      "98:\ttotal: 22.8s\tremaining: 1m 32s\n",
      "99:\ttotal: 23s\tremaining: 1m 31s\n",
      "100:\ttotal: 23.2s\tremaining: 1m 31s\n",
      "101:\ttotal: 23.4s\tremaining: 1m 31s\n",
      "102:\ttotal: 23.6s\tremaining: 1m 30s\n",
      "103:\ttotal: 23.8s\tremaining: 1m 30s\n",
      "104:\ttotal: 24s\tremaining: 1m 30s\n",
      "105:\ttotal: 24.2s\tremaining: 1m 29s\n",
      "106:\ttotal: 24.4s\tremaining: 1m 29s\n",
      "107:\ttotal: 24.6s\tremaining: 1m 29s\n",
      "108:\ttotal: 24.8s\tremaining: 1m 29s\n",
      "109:\ttotal: 25s\tremaining: 1m 28s\n",
      "110:\ttotal: 25.3s\tremaining: 1m 28s\n",
      "111:\ttotal: 25.4s\tremaining: 1m 28s\n",
      "112:\ttotal: 25.7s\tremaining: 1m 27s\n",
      "113:\ttotal: 25.9s\tremaining: 1m 27s\n",
      "114:\ttotal: 26.1s\tremaining: 1m 27s\n",
      "115:\ttotal: 26.3s\tremaining: 1m 26s\n",
      "116:\ttotal: 26.5s\tremaining: 1m 26s\n",
      "117:\ttotal: 26.7s\tremaining: 1m 26s\n",
      "118:\ttotal: 26.9s\tremaining: 1m 26s\n",
      "119:\ttotal: 27.1s\tremaining: 1m 25s\n",
      "120:\ttotal: 27.3s\tremaining: 1m 25s\n",
      "121:\ttotal: 27.5s\tremaining: 1m 25s\n",
      "122:\ttotal: 27.7s\tremaining: 1m 24s\n",
      "123:\ttotal: 27.9s\tremaining: 1m 24s\n",
      "124:\ttotal: 28.1s\tremaining: 1m 24s\n",
      "125:\ttotal: 28.3s\tremaining: 1m 24s\n",
      "126:\ttotal: 28.5s\tremaining: 1m 23s\n",
      "127:\ttotal: 28.7s\tremaining: 1m 23s\n",
      "128:\ttotal: 28.9s\tremaining: 1m 23s\n",
      "129:\ttotal: 29.1s\tremaining: 1m 22s\n",
      "130:\ttotal: 29.3s\tremaining: 1m 22s\n",
      "131:\ttotal: 29.5s\tremaining: 1m 22s\n",
      "132:\ttotal: 29.7s\tremaining: 1m 22s\n",
      "133:\ttotal: 30s\tremaining: 1m 21s\n",
      "134:\ttotal: 30.1s\tremaining: 1m 21s\n",
      "135:\ttotal: 30.4s\tremaining: 1m 21s\n",
      "136:\ttotal: 30.6s\tremaining: 1m 20s\n",
      "137:\ttotal: 30.8s\tremaining: 1m 20s\n",
      "138:\ttotal: 31.1s\tremaining: 1m 20s\n",
      "139:\ttotal: 31.3s\tremaining: 1m 20s\n",
      "140:\ttotal: 31.6s\tremaining: 1m 20s\n",
      "141:\ttotal: 31.9s\tremaining: 1m 20s\n",
      "142:\ttotal: 32.1s\tremaining: 1m 20s\n",
      "143:\ttotal: 32.4s\tremaining: 1m 20s\n",
      "144:\ttotal: 32.7s\tremaining: 1m 20s\n",
      "145:\ttotal: 33s\tremaining: 1m 20s\n",
      "146:\ttotal: 33.3s\tremaining: 1m 19s\n",
      "147:\ttotal: 33.5s\tremaining: 1m 19s\n",
      "148:\ttotal: 33.8s\tremaining: 1m 19s\n",
      "149:\ttotal: 34.1s\tremaining: 1m 19s\n",
      "150:\ttotal: 34.3s\tremaining: 1m 19s\n",
      "151:\ttotal: 34.6s\tremaining: 1m 19s\n",
      "152:\ttotal: 34.9s\tremaining: 1m 19s\n",
      "153:\ttotal: 35.2s\tremaining: 1m 19s\n",
      "154:\ttotal: 35.4s\tremaining: 1m 18s\n",
      "155:\ttotal: 35.7s\tremaining: 1m 18s\n",
      "156:\ttotal: 36s\tremaining: 1m 18s\n",
      "157:\ttotal: 36.2s\tremaining: 1m 18s\n",
      "158:\ttotal: 36.5s\tremaining: 1m 18s\n",
      "159:\ttotal: 36.7s\tremaining: 1m 18s\n",
      "160:\ttotal: 37s\tremaining: 1m 17s\n",
      "161:\ttotal: 37.3s\tremaining: 1m 17s\n",
      "162:\ttotal: 37.6s\tremaining: 1m 17s\n",
      "163:\ttotal: 37.9s\tremaining: 1m 17s\n",
      "164:\ttotal: 38.1s\tremaining: 1m 17s\n",
      "165:\ttotal: 38.3s\tremaining: 1m 17s\n",
      "166:\ttotal: 38.5s\tremaining: 1m 16s\n",
      "167:\ttotal: 38.7s\tremaining: 1m 16s\n",
      "168:\ttotal: 38.9s\tremaining: 1m 16s\n",
      "169:\ttotal: 39.1s\tremaining: 1m 15s\n",
      "170:\ttotal: 39.3s\tremaining: 1m 15s\n",
      "171:\ttotal: 39.5s\tremaining: 1m 15s\n",
      "172:\ttotal: 39.7s\tremaining: 1m 15s\n",
      "173:\ttotal: 39.9s\tremaining: 1m 14s\n",
      "174:\ttotal: 40.1s\tremaining: 1m 14s\n",
      "175:\ttotal: 40.3s\tremaining: 1m 14s\n",
      "176:\ttotal: 40.5s\tremaining: 1m 13s\n",
      "177:\ttotal: 40.7s\tremaining: 1m 13s\n",
      "178:\ttotal: 40.9s\tremaining: 1m 13s\n",
      "179:\ttotal: 41.2s\tremaining: 1m 13s\n",
      "180:\ttotal: 41.4s\tremaining: 1m 12s\n",
      "181:\ttotal: 41.6s\tremaining: 1m 12s\n",
      "182:\ttotal: 41.8s\tremaining: 1m 12s\n",
      "183:\ttotal: 42s\tremaining: 1m 12s\n",
      "184:\ttotal: 42.2s\tremaining: 1m 11s\n",
      "185:\ttotal: 42.4s\tremaining: 1m 11s\n",
      "186:\ttotal: 42.6s\tremaining: 1m 11s\n",
      "187:\ttotal: 42.8s\tremaining: 1m 11s\n",
      "188:\ttotal: 43.1s\tremaining: 1m 10s\n",
      "189:\ttotal: 43.3s\tremaining: 1m 10s\n",
      "190:\ttotal: 43.5s\tremaining: 1m 10s\n",
      "191:\ttotal: 43.7s\tremaining: 1m 10s\n",
      "192:\ttotal: 43.9s\tremaining: 1m 9s\n",
      "193:\ttotal: 44.1s\tremaining: 1m 9s\n",
      "194:\ttotal: 44.3s\tremaining: 1m 9s\n",
      "195:\ttotal: 44.5s\tremaining: 1m 8s\n",
      "196:\ttotal: 44.7s\tremaining: 1m 8s\n",
      "197:\ttotal: 44.9s\tremaining: 1m 8s\n",
      "198:\ttotal: 45.1s\tremaining: 1m 8s\n",
      "199:\ttotal: 45.3s\tremaining: 1m 7s\n",
      "200:\ttotal: 45.5s\tremaining: 1m 7s\n",
      "201:\ttotal: 45.8s\tremaining: 1m 7s\n",
      "202:\ttotal: 46s\tremaining: 1m 7s\n",
      "203:\ttotal: 46.2s\tremaining: 1m 7s\n",
      "204:\ttotal: 46.4s\tremaining: 1m 6s\n",
      "205:\ttotal: 46.6s\tremaining: 1m 6s\n",
      "206:\ttotal: 46.9s\tremaining: 1m 6s\n",
      "207:\ttotal: 47.1s\tremaining: 1m 6s\n",
      "208:\ttotal: 47.3s\tremaining: 1m 5s\n",
      "209:\ttotal: 47.5s\tremaining: 1m 5s\n",
      "210:\ttotal: 47.7s\tremaining: 1m 5s\n",
      "211:\ttotal: 47.9s\tremaining: 1m 5s\n",
      "212:\ttotal: 48.1s\tremaining: 1m 4s\n",
      "213:\ttotal: 48.3s\tremaining: 1m 4s\n",
      "214:\ttotal: 48.5s\tremaining: 1m 4s\n",
      "215:\ttotal: 48.7s\tremaining: 1m 4s\n",
      "216:\ttotal: 49s\tremaining: 1m 3s\n",
      "217:\ttotal: 49.2s\tremaining: 1m 3s\n",
      "218:\ttotal: 49.4s\tremaining: 1m 3s\n",
      "219:\ttotal: 49.6s\tremaining: 1m 3s\n",
      "220:\ttotal: 49.8s\tremaining: 1m 2s\n",
      "221:\ttotal: 50.1s\tremaining: 1m 2s\n",
      "222:\ttotal: 50.4s\tremaining: 1m 2s\n",
      "223:\ttotal: 50.7s\tremaining: 1m 2s\n",
      "224:\ttotal: 50.9s\tremaining: 1m 2s\n",
      "225:\ttotal: 51.3s\tremaining: 1m 2s\n",
      "226:\ttotal: 51.5s\tremaining: 1m 1s\n",
      "227:\ttotal: 51.8s\tremaining: 1m 1s\n",
      "228:\ttotal: 52.1s\tremaining: 1m 1s\n",
      "229:\ttotal: 52.4s\tremaining: 1m 1s\n",
      "230:\ttotal: 52.8s\tremaining: 1m 1s\n",
      "231:\ttotal: 53.1s\tremaining: 1m 1s\n",
      "232:\ttotal: 53.4s\tremaining: 1m 1s\n",
      "233:\ttotal: 53.7s\tremaining: 1m 1s\n",
      "234:\ttotal: 53.9s\tremaining: 1m\n",
      "235:\ttotal: 54.2s\tremaining: 1m\n",
      "236:\ttotal: 54.5s\tremaining: 1m\n",
      "237:\ttotal: 54.8s\tremaining: 1m\n",
      "238:\ttotal: 55s\tremaining: 1m\n",
      "239:\ttotal: 55.4s\tremaining: 60s\n",
      "240:\ttotal: 55.6s\tremaining: 59.8s\n",
      "241:\ttotal: 56s\tremaining: 59.7s\n",
      "242:\ttotal: 56.2s\tremaining: 59.4s\n",
      "243:\ttotal: 56.5s\tremaining: 59.2s\n",
      "244:\ttotal: 56.7s\tremaining: 59.1s\n",
      "245:\ttotal: 56.9s\tremaining: 58.8s\n",
      "246:\ttotal: 57.1s\tremaining: 58.5s\n",
      "247:\ttotal: 57.4s\tremaining: 58.3s\n",
      "248:\ttotal: 57.6s\tremaining: 58s\n",
      "249:\ttotal: 57.8s\tremaining: 57.8s\n",
      "250:\ttotal: 58s\tremaining: 57.5s\n",
      "251:\ttotal: 58.3s\tremaining: 57.4s\n",
      "252:\ttotal: 58.6s\tremaining: 57.2s\n",
      "253:\ttotal: 58.9s\tremaining: 57s\n",
      "254:\ttotal: 59.2s\tremaining: 56.9s\n",
      "255:\ttotal: 59.5s\tremaining: 56.7s\n",
      "256:\ttotal: 59.8s\tremaining: 56.6s\n",
      "257:\ttotal: 1m\tremaining: 56.5s\n",
      "258:\ttotal: 1m\tremaining: 56.4s\n",
      "259:\ttotal: 1m\tremaining: 56.2s\n",
      "260:\ttotal: 1m 1s\tremaining: 56s\n",
      "261:\ttotal: 1m 1s\tremaining: 55.8s\n",
      "262:\ttotal: 1m 1s\tremaining: 55.6s\n",
      "263:\ttotal: 1m 2s\tremaining: 55.5s\n",
      "264:\ttotal: 1m 2s\tremaining: 55.4s\n",
      "265:\ttotal: 1m 2s\tremaining: 55.2s\n",
      "266:\ttotal: 1m 3s\tremaining: 55.1s\n",
      "267:\ttotal: 1m 3s\tremaining: 54.9s\n",
      "268:\ttotal: 1m 3s\tremaining: 54.8s\n",
      "269:\ttotal: 1m 4s\tremaining: 54.6s\n",
      "270:\ttotal: 1m 4s\tremaining: 54.3s\n",
      "271:\ttotal: 1m 4s\tremaining: 54.2s\n",
      "272:\ttotal: 1m 4s\tremaining: 53.9s\n",
      "273:\ttotal: 1m 5s\tremaining: 53.7s\n",
      "274:\ttotal: 1m 5s\tremaining: 53.4s\n",
      "275:\ttotal: 1m 5s\tremaining: 53.1s\n",
      "276:\ttotal: 1m 5s\tremaining: 53s\n",
      "277:\ttotal: 1m 6s\tremaining: 52.8s\n",
      "278:\ttotal: 1m 6s\tremaining: 52.6s\n",
      "279:\ttotal: 1m 6s\tremaining: 52.4s\n",
      "280:\ttotal: 1m 7s\tremaining: 52.3s\n",
      "281:\ttotal: 1m 7s\tremaining: 52.1s\n",
      "282:\ttotal: 1m 7s\tremaining: 51.9s\n",
      "283:\ttotal: 1m 7s\tremaining: 51.7s\n",
      "284:\ttotal: 1m 8s\tremaining: 51.5s\n",
      "285:\ttotal: 1m 8s\tremaining: 51.3s\n",
      "286:\ttotal: 1m 8s\tremaining: 51s\n",
      "287:\ttotal: 1m 8s\tremaining: 50.8s\n",
      "288:\ttotal: 1m 9s\tremaining: 50.6s\n",
      "289:\ttotal: 1m 9s\tremaining: 50.3s\n",
      "290:\ttotal: 1m 9s\tremaining: 50.1s\n",
      "291:\ttotal: 1m 10s\tremaining: 50s\n",
      "292:\ttotal: 1m 10s\tremaining: 49.8s\n",
      "293:\ttotal: 1m 10s\tremaining: 49.6s\n",
      "294:\ttotal: 1m 11s\tremaining: 49.3s\n",
      "295:\ttotal: 1m 11s\tremaining: 49.1s\n",
      "296:\ttotal: 1m 11s\tremaining: 48.8s\n",
      "297:\ttotal: 1m 11s\tremaining: 48.6s\n",
      "298:\ttotal: 1m 12s\tremaining: 48.4s\n",
      "299:\ttotal: 1m 12s\tremaining: 48.2s\n",
      "300:\ttotal: 1m 12s\tremaining: 47.9s\n",
      "301:\ttotal: 1m 12s\tremaining: 47.7s\n",
      "302:\ttotal: 1m 13s\tremaining: 47.6s\n",
      "303:\ttotal: 1m 13s\tremaining: 47.3s\n",
      "304:\ttotal: 1m 13s\tremaining: 47.1s\n",
      "305:\ttotal: 1m 13s\tremaining: 46.8s\n",
      "306:\ttotal: 1m 14s\tremaining: 46.5s\n",
      "307:\ttotal: 1m 14s\tremaining: 46.3s\n",
      "308:\ttotal: 1m 14s\tremaining: 46s\n",
      "309:\ttotal: 1m 14s\tremaining: 45.8s\n",
      "310:\ttotal: 1m 14s\tremaining: 45.5s\n",
      "311:\ttotal: 1m 15s\tremaining: 45.2s\n",
      "312:\ttotal: 1m 15s\tremaining: 45s\n",
      "313:\ttotal: 1m 15s\tremaining: 44.7s\n",
      "314:\ttotal: 1m 15s\tremaining: 44.4s\n",
      "315:\ttotal: 1m 15s\tremaining: 44.2s\n",
      "316:\ttotal: 1m 16s\tremaining: 43.9s\n",
      "317:\ttotal: 1m 16s\tremaining: 43.7s\n",
      "318:\ttotal: 1m 16s\tremaining: 43.4s\n",
      "319:\ttotal: 1m 16s\tremaining: 43.2s\n",
      "320:\ttotal: 1m 16s\tremaining: 42.9s\n",
      "321:\ttotal: 1m 17s\tremaining: 42.6s\n",
      "322:\ttotal: 1m 17s\tremaining: 42.4s\n",
      "323:\ttotal: 1m 17s\tremaining: 42.1s\n",
      "324:\ttotal: 1m 17s\tremaining: 41.9s\n",
      "325:\ttotal: 1m 17s\tremaining: 41.6s\n",
      "326:\ttotal: 1m 18s\tremaining: 41.4s\n",
      "327:\ttotal: 1m 18s\tremaining: 41.1s\n",
      "328:\ttotal: 1m 18s\tremaining: 40.9s\n",
      "329:\ttotal: 1m 18s\tremaining: 40.6s\n",
      "330:\ttotal: 1m 19s\tremaining: 40.3s\n",
      "331:\ttotal: 1m 19s\tremaining: 40.1s\n",
      "332:\ttotal: 1m 19s\tremaining: 39.8s\n",
      "333:\ttotal: 1m 19s\tremaining: 39.6s\n",
      "334:\ttotal: 1m 19s\tremaining: 39.3s\n",
      "335:\ttotal: 1m 20s\tremaining: 39.1s\n",
      "336:\ttotal: 1m 20s\tremaining: 38.8s\n",
      "337:\ttotal: 1m 20s\tremaining: 38.6s\n",
      "338:\ttotal: 1m 20s\tremaining: 38.3s\n",
      "339:\ttotal: 1m 20s\tremaining: 38.1s\n",
      "340:\ttotal: 1m 21s\tremaining: 37.8s\n",
      "341:\ttotal: 1m 21s\tremaining: 37.6s\n",
      "342:\ttotal: 1m 21s\tremaining: 37.3s\n",
      "343:\ttotal: 1m 21s\tremaining: 37.1s\n",
      "344:\ttotal: 1m 21s\tremaining: 36.8s\n",
      "345:\ttotal: 1m 22s\tremaining: 36.6s\n",
      "346:\ttotal: 1m 22s\tremaining: 36.3s\n",
      "347:\ttotal: 1m 22s\tremaining: 36.1s\n",
      "348:\ttotal: 1m 22s\tremaining: 35.8s\n",
      "349:\ttotal: 1m 22s\tremaining: 35.6s\n",
      "350:\ttotal: 1m 23s\tremaining: 35.3s\n",
      "351:\ttotal: 1m 23s\tremaining: 35.1s\n",
      "352:\ttotal: 1m 23s\tremaining: 34.8s\n",
      "353:\ttotal: 1m 23s\tremaining: 34.6s\n",
      "354:\ttotal: 1m 24s\tremaining: 34.3s\n",
      "355:\ttotal: 1m 24s\tremaining: 34.1s\n",
      "356:\ttotal: 1m 24s\tremaining: 33.8s\n",
      "357:\ttotal: 1m 24s\tremaining: 33.6s\n",
      "358:\ttotal: 1m 24s\tremaining: 33.3s\n",
      "359:\ttotal: 1m 25s\tremaining: 33.1s\n",
      "360:\ttotal: 1m 25s\tremaining: 32.8s\n",
      "361:\ttotal: 1m 25s\tremaining: 32.6s\n",
      "362:\ttotal: 1m 25s\tremaining: 32.4s\n",
      "363:\ttotal: 1m 25s\tremaining: 32.1s\n",
      "364:\ttotal: 1m 26s\tremaining: 31.9s\n",
      "365:\ttotal: 1m 26s\tremaining: 31.6s\n",
      "366:\ttotal: 1m 26s\tremaining: 31.4s\n",
      "367:\ttotal: 1m 26s\tremaining: 31.1s\n",
      "368:\ttotal: 1m 26s\tremaining: 30.9s\n",
      "369:\ttotal: 1m 27s\tremaining: 30.6s\n",
      "370:\ttotal: 1m 27s\tremaining: 30.4s\n",
      "371:\ttotal: 1m 27s\tremaining: 30.1s\n",
      "372:\ttotal: 1m 27s\tremaining: 29.9s\n",
      "373:\ttotal: 1m 27s\tremaining: 29.6s\n",
      "374:\ttotal: 1m 28s\tremaining: 29.4s\n",
      "375:\ttotal: 1m 28s\tremaining: 29.1s\n",
      "376:\ttotal: 1m 28s\tremaining: 28.9s\n",
      "377:\ttotal: 1m 28s\tremaining: 28.7s\n",
      "378:\ttotal: 1m 29s\tremaining: 28.4s\n",
      "379:\ttotal: 1m 29s\tremaining: 28.2s\n",
      "380:\ttotal: 1m 29s\tremaining: 27.9s\n",
      "381:\ttotal: 1m 29s\tremaining: 27.7s\n",
      "382:\ttotal: 1m 29s\tremaining: 27.4s\n",
      "383:\ttotal: 1m 30s\tremaining: 27.2s\n",
      "384:\ttotal: 1m 30s\tremaining: 27s\n",
      "385:\ttotal: 1m 30s\tremaining: 26.7s\n",
      "386:\ttotal: 1m 30s\tremaining: 26.5s\n",
      "387:\ttotal: 1m 30s\tremaining: 26.2s\n",
      "388:\ttotal: 1m 31s\tremaining: 26s\n",
      "389:\ttotal: 1m 31s\tremaining: 25.8s\n",
      "390:\ttotal: 1m 31s\tremaining: 25.5s\n",
      "391:\ttotal: 1m 31s\tremaining: 25.3s\n",
      "392:\ttotal: 1m 31s\tremaining: 25s\n",
      "393:\ttotal: 1m 32s\tremaining: 24.8s\n",
      "394:\ttotal: 1m 32s\tremaining: 24.5s\n",
      "395:\ttotal: 1m 32s\tremaining: 24.3s\n",
      "396:\ttotal: 1m 32s\tremaining: 24.1s\n",
      "397:\ttotal: 1m 32s\tremaining: 23.8s\n",
      "398:\ttotal: 1m 33s\tremaining: 23.6s\n",
      "399:\ttotal: 1m 33s\tremaining: 23.3s\n",
      "400:\ttotal: 1m 33s\tremaining: 23.1s\n",
      "401:\ttotal: 1m 33s\tremaining: 22.9s\n",
      "402:\ttotal: 1m 34s\tremaining: 22.6s\n",
      "403:\ttotal: 1m 34s\tremaining: 22.4s\n",
      "404:\ttotal: 1m 34s\tremaining: 22.2s\n",
      "405:\ttotal: 1m 34s\tremaining: 21.9s\n",
      "406:\ttotal: 1m 34s\tremaining: 21.7s\n",
      "407:\ttotal: 1m 35s\tremaining: 21.4s\n",
      "408:\ttotal: 1m 35s\tremaining: 21.2s\n",
      "409:\ttotal: 1m 35s\tremaining: 21s\n",
      "410:\ttotal: 1m 35s\tremaining: 20.7s\n",
      "411:\ttotal: 1m 35s\tremaining: 20.5s\n",
      "412:\ttotal: 1m 36s\tremaining: 20.2s\n",
      "413:\ttotal: 1m 36s\tremaining: 20s\n",
      "414:\ttotal: 1m 36s\tremaining: 19.8s\n",
      "415:\ttotal: 1m 36s\tremaining: 19.5s\n",
      "416:\ttotal: 1m 36s\tremaining: 19.3s\n",
      "417:\ttotal: 1m 37s\tremaining: 19.1s\n",
      "418:\ttotal: 1m 37s\tremaining: 18.8s\n",
      "419:\ttotal: 1m 37s\tremaining: 18.6s\n",
      "420:\ttotal: 1m 37s\tremaining: 18.3s\n",
      "421:\ttotal: 1m 37s\tremaining: 18.1s\n",
      "422:\ttotal: 1m 38s\tremaining: 17.9s\n",
      "423:\ttotal: 1m 38s\tremaining: 17.6s\n",
      "424:\ttotal: 1m 38s\tremaining: 17.4s\n",
      "425:\ttotal: 1m 38s\tremaining: 17.2s\n",
      "426:\ttotal: 1m 38s\tremaining: 16.9s\n",
      "427:\ttotal: 1m 39s\tremaining: 16.7s\n",
      "428:\ttotal: 1m 39s\tremaining: 16.4s\n",
      "429:\ttotal: 1m 39s\tremaining: 16.2s\n",
      "430:\ttotal: 1m 39s\tremaining: 16s\n",
      "431:\ttotal: 1m 39s\tremaining: 15.7s\n",
      "432:\ttotal: 1m 40s\tremaining: 15.5s\n",
      "433:\ttotal: 1m 40s\tremaining: 15.3s\n",
      "434:\ttotal: 1m 40s\tremaining: 15s\n",
      "435:\ttotal: 1m 40s\tremaining: 14.8s\n",
      "436:\ttotal: 1m 41s\tremaining: 14.6s\n",
      "437:\ttotal: 1m 41s\tremaining: 14.3s\n",
      "438:\ttotal: 1m 41s\tremaining: 14.1s\n",
      "439:\ttotal: 1m 41s\tremaining: 13.9s\n",
      "440:\ttotal: 1m 41s\tremaining: 13.6s\n",
      "441:\ttotal: 1m 42s\tremaining: 13.4s\n",
      "442:\ttotal: 1m 42s\tremaining: 13.2s\n",
      "443:\ttotal: 1m 42s\tremaining: 12.9s\n",
      "444:\ttotal: 1m 42s\tremaining: 12.7s\n",
      "445:\ttotal: 1m 42s\tremaining: 12.5s\n",
      "446:\ttotal: 1m 43s\tremaining: 12.2s\n",
      "447:\ttotal: 1m 43s\tremaining: 12s\n",
      "448:\ttotal: 1m 43s\tremaining: 11.8s\n",
      "449:\ttotal: 1m 43s\tremaining: 11.5s\n",
      "450:\ttotal: 1m 43s\tremaining: 11.3s\n",
      "451:\ttotal: 1m 44s\tremaining: 11.1s\n",
      "452:\ttotal: 1m 44s\tremaining: 10.8s\n",
      "453:\ttotal: 1m 44s\tremaining: 10.6s\n",
      "454:\ttotal: 1m 44s\tremaining: 10.4s\n",
      "455:\ttotal: 1m 44s\tremaining: 10.1s\n",
      "456:\ttotal: 1m 45s\tremaining: 9.89s\n",
      "457:\ttotal: 1m 45s\tremaining: 9.66s\n",
      "458:\ttotal: 1m 45s\tremaining: 9.43s\n",
      "459:\ttotal: 1m 45s\tremaining: 9.2s\n",
      "460:\ttotal: 1m 46s\tremaining: 8.97s\n",
      "461:\ttotal: 1m 46s\tremaining: 8.74s\n",
      "462:\ttotal: 1m 46s\tremaining: 8.51s\n",
      "463:\ttotal: 1m 46s\tremaining: 8.27s\n",
      "464:\ttotal: 1m 46s\tremaining: 8.04s\n",
      "465:\ttotal: 1m 47s\tremaining: 7.81s\n",
      "466:\ttotal: 1m 47s\tremaining: 7.58s\n",
      "467:\ttotal: 1m 47s\tremaining: 7.35s\n",
      "468:\ttotal: 1m 47s\tremaining: 7.12s\n",
      "469:\ttotal: 1m 47s\tremaining: 6.89s\n",
      "470:\ttotal: 1m 48s\tremaining: 6.66s\n",
      "471:\ttotal: 1m 48s\tremaining: 6.42s\n",
      "472:\ttotal: 1m 48s\tremaining: 6.2s\n",
      "473:\ttotal: 1m 48s\tremaining: 5.97s\n",
      "474:\ttotal: 1m 49s\tremaining: 5.74s\n",
      "475:\ttotal: 1m 49s\tremaining: 5.51s\n",
      "476:\ttotal: 1m 49s\tremaining: 5.28s\n",
      "477:\ttotal: 1m 49s\tremaining: 5.05s\n",
      "478:\ttotal: 1m 49s\tremaining: 4.82s\n",
      "479:\ttotal: 1m 50s\tremaining: 4.59s\n",
      "480:\ttotal: 1m 50s\tremaining: 4.36s\n",
      "481:\ttotal: 1m 50s\tremaining: 4.13s\n",
      "482:\ttotal: 1m 50s\tremaining: 3.9s\n",
      "483:\ttotal: 1m 50s\tremaining: 3.67s\n",
      "484:\ttotal: 1m 51s\tremaining: 3.44s\n",
      "485:\ttotal: 1m 51s\tremaining: 3.21s\n",
      "486:\ttotal: 1m 51s\tremaining: 2.98s\n",
      "487:\ttotal: 1m 51s\tremaining: 2.75s\n",
      "488:\ttotal: 1m 51s\tremaining: 2.52s\n",
      "489:\ttotal: 1m 52s\tremaining: 2.29s\n",
      "490:\ttotal: 1m 52s\tremaining: 2.06s\n",
      "491:\ttotal: 1m 52s\tremaining: 1.83s\n",
      "492:\ttotal: 1m 52s\tremaining: 1.6s\n",
      "493:\ttotal: 1m 53s\tremaining: 1.37s\n",
      "494:\ttotal: 1m 53s\tremaining: 1.14s\n",
      "495:\ttotal: 1m 53s\tremaining: 915ms\n",
      "496:\ttotal: 1m 53s\tremaining: 686ms\n",
      "497:\ttotal: 1m 53s\tremaining: 458ms\n",
      "498:\ttotal: 1m 54s\tremaining: 229ms\n",
      "499:\ttotal: 1m 54s\tremaining: 0us\n",
      "0:\ttotal: 302ms\tremaining: 2m 30s\n",
      "1:\ttotal: 722ms\tremaining: 2m 59s\n",
      "2:\ttotal: 1.03s\tremaining: 2m 50s\n",
      "3:\ttotal: 1.25s\tremaining: 2m 35s\n",
      "4:\ttotal: 1.48s\tremaining: 2m 26s\n",
      "5:\ttotal: 1.68s\tremaining: 2m 18s\n",
      "6:\ttotal: 1.89s\tremaining: 2m 13s\n",
      "7:\ttotal: 2.1s\tremaining: 2m 9s\n",
      "8:\ttotal: 2.31s\tremaining: 2m 6s\n",
      "9:\ttotal: 2.53s\tremaining: 2m 3s\n",
      "10:\ttotal: 2.74s\tremaining: 2m 1s\n",
      "11:\ttotal: 2.95s\tremaining: 1m 59s\n",
      "12:\ttotal: 3.15s\tremaining: 1m 58s\n",
      "13:\ttotal: 3.36s\tremaining: 1m 56s\n",
      "14:\ttotal: 3.57s\tremaining: 1m 55s\n",
      "15:\ttotal: 3.77s\tremaining: 1m 54s\n",
      "16:\ttotal: 3.98s\tremaining: 1m 53s\n",
      "17:\ttotal: 4.18s\tremaining: 1m 51s\n",
      "18:\ttotal: 4.39s\tremaining: 1m 51s\n",
      "19:\ttotal: 4.59s\tremaining: 1m 50s\n",
      "20:\ttotal: 4.8s\tremaining: 1m 49s\n",
      "21:\ttotal: 5.01s\tremaining: 1m 48s\n",
      "22:\ttotal: 5.21s\tremaining: 1m 48s\n",
      "23:\ttotal: 5.41s\tremaining: 1m 47s\n",
      "24:\ttotal: 5.62s\tremaining: 1m 46s\n",
      "25:\ttotal: 5.85s\tremaining: 1m 46s\n",
      "26:\ttotal: 6.05s\tremaining: 1m 46s\n",
      "27:\ttotal: 6.26s\tremaining: 1m 45s\n",
      "28:\ttotal: 6.46s\tremaining: 1m 44s\n",
      "29:\ttotal: 6.67s\tremaining: 1m 44s\n",
      "30:\ttotal: 6.88s\tremaining: 1m 44s\n",
      "31:\ttotal: 7.1s\tremaining: 1m 43s\n",
      "32:\ttotal: 7.32s\tremaining: 1m 43s\n",
      "33:\ttotal: 7.54s\tremaining: 1m 43s\n",
      "34:\ttotal: 7.75s\tremaining: 1m 42s\n",
      "35:\ttotal: 7.96s\tremaining: 1m 42s\n",
      "36:\ttotal: 8.16s\tremaining: 1m 42s\n",
      "37:\ttotal: 8.38s\tremaining: 1m 41s\n",
      "38:\ttotal: 8.59s\tremaining: 1m 41s\n",
      "39:\ttotal: 8.79s\tremaining: 1m 41s\n",
      "40:\ttotal: 9s\tremaining: 1m 40s\n",
      "41:\ttotal: 9.2s\tremaining: 1m 40s\n",
      "42:\ttotal: 9.41s\tremaining: 1m 40s\n",
      "43:\ttotal: 9.63s\tremaining: 1m 39s\n",
      "44:\ttotal: 9.86s\tremaining: 1m 39s\n",
      "45:\ttotal: 10.1s\tremaining: 1m 39s\n",
      "46:\ttotal: 10.3s\tremaining: 1m 38s\n",
      "47:\ttotal: 10.5s\tremaining: 1m 38s\n",
      "48:\ttotal: 10.7s\tremaining: 1m 38s\n",
      "49:\ttotal: 10.9s\tremaining: 1m 37s\n",
      "50:\ttotal: 11.1s\tremaining: 1m 37s\n",
      "51:\ttotal: 11.3s\tremaining: 1m 37s\n",
      "52:\ttotal: 11.5s\tremaining: 1m 37s\n",
      "53:\ttotal: 11.7s\tremaining: 1m 36s\n",
      "54:\ttotal: 11.9s\tremaining: 1m 36s\n",
      "55:\ttotal: 12.1s\tremaining: 1m 36s\n",
      "56:\ttotal: 12.3s\tremaining: 1m 35s\n",
      "57:\ttotal: 12.5s\tremaining: 1m 35s\n",
      "58:\ttotal: 12.7s\tremaining: 1m 35s\n",
      "59:\ttotal: 13s\tremaining: 1m 34s\n",
      "60:\ttotal: 13.2s\tremaining: 1m 34s\n",
      "61:\ttotal: 13.4s\tremaining: 1m 34s\n",
      "62:\ttotal: 13.6s\tremaining: 1m 34s\n",
      "63:\ttotal: 13.8s\tremaining: 1m 33s\n",
      "64:\ttotal: 14s\tremaining: 1m 33s\n",
      "65:\ttotal: 14.2s\tremaining: 1m 33s\n",
      "66:\ttotal: 14.4s\tremaining: 1m 32s\n",
      "67:\ttotal: 14.6s\tremaining: 1m 32s\n",
      "68:\ttotal: 14.8s\tremaining: 1m 32s\n",
      "69:\ttotal: 15s\tremaining: 1m 32s\n",
      "70:\ttotal: 15.2s\tremaining: 1m 32s\n",
      "71:\ttotal: 15.4s\tremaining: 1m 31s\n",
      "72:\ttotal: 15.7s\tremaining: 1m 31s\n",
      "73:\ttotal: 15.9s\tremaining: 1m 31s\n",
      "74:\ttotal: 16.1s\tremaining: 1m 31s\n",
      "75:\ttotal: 16.3s\tremaining: 1m 31s\n",
      "76:\ttotal: 16.5s\tremaining: 1m 30s\n",
      "77:\ttotal: 16.7s\tremaining: 1m 30s\n",
      "78:\ttotal: 16.9s\tremaining: 1m 30s\n",
      "79:\ttotal: 17.1s\tremaining: 1m 29s\n",
      "80:\ttotal: 17.3s\tremaining: 1m 29s\n",
      "81:\ttotal: 17.6s\tremaining: 1m 29s\n",
      "82:\ttotal: 17.8s\tremaining: 1m 29s\n",
      "83:\ttotal: 18s\tremaining: 1m 29s\n",
      "84:\ttotal: 18.2s\tremaining: 1m 28s\n",
      "85:\ttotal: 18.4s\tremaining: 1m 28s\n",
      "86:\ttotal: 18.6s\tremaining: 1m 28s\n",
      "87:\ttotal: 18.8s\tremaining: 1m 28s\n",
      "88:\ttotal: 19s\tremaining: 1m 27s\n",
      "89:\ttotal: 19.2s\tremaining: 1m 27s\n",
      "90:\ttotal: 19.4s\tremaining: 1m 27s\n",
      "91:\ttotal: 19.6s\tremaining: 1m 27s\n",
      "92:\ttotal: 19.8s\tremaining: 1m 26s\n",
      "93:\ttotal: 20s\tremaining: 1m 26s\n",
      "94:\ttotal: 20.3s\tremaining: 1m 26s\n",
      "95:\ttotal: 20.5s\tremaining: 1m 26s\n",
      "96:\ttotal: 20.7s\tremaining: 1m 25s\n",
      "97:\ttotal: 20.9s\tremaining: 1m 25s\n",
      "98:\ttotal: 21.1s\tremaining: 1m 25s\n",
      "99:\ttotal: 21.3s\tremaining: 1m 25s\n",
      "100:\ttotal: 21.6s\tremaining: 1m 25s\n",
      "101:\ttotal: 21.9s\tremaining: 1m 25s\n",
      "102:\ttotal: 22.1s\tremaining: 1m 25s\n",
      "103:\ttotal: 22.4s\tremaining: 1m 25s\n",
      "104:\ttotal: 22.6s\tremaining: 1m 25s\n",
      "105:\ttotal: 22.9s\tremaining: 1m 25s\n",
      "106:\ttotal: 23.1s\tremaining: 1m 24s\n",
      "107:\ttotal: 23.3s\tremaining: 1m 24s\n",
      "108:\ttotal: 23.5s\tremaining: 1m 24s\n",
      "109:\ttotal: 23.7s\tremaining: 1m 24s\n",
      "110:\ttotal: 23.9s\tremaining: 1m 23s\n",
      "111:\ttotal: 24.1s\tremaining: 1m 23s\n",
      "112:\ttotal: 24.3s\tremaining: 1m 23s\n",
      "113:\ttotal: 24.6s\tremaining: 1m 23s\n",
      "114:\ttotal: 24.9s\tremaining: 1m 23s\n",
      "115:\ttotal: 25.1s\tremaining: 1m 23s\n",
      "116:\ttotal: 25.3s\tremaining: 1m 22s\n",
      "117:\ttotal: 25.5s\tremaining: 1m 22s\n",
      "118:\ttotal: 25.7s\tremaining: 1m 22s\n",
      "119:\ttotal: 26s\tremaining: 1m 22s\n",
      "120:\ttotal: 26.2s\tremaining: 1m 21s\n",
      "121:\ttotal: 26.4s\tremaining: 1m 21s\n",
      "122:\ttotal: 26.6s\tremaining: 1m 21s\n",
      "123:\ttotal: 26.8s\tremaining: 1m 21s\n",
      "124:\ttotal: 27s\tremaining: 1m 21s\n",
      "125:\ttotal: 27.2s\tremaining: 1m 20s\n",
      "126:\ttotal: 27.4s\tremaining: 1m 20s\n",
      "127:\ttotal: 27.7s\tremaining: 1m 20s\n",
      "128:\ttotal: 27.9s\tremaining: 1m 20s\n",
      "129:\ttotal: 28.2s\tremaining: 1m 20s\n",
      "130:\ttotal: 28.5s\tremaining: 1m 20s\n",
      "131:\ttotal: 28.7s\tremaining: 1m 19s\n",
      "132:\ttotal: 28.9s\tremaining: 1m 19s\n",
      "133:\ttotal: 29.1s\tremaining: 1m 19s\n",
      "134:\ttotal: 29.3s\tremaining: 1m 19s\n",
      "135:\ttotal: 29.5s\tremaining: 1m 19s\n",
      "136:\ttotal: 29.7s\tremaining: 1m 18s\n",
      "137:\ttotal: 30s\tremaining: 1m 18s\n",
      "138:\ttotal: 30.2s\tremaining: 1m 18s\n",
      "139:\ttotal: 30.5s\tremaining: 1m 18s\n",
      "140:\ttotal: 30.7s\tremaining: 1m 18s\n",
      "141:\ttotal: 31s\tremaining: 1m 18s\n",
      "142:\ttotal: 31.3s\tremaining: 1m 18s\n",
      "143:\ttotal: 31.6s\tremaining: 1m 18s\n",
      "144:\ttotal: 31.9s\tremaining: 1m 18s\n",
      "145:\ttotal: 32.2s\tremaining: 1m 18s\n",
      "146:\ttotal: 32.4s\tremaining: 1m 17s\n",
      "147:\ttotal: 32.7s\tremaining: 1m 17s\n",
      "148:\ttotal: 32.9s\tremaining: 1m 17s\n",
      "149:\ttotal: 33.1s\tremaining: 1m 17s\n",
      "150:\ttotal: 33.3s\tremaining: 1m 17s\n",
      "151:\ttotal: 33.5s\tremaining: 1m 16s\n",
      "152:\ttotal: 33.8s\tremaining: 1m 16s\n",
      "153:\ttotal: 34s\tremaining: 1m 16s\n",
      "154:\ttotal: 34.2s\tremaining: 1m 16s\n",
      "155:\ttotal: 34.4s\tremaining: 1m 15s\n",
      "156:\ttotal: 34.7s\tremaining: 1m 15s\n",
      "157:\ttotal: 34.9s\tremaining: 1m 15s\n",
      "158:\ttotal: 35.1s\tremaining: 1m 15s\n",
      "159:\ttotal: 35.4s\tremaining: 1m 15s\n",
      "160:\ttotal: 35.7s\tremaining: 1m 15s\n",
      "161:\ttotal: 36s\tremaining: 1m 15s\n",
      "162:\ttotal: 36.3s\tremaining: 1m 14s\n",
      "163:\ttotal: 36.6s\tremaining: 1m 14s\n",
      "164:\ttotal: 36.8s\tremaining: 1m 14s\n",
      "165:\ttotal: 37.1s\tremaining: 1m 14s\n",
      "166:\ttotal: 37.5s\tremaining: 1m 14s\n",
      "167:\ttotal: 37.7s\tremaining: 1m 14s\n",
      "168:\ttotal: 37.9s\tremaining: 1m 14s\n",
      "169:\ttotal: 38.1s\tremaining: 1m 13s\n",
      "170:\ttotal: 38.3s\tremaining: 1m 13s\n",
      "171:\ttotal: 38.7s\tremaining: 1m 13s\n",
      "172:\ttotal: 38.9s\tremaining: 1m 13s\n",
      "173:\ttotal: 39.2s\tremaining: 1m 13s\n",
      "174:\ttotal: 39.5s\tremaining: 1m 13s\n",
      "175:\ttotal: 39.7s\tremaining: 1m 13s\n",
      "176:\ttotal: 40s\tremaining: 1m 12s\n",
      "177:\ttotal: 40.2s\tremaining: 1m 12s\n",
      "178:\ttotal: 40.5s\tremaining: 1m 12s\n",
      "179:\ttotal: 40.8s\tremaining: 1m 12s\n",
      "180:\ttotal: 41.1s\tremaining: 1m 12s\n",
      "181:\ttotal: 41.3s\tremaining: 1m 12s\n",
      "182:\ttotal: 41.6s\tremaining: 1m 12s\n",
      "183:\ttotal: 41.9s\tremaining: 1m 11s\n",
      "184:\ttotal: 42.2s\tremaining: 1m 11s\n",
      "185:\ttotal: 42.4s\tremaining: 1m 11s\n",
      "186:\ttotal: 42.6s\tremaining: 1m 11s\n",
      "187:\ttotal: 42.8s\tremaining: 1m 11s\n",
      "188:\ttotal: 43s\tremaining: 1m 10s\n",
      "189:\ttotal: 43.2s\tremaining: 1m 10s\n",
      "190:\ttotal: 43.4s\tremaining: 1m 10s\n",
      "191:\ttotal: 43.6s\tremaining: 1m 10s\n",
      "192:\ttotal: 43.8s\tremaining: 1m 9s\n",
      "193:\ttotal: 44s\tremaining: 1m 9s\n",
      "194:\ttotal: 44.3s\tremaining: 1m 9s\n",
      "195:\ttotal: 44.5s\tremaining: 1m 8s\n",
      "196:\ttotal: 44.7s\tremaining: 1m 8s\n",
      "197:\ttotal: 44.9s\tremaining: 1m 8s\n",
      "198:\ttotal: 45.2s\tremaining: 1m 8s\n",
      "199:\ttotal: 45.4s\tremaining: 1m 8s\n",
      "200:\ttotal: 45.6s\tremaining: 1m 7s\n",
      "201:\ttotal: 45.8s\tremaining: 1m 7s\n",
      "202:\ttotal: 46s\tremaining: 1m 7s\n",
      "203:\ttotal: 46.2s\tremaining: 1m 7s\n",
      "204:\ttotal: 46.5s\tremaining: 1m 6s\n",
      "205:\ttotal: 46.7s\tremaining: 1m 6s\n",
      "206:\ttotal: 46.9s\tremaining: 1m 6s\n",
      "207:\ttotal: 47.1s\tremaining: 1m 6s\n",
      "208:\ttotal: 47.3s\tremaining: 1m 5s\n",
      "209:\ttotal: 47.5s\tremaining: 1m 5s\n",
      "210:\ttotal: 47.7s\tremaining: 1m 5s\n",
      "211:\ttotal: 47.9s\tremaining: 1m 5s\n",
      "212:\ttotal: 48.2s\tremaining: 1m 4s\n",
      "213:\ttotal: 48.5s\tremaining: 1m 4s\n",
      "214:\ttotal: 48.7s\tremaining: 1m 4s\n",
      "215:\ttotal: 48.9s\tremaining: 1m 4s\n",
      "216:\ttotal: 49.1s\tremaining: 1m 4s\n",
      "217:\ttotal: 49.3s\tremaining: 1m 3s\n",
      "218:\ttotal: 49.5s\tremaining: 1m 3s\n",
      "219:\ttotal: 49.7s\tremaining: 1m 3s\n",
      "220:\ttotal: 49.9s\tremaining: 1m 3s\n",
      "221:\ttotal: 50.1s\tremaining: 1m 2s\n",
      "222:\ttotal: 50.3s\tremaining: 1m 2s\n",
      "223:\ttotal: 50.6s\tremaining: 1m 2s\n",
      "224:\ttotal: 50.8s\tremaining: 1m 2s\n",
      "225:\ttotal: 51s\tremaining: 1m 1s\n",
      "226:\ttotal: 51.2s\tremaining: 1m 1s\n",
      "227:\ttotal: 51.4s\tremaining: 1m 1s\n",
      "228:\ttotal: 51.6s\tremaining: 1m 1s\n",
      "229:\ttotal: 51.8s\tremaining: 1m\n",
      "230:\ttotal: 52s\tremaining: 1m\n",
      "231:\ttotal: 52.2s\tremaining: 1m\n",
      "232:\ttotal: 52.4s\tremaining: 1m\n",
      "233:\ttotal: 52.6s\tremaining: 59.8s\n",
      "234:\ttotal: 52.9s\tremaining: 59.6s\n",
      "235:\ttotal: 53.2s\tremaining: 59.5s\n",
      "236:\ttotal: 53.4s\tremaining: 59.2s\n",
      "237:\ttotal: 53.6s\tremaining: 59.1s\n",
      "238:\ttotal: 53.9s\tremaining: 58.8s\n",
      "239:\ttotal: 54.1s\tremaining: 58.6s\n",
      "240:\ttotal: 54.3s\tremaining: 58.4s\n",
      "241:\ttotal: 54.5s\tremaining: 58.1s\n",
      "242:\ttotal: 54.7s\tremaining: 57.9s\n",
      "243:\ttotal: 55s\tremaining: 57.7s\n",
      "244:\ttotal: 55.2s\tremaining: 57.4s\n",
      "245:\ttotal: 55.4s\tremaining: 57.2s\n",
      "246:\ttotal: 55.6s\tremaining: 57s\n",
      "247:\ttotal: 55.8s\tremaining: 56.7s\n",
      "248:\ttotal: 56s\tremaining: 56.5s\n",
      "249:\ttotal: 56.3s\tremaining: 56.3s\n",
      "250:\ttotal: 56.7s\tremaining: 56.2s\n",
      "251:\ttotal: 57s\tremaining: 56s\n",
      "252:\ttotal: 57.2s\tremaining: 55.8s\n",
      "253:\ttotal: 57.5s\tremaining: 55.7s\n",
      "254:\ttotal: 57.8s\tremaining: 55.5s\n",
      "255:\ttotal: 58s\tremaining: 55.3s\n",
      "256:\ttotal: 58.3s\tremaining: 55.1s\n",
      "257:\ttotal: 58.6s\tremaining: 54.9s\n",
      "258:\ttotal: 58.9s\tremaining: 54.8s\n",
      "259:\ttotal: 59.2s\tremaining: 54.6s\n",
      "260:\ttotal: 59.5s\tremaining: 54.5s\n",
      "261:\ttotal: 59.8s\tremaining: 54.3s\n",
      "262:\ttotal: 1m\tremaining: 54.1s\n",
      "263:\ttotal: 1m\tremaining: 53.9s\n",
      "264:\ttotal: 1m\tremaining: 53.7s\n",
      "265:\ttotal: 1m\tremaining: 53.5s\n",
      "266:\ttotal: 1m 1s\tremaining: 53.3s\n",
      "267:\ttotal: 1m 1s\tremaining: 53.2s\n",
      "268:\ttotal: 1m 1s\tremaining: 53.1s\n",
      "269:\ttotal: 1m 2s\tremaining: 52.9s\n",
      "270:\ttotal: 1m 2s\tremaining: 52.7s\n",
      "271:\ttotal: 1m 2s\tremaining: 52.6s\n",
      "272:\ttotal: 1m 2s\tremaining: 52.3s\n",
      "273:\ttotal: 1m 3s\tremaining: 52.1s\n",
      "274:\ttotal: 1m 3s\tremaining: 51.9s\n",
      "275:\ttotal: 1m 3s\tremaining: 51.8s\n",
      "276:\ttotal: 1m 4s\tremaining: 51.6s\n",
      "277:\ttotal: 1m 4s\tremaining: 51.5s\n",
      "278:\ttotal: 1m 4s\tremaining: 51.2s\n",
      "279:\ttotal: 1m 4s\tremaining: 51s\n",
      "280:\ttotal: 1m 5s\tremaining: 50.7s\n",
      "281:\ttotal: 1m 5s\tremaining: 50.5s\n",
      "282:\ttotal: 1m 5s\tremaining: 50.3s\n",
      "283:\ttotal: 1m 5s\tremaining: 50s\n",
      "284:\ttotal: 1m 5s\tremaining: 49.8s\n",
      "285:\ttotal: 1m 6s\tremaining: 49.5s\n",
      "286:\ttotal: 1m 6s\tremaining: 49.3s\n",
      "287:\ttotal: 1m 6s\tremaining: 49.1s\n",
      "288:\ttotal: 1m 6s\tremaining: 48.9s\n",
      "289:\ttotal: 1m 7s\tremaining: 48.6s\n",
      "290:\ttotal: 1m 7s\tremaining: 48.4s\n",
      "291:\ttotal: 1m 7s\tremaining: 48.1s\n",
      "292:\ttotal: 1m 7s\tremaining: 47.9s\n",
      "293:\ttotal: 1m 7s\tremaining: 47.6s\n",
      "294:\ttotal: 1m 8s\tremaining: 47.4s\n",
      "295:\ttotal: 1m 8s\tremaining: 47.2s\n",
      "296:\ttotal: 1m 8s\tremaining: 46.9s\n",
      "297:\ttotal: 1m 8s\tremaining: 46.7s\n",
      "298:\ttotal: 1m 9s\tremaining: 46.5s\n",
      "299:\ttotal: 1m 9s\tremaining: 46.2s\n",
      "300:\ttotal: 1m 9s\tremaining: 46s\n",
      "301:\ttotal: 1m 9s\tremaining: 45.7s\n",
      "302:\ttotal: 1m 9s\tremaining: 45.5s\n",
      "303:\ttotal: 1m 10s\tremaining: 45.3s\n",
      "304:\ttotal: 1m 10s\tremaining: 45s\n",
      "305:\ttotal: 1m 10s\tremaining: 44.8s\n",
      "306:\ttotal: 1m 10s\tremaining: 44.6s\n",
      "307:\ttotal: 1m 11s\tremaining: 44.3s\n",
      "308:\ttotal: 1m 11s\tremaining: 44.1s\n",
      "309:\ttotal: 1m 11s\tremaining: 43.8s\n",
      "310:\ttotal: 1m 11s\tremaining: 43.6s\n",
      "311:\ttotal: 1m 11s\tremaining: 43.4s\n",
      "312:\ttotal: 1m 12s\tremaining: 43.1s\n",
      "313:\ttotal: 1m 12s\tremaining: 42.9s\n",
      "314:\ttotal: 1m 12s\tremaining: 42.7s\n",
      "315:\ttotal: 1m 12s\tremaining: 42.4s\n",
      "316:\ttotal: 1m 13s\tremaining: 42.2s\n",
      "317:\ttotal: 1m 13s\tremaining: 41.9s\n",
      "318:\ttotal: 1m 13s\tremaining: 41.7s\n",
      "319:\ttotal: 1m 13s\tremaining: 41.5s\n",
      "320:\ttotal: 1m 13s\tremaining: 41.2s\n",
      "321:\ttotal: 1m 14s\tremaining: 41s\n",
      "322:\ttotal: 1m 14s\tremaining: 40.8s\n",
      "323:\ttotal: 1m 14s\tremaining: 40.5s\n",
      "324:\ttotal: 1m 14s\tremaining: 40.3s\n",
      "325:\ttotal: 1m 15s\tremaining: 40s\n",
      "326:\ttotal: 1m 15s\tremaining: 39.7s\n",
      "327:\ttotal: 1m 15s\tremaining: 39.5s\n",
      "328:\ttotal: 1m 15s\tremaining: 39.2s\n",
      "329:\ttotal: 1m 15s\tremaining: 39s\n",
      "330:\ttotal: 1m 15s\tremaining: 38.8s\n",
      "331:\ttotal: 1m 16s\tremaining: 38.6s\n",
      "332:\ttotal: 1m 16s\tremaining: 38.4s\n",
      "333:\ttotal: 1m 16s\tremaining: 38.2s\n",
      "334:\ttotal: 1m 17s\tremaining: 38s\n",
      "335:\ttotal: 1m 17s\tremaining: 37.8s\n",
      "336:\ttotal: 1m 17s\tremaining: 37.6s\n",
      "337:\ttotal: 1m 18s\tremaining: 37.4s\n",
      "338:\ttotal: 1m 18s\tremaining: 37.2s\n",
      "339:\ttotal: 1m 18s\tremaining: 37s\n",
      "340:\ttotal: 1m 18s\tremaining: 36.8s\n",
      "341:\ttotal: 1m 19s\tremaining: 36.6s\n",
      "342:\ttotal: 1m 19s\tremaining: 36.3s\n",
      "343:\ttotal: 1m 19s\tremaining: 36.1s\n",
      "344:\ttotal: 1m 19s\tremaining: 35.9s\n",
      "345:\ttotal: 1m 20s\tremaining: 35.6s\n",
      "346:\ttotal: 1m 20s\tremaining: 35.4s\n",
      "347:\ttotal: 1m 20s\tremaining: 35.1s\n",
      "348:\ttotal: 1m 20s\tremaining: 34.9s\n",
      "349:\ttotal: 1m 20s\tremaining: 34.7s\n",
      "350:\ttotal: 1m 21s\tremaining: 34.4s\n",
      "351:\ttotal: 1m 21s\tremaining: 34.2s\n",
      "352:\ttotal: 1m 21s\tremaining: 34s\n",
      "353:\ttotal: 1m 21s\tremaining: 33.8s\n",
      "354:\ttotal: 1m 22s\tremaining: 33.6s\n",
      "355:\ttotal: 1m 22s\tremaining: 33.3s\n",
      "356:\ttotal: 1m 22s\tremaining: 33.1s\n",
      "357:\ttotal: 1m 22s\tremaining: 32.9s\n",
      "358:\ttotal: 1m 23s\tremaining: 32.6s\n",
      "359:\ttotal: 1m 23s\tremaining: 32.4s\n",
      "360:\ttotal: 1m 23s\tremaining: 32.2s\n",
      "361:\ttotal: 1m 23s\tremaining: 31.9s\n",
      "362:\ttotal: 1m 23s\tremaining: 31.7s\n",
      "363:\ttotal: 1m 24s\tremaining: 31.6s\n",
      "364:\ttotal: 1m 24s\tremaining: 31.4s\n",
      "365:\ttotal: 1m 25s\tremaining: 31.2s\n",
      "366:\ttotal: 1m 25s\tremaining: 31s\n",
      "367:\ttotal: 1m 25s\tremaining: 30.7s\n",
      "368:\ttotal: 1m 25s\tremaining: 30.5s\n",
      "369:\ttotal: 1m 26s\tremaining: 30.2s\n",
      "370:\ttotal: 1m 26s\tremaining: 30s\n",
      "371:\ttotal: 1m 26s\tremaining: 29.8s\n",
      "372:\ttotal: 1m 26s\tremaining: 29.6s\n",
      "373:\ttotal: 1m 27s\tremaining: 29.4s\n",
      "374:\ttotal: 1m 27s\tremaining: 29.2s\n",
      "375:\ttotal: 1m 27s\tremaining: 29s\n",
      "376:\ttotal: 1m 28s\tremaining: 28.8s\n",
      "377:\ttotal: 1m 28s\tremaining: 28.5s\n",
      "378:\ttotal: 1m 28s\tremaining: 28.3s\n",
      "379:\ttotal: 1m 28s\tremaining: 28s\n",
      "380:\ttotal: 1m 29s\tremaining: 27.8s\n",
      "381:\ttotal: 1m 29s\tremaining: 27.6s\n",
      "382:\ttotal: 1m 29s\tremaining: 27.4s\n",
      "383:\ttotal: 1m 29s\tremaining: 27.1s\n",
      "384:\ttotal: 1m 30s\tremaining: 26.9s\n",
      "385:\ttotal: 1m 30s\tremaining: 26.7s\n",
      "386:\ttotal: 1m 30s\tremaining: 26.5s\n",
      "387:\ttotal: 1m 31s\tremaining: 26.3s\n",
      "388:\ttotal: 1m 31s\tremaining: 26s\n",
      "389:\ttotal: 1m 31s\tremaining: 25.8s\n",
      "390:\ttotal: 1m 31s\tremaining: 25.6s\n",
      "391:\ttotal: 1m 32s\tremaining: 25.4s\n",
      "392:\ttotal: 1m 32s\tremaining: 25.2s\n",
      "393:\ttotal: 1m 32s\tremaining: 24.9s\n",
      "394:\ttotal: 1m 32s\tremaining: 24.7s\n",
      "395:\ttotal: 1m 33s\tremaining: 24.5s\n",
      "396:\ttotal: 1m 33s\tremaining: 24.3s\n",
      "397:\ttotal: 1m 33s\tremaining: 24.1s\n",
      "398:\ttotal: 1m 34s\tremaining: 23.9s\n",
      "399:\ttotal: 1m 34s\tremaining: 23.6s\n",
      "400:\ttotal: 1m 34s\tremaining: 23.4s\n",
      "401:\ttotal: 1m 35s\tremaining: 23.2s\n",
      "402:\ttotal: 1m 35s\tremaining: 23s\n",
      "403:\ttotal: 1m 35s\tremaining: 22.7s\n",
      "404:\ttotal: 1m 36s\tremaining: 22.5s\n",
      "405:\ttotal: 1m 36s\tremaining: 22.3s\n",
      "406:\ttotal: 1m 36s\tremaining: 22.1s\n",
      "407:\ttotal: 1m 36s\tremaining: 21.8s\n",
      "408:\ttotal: 1m 37s\tremaining: 21.6s\n",
      "409:\ttotal: 1m 37s\tremaining: 21.4s\n",
      "410:\ttotal: 1m 37s\tremaining: 21.2s\n",
      "411:\ttotal: 1m 38s\tremaining: 21s\n",
      "412:\ttotal: 1m 38s\tremaining: 20.7s\n",
      "413:\ttotal: 1m 38s\tremaining: 20.5s\n",
      "414:\ttotal: 1m 38s\tremaining: 20.3s\n",
      "415:\ttotal: 1m 39s\tremaining: 20s\n",
      "416:\ttotal: 1m 39s\tremaining: 19.8s\n",
      "417:\ttotal: 1m 39s\tremaining: 19.6s\n",
      "418:\ttotal: 1m 40s\tremaining: 19.4s\n",
      "419:\ttotal: 1m 40s\tremaining: 19.1s\n",
      "420:\ttotal: 1m 40s\tremaining: 18.9s\n",
      "421:\ttotal: 1m 41s\tremaining: 18.7s\n",
      "422:\ttotal: 1m 41s\tremaining: 18.5s\n",
      "423:\ttotal: 1m 41s\tremaining: 18.2s\n",
      "424:\ttotal: 1m 41s\tremaining: 18s\n",
      "425:\ttotal: 1m 42s\tremaining: 17.7s\n",
      "426:\ttotal: 1m 42s\tremaining: 17.5s\n",
      "427:\ttotal: 1m 42s\tremaining: 17.3s\n",
      "428:\ttotal: 1m 42s\tremaining: 17s\n",
      "429:\ttotal: 1m 43s\tremaining: 16.8s\n",
      "430:\ttotal: 1m 43s\tremaining: 16.6s\n",
      "431:\ttotal: 1m 43s\tremaining: 16.4s\n",
      "432:\ttotal: 1m 44s\tremaining: 16.1s\n",
      "433:\ttotal: 1m 44s\tremaining: 15.9s\n",
      "434:\ttotal: 1m 44s\tremaining: 15.7s\n",
      "435:\ttotal: 1m 45s\tremaining: 15.4s\n",
      "436:\ttotal: 1m 45s\tremaining: 15.2s\n",
      "437:\ttotal: 1m 45s\tremaining: 15s\n",
      "438:\ttotal: 1m 45s\tremaining: 14.7s\n",
      "439:\ttotal: 1m 46s\tremaining: 14.5s\n",
      "440:\ttotal: 1m 46s\tremaining: 14.3s\n",
      "441:\ttotal: 1m 46s\tremaining: 14s\n",
      "442:\ttotal: 1m 47s\tremaining: 13.8s\n",
      "443:\ttotal: 1m 47s\tremaining: 13.5s\n",
      "444:\ttotal: 1m 47s\tremaining: 13.3s\n",
      "445:\ttotal: 1m 48s\tremaining: 13.1s\n",
      "446:\ttotal: 1m 48s\tremaining: 12.9s\n",
      "447:\ttotal: 1m 48s\tremaining: 12.6s\n",
      "448:\ttotal: 1m 48s\tremaining: 12.4s\n",
      "449:\ttotal: 1m 49s\tremaining: 12.1s\n",
      "450:\ttotal: 1m 49s\tremaining: 11.9s\n",
      "451:\ttotal: 1m 49s\tremaining: 11.6s\n",
      "452:\ttotal: 1m 49s\tremaining: 11.4s\n",
      "453:\ttotal: 1m 50s\tremaining: 11.2s\n",
      "454:\ttotal: 1m 50s\tremaining: 10.9s\n",
      "455:\ttotal: 1m 50s\tremaining: 10.7s\n",
      "456:\ttotal: 1m 50s\tremaining: 10.4s\n",
      "457:\ttotal: 1m 51s\tremaining: 10.2s\n",
      "458:\ttotal: 1m 51s\tremaining: 9.95s\n",
      "459:\ttotal: 1m 51s\tremaining: 9.71s\n",
      "460:\ttotal: 1m 51s\tremaining: 9.47s\n",
      "461:\ttotal: 1m 52s\tremaining: 9.23s\n",
      "462:\ttotal: 1m 52s\tremaining: 8.99s\n",
      "463:\ttotal: 1m 52s\tremaining: 8.74s\n",
      "464:\ttotal: 1m 53s\tremaining: 8.51s\n",
      "465:\ttotal: 1m 53s\tremaining: 8.26s\n",
      "466:\ttotal: 1m 53s\tremaining: 8.02s\n",
      "467:\ttotal: 1m 53s\tremaining: 7.78s\n",
      "468:\ttotal: 1m 54s\tremaining: 7.54s\n",
      "469:\ttotal: 1m 54s\tremaining: 7.29s\n",
      "470:\ttotal: 1m 54s\tremaining: 7.05s\n",
      "471:\ttotal: 1m 54s\tremaining: 6.82s\n",
      "472:\ttotal: 1m 55s\tremaining: 6.57s\n",
      "473:\ttotal: 1m 55s\tremaining: 6.33s\n",
      "474:\ttotal: 1m 55s\tremaining: 6.09s\n",
      "475:\ttotal: 1m 55s\tremaining: 5.84s\n",
      "476:\ttotal: 1m 56s\tremaining: 5.6s\n",
      "477:\ttotal: 1m 56s\tremaining: 5.36s\n",
      "478:\ttotal: 1m 56s\tremaining: 5.12s\n",
      "479:\ttotal: 1m 57s\tremaining: 4.88s\n",
      "480:\ttotal: 1m 57s\tremaining: 4.64s\n",
      "481:\ttotal: 1m 57s\tremaining: 4.39s\n",
      "482:\ttotal: 1m 57s\tremaining: 4.15s\n",
      "483:\ttotal: 1m 58s\tremaining: 3.9s\n",
      "484:\ttotal: 1m 58s\tremaining: 3.66s\n",
      "485:\ttotal: 1m 58s\tremaining: 3.42s\n",
      "486:\ttotal: 1m 58s\tremaining: 3.17s\n",
      "487:\ttotal: 1m 59s\tremaining: 2.93s\n",
      "488:\ttotal: 1m 59s\tremaining: 2.68s\n",
      "489:\ttotal: 1m 59s\tremaining: 2.44s\n",
      "490:\ttotal: 1m 59s\tremaining: 2.19s\n",
      "491:\ttotal: 2m\tremaining: 1.95s\n",
      "492:\ttotal: 2m\tremaining: 1.71s\n",
      "493:\ttotal: 2m\tremaining: 1.47s\n",
      "494:\ttotal: 2m\tremaining: 1.22s\n",
      "495:\ttotal: 2m 1s\tremaining: 978ms\n",
      "496:\ttotal: 2m 1s\tremaining: 733ms\n",
      "497:\ttotal: 2m 1s\tremaining: 489ms\n",
      "498:\ttotal: 2m 1s\tremaining: 244ms\n",
      "499:\ttotal: 2m 2s\tremaining: 0us\n",
      "0:\ttotal: 199ms\tremaining: 1m 39s\n",
      "1:\ttotal: 408ms\tremaining: 1m 41s\n",
      "2:\ttotal: 648ms\tremaining: 1m 47s\n",
      "3:\ttotal: 862ms\tremaining: 1m 46s\n",
      "4:\ttotal: 1.09s\tremaining: 1m 47s\n",
      "5:\ttotal: 1.3s\tremaining: 1m 46s\n",
      "6:\ttotal: 1.52s\tremaining: 1m 46s\n",
      "7:\ttotal: 1.84s\tremaining: 1m 53s\n",
      "8:\ttotal: 2.06s\tremaining: 1m 52s\n",
      "9:\ttotal: 2.4s\tremaining: 1m 57s\n",
      "10:\ttotal: 2.62s\tremaining: 1m 56s\n",
      "11:\ttotal: 2.96s\tremaining: 2m\n",
      "12:\ttotal: 3.2s\tremaining: 1m 59s\n",
      "13:\ttotal: 3.49s\tremaining: 2m 1s\n",
      "14:\ttotal: 3.7s\tremaining: 1m 59s\n",
      "15:\ttotal: 3.91s\tremaining: 1m 58s\n",
      "16:\ttotal: 4.12s\tremaining: 1m 57s\n",
      "17:\ttotal: 4.32s\tremaining: 1m 55s\n",
      "18:\ttotal: 4.54s\tremaining: 1m 54s\n",
      "19:\ttotal: 4.75s\tremaining: 1m 53s\n",
      "20:\ttotal: 4.96s\tremaining: 1m 53s\n",
      "21:\ttotal: 5.17s\tremaining: 1m 52s\n",
      "22:\ttotal: 5.38s\tremaining: 1m 51s\n",
      "23:\ttotal: 5.69s\tremaining: 1m 52s\n",
      "24:\ttotal: 5.95s\tremaining: 1m 53s\n",
      "25:\ttotal: 6.31s\tremaining: 1m 55s\n",
      "26:\ttotal: 6.7s\tremaining: 1m 57s\n",
      "27:\ttotal: 7s\tremaining: 1m 58s\n",
      "28:\ttotal: 7.3s\tremaining: 1m 58s\n",
      "29:\ttotal: 7.61s\tremaining: 1m 59s\n",
      "30:\ttotal: 7.93s\tremaining: 2m\n",
      "31:\ttotal: 8.28s\tremaining: 2m 1s\n",
      "32:\ttotal: 8.59s\tremaining: 2m 1s\n",
      "33:\ttotal: 8.82s\tremaining: 2m\n",
      "34:\ttotal: 9.03s\tremaining: 1m 59s\n",
      "35:\ttotal: 9.31s\tremaining: 2m\n",
      "36:\ttotal: 9.67s\tremaining: 2m 1s\n",
      "37:\ttotal: 9.88s\tremaining: 2m\n",
      "38:\ttotal: 10.2s\tremaining: 2m\n",
      "39:\ttotal: 10.5s\tremaining: 2m\n",
      "40:\ttotal: 10.9s\tremaining: 2m 1s\n",
      "41:\ttotal: 11.1s\tremaining: 2m\n",
      "42:\ttotal: 11.3s\tremaining: 1m 59s\n",
      "43:\ttotal: 11.5s\tremaining: 1m 59s\n",
      "44:\ttotal: 11.7s\tremaining: 1m 58s\n",
      "45:\ttotal: 11.9s\tremaining: 1m 57s\n",
      "46:\ttotal: 12.1s\tremaining: 1m 56s\n",
      "47:\ttotal: 12.5s\tremaining: 1m 57s\n",
      "48:\ttotal: 12.8s\tremaining: 1m 57s\n",
      "49:\ttotal: 13s\tremaining: 1m 57s\n",
      "50:\ttotal: 13.4s\tremaining: 1m 57s\n",
      "51:\ttotal: 13.6s\tremaining: 1m 57s\n",
      "52:\ttotal: 13.8s\tremaining: 1m 56s\n",
      "53:\ttotal: 14.2s\tremaining: 1m 56s\n",
      "54:\ttotal: 14.5s\tremaining: 1m 57s\n",
      "55:\ttotal: 14.7s\tremaining: 1m 56s\n",
      "56:\ttotal: 15.1s\tremaining: 1m 57s\n",
      "57:\ttotal: 15.4s\tremaining: 1m 57s\n",
      "58:\ttotal: 15.8s\tremaining: 1m 57s\n",
      "59:\ttotal: 16.1s\tremaining: 1m 58s\n",
      "60:\ttotal: 16.4s\tremaining: 1m 58s\n",
      "61:\ttotal: 16.7s\tremaining: 1m 57s\n",
      "62:\ttotal: 16.9s\tremaining: 1m 57s\n",
      "63:\ttotal: 17.1s\tremaining: 1m 56s\n",
      "64:\ttotal: 17.4s\tremaining: 1m 56s\n",
      "65:\ttotal: 17.6s\tremaining: 1m 55s\n",
      "66:\ttotal: 17.8s\tremaining: 1m 55s\n",
      "67:\ttotal: 18.1s\tremaining: 1m 54s\n",
      "68:\ttotal: 18.4s\tremaining: 1m 54s\n",
      "69:\ttotal: 18.6s\tremaining: 1m 54s\n",
      "70:\ttotal: 18.9s\tremaining: 1m 54s\n",
      "71:\ttotal: 19.3s\tremaining: 1m 54s\n",
      "72:\ttotal: 19.5s\tremaining: 1m 54s\n",
      "73:\ttotal: 19.7s\tremaining: 1m 53s\n",
      "74:\ttotal: 20s\tremaining: 1m 53s\n",
      "75:\ttotal: 20.3s\tremaining: 1m 53s\n",
      "76:\ttotal: 20.7s\tremaining: 1m 53s\n",
      "77:\ttotal: 21s\tremaining: 1m 53s\n",
      "78:\ttotal: 21.3s\tremaining: 1m 53s\n",
      "79:\ttotal: 21.6s\tremaining: 1m 53s\n",
      "80:\ttotal: 21.9s\tremaining: 1m 53s\n",
      "81:\ttotal: 22.2s\tremaining: 1m 53s\n",
      "82:\ttotal: 22.6s\tremaining: 1m 53s\n",
      "83:\ttotal: 22.9s\tremaining: 1m 53s\n",
      "84:\ttotal: 23.1s\tremaining: 1m 52s\n",
      "85:\ttotal: 23.3s\tremaining: 1m 52s\n",
      "86:\ttotal: 23.6s\tremaining: 1m 51s\n",
      "87:\ttotal: 23.9s\tremaining: 1m 51s\n",
      "88:\ttotal: 24.2s\tremaining: 1m 51s\n",
      "89:\ttotal: 24.4s\tremaining: 1m 51s\n",
      "90:\ttotal: 24.6s\tremaining: 1m 50s\n",
      "91:\ttotal: 24.9s\tremaining: 1m 50s\n",
      "92:\ttotal: 25.1s\tremaining: 1m 49s\n",
      "93:\ttotal: 25.3s\tremaining: 1m 49s\n",
      "94:\ttotal: 25.6s\tremaining: 1m 48s\n",
      "95:\ttotal: 25.8s\tremaining: 1m 48s\n",
      "96:\ttotal: 26s\tremaining: 1m 48s\n",
      "97:\ttotal: 26.2s\tremaining: 1m 47s\n",
      "98:\ttotal: 26.5s\tremaining: 1m 47s\n",
      "99:\ttotal: 26.7s\tremaining: 1m 46s\n",
      "100:\ttotal: 26.9s\tremaining: 1m 46s\n",
      "101:\ttotal: 27.1s\tremaining: 1m 45s\n",
      "102:\ttotal: 27.3s\tremaining: 1m 45s\n",
      "103:\ttotal: 27.6s\tremaining: 1m 44s\n",
      "104:\ttotal: 27.8s\tremaining: 1m 44s\n",
      "105:\ttotal: 28s\tremaining: 1m 44s\n",
      "106:\ttotal: 28.2s\tremaining: 1m 43s\n",
      "107:\ttotal: 28.5s\tremaining: 1m 43s\n",
      "108:\ttotal: 28.8s\tremaining: 1m 43s\n",
      "109:\ttotal: 29s\tremaining: 1m 42s\n",
      "110:\ttotal: 29.2s\tremaining: 1m 42s\n",
      "111:\ttotal: 29.6s\tremaining: 1m 42s\n",
      "112:\ttotal: 29.9s\tremaining: 1m 42s\n",
      "113:\ttotal: 30.2s\tremaining: 1m 42s\n",
      "114:\ttotal: 30.5s\tremaining: 1m 42s\n",
      "115:\ttotal: 30.8s\tremaining: 1m 42s\n",
      "116:\ttotal: 31.3s\tremaining: 1m 42s\n",
      "117:\ttotal: 31.6s\tremaining: 1m 42s\n",
      "118:\ttotal: 32s\tremaining: 1m 42s\n",
      "119:\ttotal: 32.3s\tremaining: 1m 42s\n",
      "120:\ttotal: 32.7s\tremaining: 1m 42s\n",
      "121:\ttotal: 33s\tremaining: 1m 42s\n",
      "122:\ttotal: 33.2s\tremaining: 1m 41s\n",
      "123:\ttotal: 33.5s\tremaining: 1m 41s\n",
      "124:\ttotal: 33.8s\tremaining: 1m 41s\n",
      "125:\ttotal: 34s\tremaining: 1m 40s\n",
      "126:\ttotal: 34.3s\tremaining: 1m 40s\n",
      "127:\ttotal: 34.5s\tremaining: 1m 40s\n",
      "128:\ttotal: 34.7s\tremaining: 1m 39s\n",
      "129:\ttotal: 35s\tremaining: 1m 39s\n",
      "130:\ttotal: 35.2s\tremaining: 1m 39s\n",
      "131:\ttotal: 35.4s\tremaining: 1m 38s\n",
      "132:\ttotal: 35.7s\tremaining: 1m 38s\n",
      "133:\ttotal: 35.9s\tremaining: 1m 38s\n",
      "134:\ttotal: 36.1s\tremaining: 1m 37s\n",
      "135:\ttotal: 36.4s\tremaining: 1m 37s\n",
      "136:\ttotal: 36.6s\tremaining: 1m 36s\n",
      "137:\ttotal: 36.8s\tremaining: 1m 36s\n",
      "138:\ttotal: 37s\tremaining: 1m 36s\n",
      "139:\ttotal: 37.2s\tremaining: 1m 35s\n",
      "140:\ttotal: 37.4s\tremaining: 1m 35s\n",
      "141:\ttotal: 37.6s\tremaining: 1m 34s\n",
      "142:\ttotal: 37.9s\tremaining: 1m 34s\n",
      "143:\ttotal: 38.1s\tremaining: 1m 34s\n",
      "144:\ttotal: 38.5s\tremaining: 1m 34s\n",
      "145:\ttotal: 38.8s\tremaining: 1m 34s\n",
      "146:\ttotal: 39.1s\tremaining: 1m 33s\n",
      "147:\ttotal: 39.4s\tremaining: 1m 33s\n",
      "148:\ttotal: 39.6s\tremaining: 1m 33s\n",
      "149:\ttotal: 39.8s\tremaining: 1m 32s\n",
      "150:\ttotal: 40.1s\tremaining: 1m 32s\n",
      "151:\ttotal: 40.4s\tremaining: 1m 32s\n",
      "152:\ttotal: 40.7s\tremaining: 1m 32s\n",
      "153:\ttotal: 41s\tremaining: 1m 32s\n",
      "154:\ttotal: 41.2s\tremaining: 1m 31s\n",
      "155:\ttotal: 41.5s\tremaining: 1m 31s\n",
      "156:\ttotal: 41.7s\tremaining: 1m 31s\n",
      "157:\ttotal: 41.9s\tremaining: 1m 30s\n",
      "158:\ttotal: 42.1s\tremaining: 1m 30s\n",
      "159:\ttotal: 42.4s\tremaining: 1m 30s\n",
      "160:\ttotal: 42.7s\tremaining: 1m 29s\n",
      "161:\ttotal: 43s\tremaining: 1m 29s\n",
      "162:\ttotal: 43.2s\tremaining: 1m 29s\n",
      "163:\ttotal: 43.4s\tremaining: 1m 28s\n",
      "164:\ttotal: 43.6s\tremaining: 1m 28s\n",
      "165:\ttotal: 43.8s\tremaining: 1m 28s\n",
      "166:\ttotal: 44s\tremaining: 1m 27s\n",
      "167:\ttotal: 44.2s\tremaining: 1m 27s\n",
      "168:\ttotal: 44.5s\tremaining: 1m 27s\n",
      "169:\ttotal: 44.8s\tremaining: 1m 26s\n",
      "170:\ttotal: 45s\tremaining: 1m 26s\n",
      "171:\ttotal: 45.4s\tremaining: 1m 26s\n",
      "172:\ttotal: 45.6s\tremaining: 1m 26s\n",
      "173:\ttotal: 45.8s\tremaining: 1m 25s\n",
      "174:\ttotal: 46.1s\tremaining: 1m 25s\n",
      "175:\ttotal: 46.3s\tremaining: 1m 25s\n",
      "176:\ttotal: 46.5s\tremaining: 1m 24s\n",
      "177:\ttotal: 46.8s\tremaining: 1m 24s\n",
      "178:\ttotal: 47s\tremaining: 1m 24s\n",
      "179:\ttotal: 47.3s\tremaining: 1m 24s\n",
      "180:\ttotal: 47.5s\tremaining: 1m 23s\n",
      "181:\ttotal: 47.7s\tremaining: 1m 23s\n",
      "182:\ttotal: 47.9s\tremaining: 1m 22s\n",
      "183:\ttotal: 48.1s\tremaining: 1m 22s\n",
      "184:\ttotal: 48.3s\tremaining: 1m 22s\n",
      "185:\ttotal: 48.5s\tremaining: 1m 21s\n",
      "186:\ttotal: 48.8s\tremaining: 1m 21s\n",
      "187:\ttotal: 49s\tremaining: 1m 21s\n",
      "188:\ttotal: 49.2s\tremaining: 1m 20s\n",
      "189:\ttotal: 49.4s\tremaining: 1m 20s\n",
      "190:\ttotal: 49.6s\tremaining: 1m 20s\n",
      "191:\ttotal: 49.9s\tremaining: 1m 20s\n",
      "192:\ttotal: 50.2s\tremaining: 1m 19s\n",
      "193:\ttotal: 50.4s\tremaining: 1m 19s\n",
      "194:\ttotal: 50.7s\tremaining: 1m 19s\n",
      "195:\ttotal: 51s\tremaining: 1m 19s\n",
      "196:\ttotal: 51.3s\tremaining: 1m 18s\n",
      "197:\ttotal: 51.7s\tremaining: 1m 18s\n",
      "198:\ttotal: 52s\tremaining: 1m 18s\n",
      "199:\ttotal: 52.3s\tremaining: 1m 18s\n",
      "200:\ttotal: 52.6s\tremaining: 1m 18s\n",
      "201:\ttotal: 52.9s\tremaining: 1m 18s\n",
      "202:\ttotal: 53.2s\tremaining: 1m 17s\n",
      "203:\ttotal: 53.5s\tremaining: 1m 17s\n",
      "204:\ttotal: 53.8s\tremaining: 1m 17s\n",
      "205:\ttotal: 54.1s\tremaining: 1m 17s\n",
      "206:\ttotal: 54.4s\tremaining: 1m 17s\n",
      "207:\ttotal: 54.7s\tremaining: 1m 16s\n",
      "208:\ttotal: 55s\tremaining: 1m 16s\n",
      "209:\ttotal: 55.4s\tremaining: 1m 16s\n",
      "210:\ttotal: 55.6s\tremaining: 1m 16s\n",
      "211:\ttotal: 55.9s\tremaining: 1m 15s\n",
      "212:\ttotal: 56.3s\tremaining: 1m 15s\n",
      "213:\ttotal: 56.5s\tremaining: 1m 15s\n",
      "214:\ttotal: 56.8s\tremaining: 1m 15s\n",
      "215:\ttotal: 57.2s\tremaining: 1m 15s\n",
      "216:\ttotal: 57.5s\tremaining: 1m 14s\n",
      "217:\ttotal: 57.7s\tremaining: 1m 14s\n",
      "218:\ttotal: 58s\tremaining: 1m 14s\n",
      "219:\ttotal: 58.2s\tremaining: 1m 14s\n",
      "220:\ttotal: 58.5s\tremaining: 1m 13s\n",
      "221:\ttotal: 58.8s\tremaining: 1m 13s\n",
      "222:\ttotal: 59.2s\tremaining: 1m 13s\n",
      "223:\ttotal: 59.5s\tremaining: 1m 13s\n",
      "224:\ttotal: 59.7s\tremaining: 1m 13s\n",
      "225:\ttotal: 1m\tremaining: 1m 12s\n",
      "226:\ttotal: 1m\tremaining: 1m 12s\n",
      "227:\ttotal: 1m\tremaining: 1m 12s\n",
      "228:\ttotal: 1m\tremaining: 1m 12s\n",
      "229:\ttotal: 1m 1s\tremaining: 1m 11s\n",
      "230:\ttotal: 1m 1s\tremaining: 1m 11s\n",
      "231:\ttotal: 1m 1s\tremaining: 1m 11s\n",
      "232:\ttotal: 1m 2s\tremaining: 1m 11s\n",
      "233:\ttotal: 1m 2s\tremaining: 1m 10s\n",
      "234:\ttotal: 1m 2s\tremaining: 1m 10s\n",
      "235:\ttotal: 1m 3s\tremaining: 1m 10s\n",
      "236:\ttotal: 1m 3s\tremaining: 1m 10s\n",
      "237:\ttotal: 1m 3s\tremaining: 1m 10s\n",
      "238:\ttotal: 1m 4s\tremaining: 1m 9s\n",
      "239:\ttotal: 1m 4s\tremaining: 1m 9s\n",
      "240:\ttotal: 1m 4s\tremaining: 1m 9s\n",
      "241:\ttotal: 1m 5s\tremaining: 1m 9s\n",
      "242:\ttotal: 1m 5s\tremaining: 1m 9s\n",
      "243:\ttotal: 1m 5s\tremaining: 1m 8s\n",
      "244:\ttotal: 1m 6s\tremaining: 1m 8s\n",
      "245:\ttotal: 1m 6s\tremaining: 1m 8s\n",
      "246:\ttotal: 1m 6s\tremaining: 1m 8s\n",
      "247:\ttotal: 1m 7s\tremaining: 1m 8s\n",
      "248:\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "249:\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "250:\ttotal: 1m 8s\tremaining: 1m 7s\n",
      "251:\ttotal: 1m 8s\tremaining: 1m 7s\n",
      "252:\ttotal: 1m 8s\tremaining: 1m 7s\n",
      "253:\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "254:\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "255:\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "256:\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "257:\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "258:\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "259:\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "260:\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "261:\ttotal: 1m 11s\tremaining: 1m 4s\n",
      "262:\ttotal: 1m 11s\tremaining: 1m 4s\n",
      "263:\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "264:\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "265:\ttotal: 1m 12s\tremaining: 1m 3s\n",
      "266:\ttotal: 1m 12s\tremaining: 1m 3s\n",
      "267:\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "268:\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "269:\ttotal: 1m 13s\tremaining: 1m 2s\n",
      "270:\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "271:\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "272:\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "273:\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "274:\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "275:\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "276:\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "277:\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "278:\ttotal: 1m 16s\tremaining: 1m\n",
      "279:\ttotal: 1m 17s\tremaining: 1m\n",
      "280:\ttotal: 1m 17s\tremaining: 1m\n",
      "281:\ttotal: 1m 17s\tremaining: 1m\n",
      "282:\ttotal: 1m 17s\tremaining: 59.8s\n",
      "283:\ttotal: 1m 18s\tremaining: 59.5s\n",
      "284:\ttotal: 1m 18s\tremaining: 59.3s\n",
      "285:\ttotal: 1m 18s\tremaining: 59s\n",
      "286:\ttotal: 1m 19s\tremaining: 58.8s\n",
      "287:\ttotal: 1m 19s\tremaining: 58.5s\n",
      "288:\ttotal: 1m 19s\tremaining: 58.3s\n",
      "289:\ttotal: 1m 20s\tremaining: 58s\n",
      "290:\ttotal: 1m 20s\tremaining: 57.8s\n",
      "291:\ttotal: 1m 20s\tremaining: 57.5s\n",
      "292:\ttotal: 1m 21s\tremaining: 57.2s\n",
      "293:\ttotal: 1m 21s\tremaining: 57s\n",
      "294:\ttotal: 1m 21s\tremaining: 56.7s\n",
      "295:\ttotal: 1m 21s\tremaining: 56.5s\n",
      "296:\ttotal: 1m 22s\tremaining: 56.2s\n",
      "297:\ttotal: 1m 22s\tremaining: 56s\n",
      "298:\ttotal: 1m 22s\tremaining: 55.7s\n",
      "299:\ttotal: 1m 23s\tremaining: 55.4s\n",
      "300:\ttotal: 1m 23s\tremaining: 55.1s\n",
      "301:\ttotal: 1m 23s\tremaining: 54.9s\n",
      "302:\ttotal: 1m 24s\tremaining: 54.7s\n",
      "303:\ttotal: 1m 24s\tremaining: 54.4s\n",
      "304:\ttotal: 1m 24s\tremaining: 54.1s\n",
      "305:\ttotal: 1m 24s\tremaining: 53.9s\n",
      "306:\ttotal: 1m 25s\tremaining: 53.6s\n",
      "307:\ttotal: 1m 25s\tremaining: 53.4s\n",
      "308:\ttotal: 1m 25s\tremaining: 53.1s\n",
      "309:\ttotal: 1m 26s\tremaining: 52.8s\n",
      "310:\ttotal: 1m 26s\tremaining: 52.6s\n",
      "311:\ttotal: 1m 26s\tremaining: 52.4s\n",
      "312:\ttotal: 1m 27s\tremaining: 52.1s\n",
      "313:\ttotal: 1m 27s\tremaining: 51.8s\n",
      "314:\ttotal: 1m 27s\tremaining: 51.6s\n",
      "315:\ttotal: 1m 28s\tremaining: 51.3s\n",
      "316:\ttotal: 1m 28s\tremaining: 51s\n",
      "317:\ttotal: 1m 28s\tremaining: 50.7s\n",
      "318:\ttotal: 1m 28s\tremaining: 50.5s\n",
      "319:\ttotal: 1m 29s\tremaining: 50.2s\n",
      "320:\ttotal: 1m 29s\tremaining: 50s\n",
      "321:\ttotal: 1m 29s\tremaining: 49.7s\n",
      "322:\ttotal: 1m 30s\tremaining: 49.4s\n",
      "323:\ttotal: 1m 30s\tremaining: 49.1s\n",
      "324:\ttotal: 1m 30s\tremaining: 48.9s\n",
      "325:\ttotal: 1m 31s\tremaining: 48.6s\n",
      "326:\ttotal: 1m 31s\tremaining: 48.3s\n",
      "327:\ttotal: 1m 31s\tremaining: 48.1s\n",
      "328:\ttotal: 1m 31s\tremaining: 47.8s\n",
      "329:\ttotal: 1m 32s\tremaining: 47.5s\n",
      "330:\ttotal: 1m 32s\tremaining: 47.2s\n",
      "331:\ttotal: 1m 32s\tremaining: 46.9s\n",
      "332:\ttotal: 1m 32s\tremaining: 46.6s\n",
      "333:\ttotal: 1m 33s\tremaining: 46.3s\n",
      "334:\ttotal: 1m 33s\tremaining: 46s\n",
      "335:\ttotal: 1m 33s\tremaining: 45.7s\n",
      "336:\ttotal: 1m 33s\tremaining: 45.4s\n",
      "337:\ttotal: 1m 34s\tremaining: 45.2s\n",
      "338:\ttotal: 1m 34s\tremaining: 44.9s\n",
      "339:\ttotal: 1m 34s\tremaining: 44.6s\n",
      "340:\ttotal: 1m 35s\tremaining: 44.3s\n",
      "341:\ttotal: 1m 35s\tremaining: 44.1s\n",
      "342:\ttotal: 1m 35s\tremaining: 43.8s\n",
      "343:\ttotal: 1m 35s\tremaining: 43.5s\n",
      "344:\ttotal: 1m 36s\tremaining: 43.2s\n",
      "345:\ttotal: 1m 36s\tremaining: 42.9s\n",
      "346:\ttotal: 1m 36s\tremaining: 42.7s\n",
      "347:\ttotal: 1m 36s\tremaining: 42.4s\n",
      "348:\ttotal: 1m 37s\tremaining: 42.1s\n",
      "349:\ttotal: 1m 37s\tremaining: 41.9s\n",
      "350:\ttotal: 1m 38s\tremaining: 41.6s\n",
      "351:\ttotal: 1m 38s\tremaining: 41.4s\n",
      "352:\ttotal: 1m 38s\tremaining: 41.1s\n",
      "353:\ttotal: 1m 39s\tremaining: 40.8s\n",
      "354:\ttotal: 1m 39s\tremaining: 40.6s\n",
      "355:\ttotal: 1m 39s\tremaining: 40.3s\n",
      "356:\ttotal: 1m 39s\tremaining: 40s\n",
      "357:\ttotal: 1m 40s\tremaining: 39.7s\n",
      "358:\ttotal: 1m 40s\tremaining: 39.5s\n",
      "359:\ttotal: 1m 40s\tremaining: 39.2s\n",
      "360:\ttotal: 1m 40s\tremaining: 38.9s\n",
      "361:\ttotal: 1m 41s\tremaining: 38.6s\n",
      "362:\ttotal: 1m 41s\tremaining: 38.3s\n",
      "363:\ttotal: 1m 41s\tremaining: 38s\n",
      "364:\ttotal: 1m 41s\tremaining: 37.7s\n",
      "365:\ttotal: 1m 42s\tremaining: 37.4s\n",
      "366:\ttotal: 1m 42s\tremaining: 37.1s\n",
      "367:\ttotal: 1m 42s\tremaining: 36.8s\n",
      "368:\ttotal: 1m 42s\tremaining: 36.5s\n",
      "369:\ttotal: 1m 42s\tremaining: 36.2s\n",
      "370:\ttotal: 1m 43s\tremaining: 35.9s\n",
      "371:\ttotal: 1m 43s\tremaining: 35.6s\n",
      "372:\ttotal: 1m 43s\tremaining: 35.3s\n",
      "373:\ttotal: 1m 43s\tremaining: 35s\n",
      "374:\ttotal: 1m 44s\tremaining: 34.7s\n",
      "375:\ttotal: 1m 44s\tremaining: 34.4s\n",
      "376:\ttotal: 1m 44s\tremaining: 34.1s\n",
      "377:\ttotal: 1m 44s\tremaining: 33.8s\n",
      "378:\ttotal: 1m 44s\tremaining: 33.5s\n",
      "379:\ttotal: 1m 45s\tremaining: 33.2s\n",
      "380:\ttotal: 1m 45s\tremaining: 33s\n",
      "381:\ttotal: 1m 45s\tremaining: 32.7s\n",
      "382:\ttotal: 1m 45s\tremaining: 32.4s\n",
      "383:\ttotal: 1m 46s\tremaining: 32.1s\n",
      "384:\ttotal: 1m 46s\tremaining: 31.8s\n",
      "385:\ttotal: 1m 46s\tremaining: 31.5s\n",
      "386:\ttotal: 1m 46s\tremaining: 31.2s\n",
      "387:\ttotal: 1m 47s\tremaining: 30.9s\n",
      "388:\ttotal: 1m 47s\tremaining: 30.6s\n",
      "389:\ttotal: 1m 47s\tremaining: 30.3s\n",
      "390:\ttotal: 1m 47s\tremaining: 30s\n",
      "391:\ttotal: 1m 47s\tremaining: 29.7s\n",
      "392:\ttotal: 1m 48s\tremaining: 29.5s\n",
      "393:\ttotal: 1m 48s\tremaining: 29.2s\n",
      "394:\ttotal: 1m 48s\tremaining: 28.9s\n",
      "395:\ttotal: 1m 48s\tremaining: 28.6s\n",
      "396:\ttotal: 1m 49s\tremaining: 28.3s\n",
      "397:\ttotal: 1m 49s\tremaining: 28s\n",
      "398:\ttotal: 1m 49s\tremaining: 27.7s\n",
      "399:\ttotal: 1m 49s\tremaining: 27.4s\n",
      "400:\ttotal: 1m 49s\tremaining: 27.1s\n",
      "401:\ttotal: 1m 50s\tremaining: 26.8s\n",
      "402:\ttotal: 1m 50s\tremaining: 26.6s\n",
      "403:\ttotal: 1m 50s\tremaining: 26.3s\n",
      "404:\ttotal: 1m 50s\tremaining: 26s\n",
      "405:\ttotal: 1m 50s\tremaining: 25.7s\n",
      "406:\ttotal: 1m 51s\tremaining: 25.4s\n",
      "407:\ttotal: 1m 51s\tremaining: 25.1s\n",
      "408:\ttotal: 1m 51s\tremaining: 24.8s\n",
      "409:\ttotal: 1m 51s\tremaining: 24.6s\n",
      "410:\ttotal: 1m 52s\tremaining: 24.3s\n",
      "411:\ttotal: 1m 52s\tremaining: 24s\n",
      "412:\ttotal: 1m 52s\tremaining: 23.7s\n",
      "413:\ttotal: 1m 52s\tremaining: 23.4s\n",
      "414:\ttotal: 1m 52s\tremaining: 23.1s\n",
      "415:\ttotal: 1m 53s\tremaining: 22.9s\n",
      "416:\ttotal: 1m 53s\tremaining: 22.6s\n",
      "417:\ttotal: 1m 53s\tremaining: 22.3s\n",
      "418:\ttotal: 1m 53s\tremaining: 22s\n",
      "419:\ttotal: 1m 54s\tremaining: 21.7s\n",
      "420:\ttotal: 1m 54s\tremaining: 21.4s\n",
      "421:\ttotal: 1m 54s\tremaining: 21.2s\n",
      "422:\ttotal: 1m 54s\tremaining: 20.9s\n",
      "423:\ttotal: 1m 54s\tremaining: 20.6s\n",
      "424:\ttotal: 1m 55s\tremaining: 20.3s\n",
      "425:\ttotal: 1m 55s\tremaining: 20s\n",
      "426:\ttotal: 1m 55s\tremaining: 19.8s\n",
      "427:\ttotal: 1m 55s\tremaining: 19.5s\n",
      "428:\ttotal: 1m 55s\tremaining: 19.2s\n",
      "429:\ttotal: 1m 56s\tremaining: 18.9s\n",
      "430:\ttotal: 1m 56s\tremaining: 18.6s\n",
      "431:\ttotal: 1m 56s\tremaining: 18.4s\n",
      "432:\ttotal: 1m 56s\tremaining: 18.1s\n",
      "433:\ttotal: 1m 57s\tremaining: 17.8s\n",
      "434:\ttotal: 1m 57s\tremaining: 17.5s\n",
      "435:\ttotal: 1m 57s\tremaining: 17.3s\n",
      "436:\ttotal: 1m 57s\tremaining: 17s\n",
      "437:\ttotal: 1m 57s\tremaining: 16.7s\n",
      "438:\ttotal: 1m 58s\tremaining: 16.4s\n",
      "439:\ttotal: 1m 58s\tremaining: 16.1s\n",
      "440:\ttotal: 1m 58s\tremaining: 15.9s\n",
      "441:\ttotal: 1m 58s\tremaining: 15.6s\n",
      "442:\ttotal: 1m 59s\tremaining: 15.3s\n",
      "443:\ttotal: 1m 59s\tremaining: 15s\n",
      "444:\ttotal: 1m 59s\tremaining: 14.8s\n",
      "445:\ttotal: 1m 59s\tremaining: 14.5s\n",
      "446:\ttotal: 1m 59s\tremaining: 14.2s\n",
      "447:\ttotal: 2m\tremaining: 13.9s\n",
      "448:\ttotal: 2m\tremaining: 13.7s\n",
      "449:\ttotal: 2m\tremaining: 13.4s\n",
      "450:\ttotal: 2m\tremaining: 13.1s\n",
      "451:\ttotal: 2m\tremaining: 12.8s\n",
      "452:\ttotal: 2m 1s\tremaining: 12.6s\n",
      "453:\ttotal: 2m 1s\tremaining: 12.3s\n",
      "454:\ttotal: 2m 1s\tremaining: 12s\n",
      "455:\ttotal: 2m 1s\tremaining: 11.8s\n",
      "456:\ttotal: 2m 2s\tremaining: 11.5s\n",
      "457:\ttotal: 2m 2s\tremaining: 11.2s\n",
      "458:\ttotal: 2m 2s\tremaining: 10.9s\n",
      "459:\ttotal: 2m 2s\tremaining: 10.7s\n",
      "460:\ttotal: 2m 2s\tremaining: 10.4s\n",
      "461:\ttotal: 2m 3s\tremaining: 10.1s\n",
      "462:\ttotal: 2m 3s\tremaining: 9.86s\n",
      "463:\ttotal: 2m 3s\tremaining: 9.59s\n",
      "464:\ttotal: 2m 3s\tremaining: 9.32s\n",
      "465:\ttotal: 2m 4s\tremaining: 9.05s\n",
      "466:\ttotal: 2m 4s\tremaining: 8.78s\n",
      "467:\ttotal: 2m 4s\tremaining: 8.51s\n",
      "468:\ttotal: 2m 4s\tremaining: 8.24s\n",
      "469:\ttotal: 2m 4s\tremaining: 7.97s\n",
      "470:\ttotal: 2m 5s\tremaining: 7.7s\n",
      "471:\ttotal: 2m 5s\tremaining: 7.43s\n",
      "472:\ttotal: 2m 5s\tremaining: 7.16s\n",
      "473:\ttotal: 2m 5s\tremaining: 6.89s\n",
      "474:\ttotal: 2m 5s\tremaining: 6.63s\n",
      "475:\ttotal: 2m 6s\tremaining: 6.36s\n",
      "476:\ttotal: 2m 6s\tremaining: 6.09s\n",
      "477:\ttotal: 2m 6s\tremaining: 5.83s\n",
      "478:\ttotal: 2m 6s\tremaining: 5.56s\n",
      "479:\ttotal: 2m 7s\tremaining: 5.29s\n",
      "480:\ttotal: 2m 7s\tremaining: 5.03s\n",
      "481:\ttotal: 2m 7s\tremaining: 4.76s\n",
      "482:\ttotal: 2m 7s\tremaining: 4.49s\n",
      "483:\ttotal: 2m 7s\tremaining: 4.23s\n",
      "484:\ttotal: 2m 8s\tremaining: 3.96s\n",
      "485:\ttotal: 2m 8s\tremaining: 3.69s\n",
      "486:\ttotal: 2m 8s\tremaining: 3.43s\n",
      "487:\ttotal: 2m 8s\tremaining: 3.17s\n",
      "488:\ttotal: 2m 8s\tremaining: 2.9s\n",
      "489:\ttotal: 2m 9s\tremaining: 2.63s\n",
      "490:\ttotal: 2m 9s\tremaining: 2.37s\n",
      "491:\ttotal: 2m 9s\tremaining: 2.11s\n",
      "492:\ttotal: 2m 9s\tremaining: 1.84s\n",
      "493:\ttotal: 2m 10s\tremaining: 1.58s\n",
      "494:\ttotal: 2m 10s\tremaining: 1.31s\n",
      "495:\ttotal: 2m 10s\tremaining: 1.05s\n",
      "496:\ttotal: 2m 10s\tremaining: 789ms\n",
      "497:\ttotal: 2m 10s\tremaining: 526ms\n",
      "498:\ttotal: 2m 11s\tremaining: 263ms\n",
      "499:\ttotal: 2m 11s\tremaining: 0us\n",
      "0:\ttotal: 196ms\tremaining: 1m 37s\n",
      "1:\ttotal: 409ms\tremaining: 1m 41s\n",
      "2:\ttotal: 631ms\tremaining: 1m 44s\n",
      "3:\ttotal: 854ms\tremaining: 1m 45s\n",
      "4:\ttotal: 1.07s\tremaining: 1m 45s\n",
      "5:\ttotal: 1.28s\tremaining: 1m 45s\n",
      "6:\ttotal: 1.51s\tremaining: 1m 46s\n",
      "7:\ttotal: 1.72s\tremaining: 1m 45s\n",
      "8:\ttotal: 1.94s\tremaining: 1m 45s\n",
      "9:\ttotal: 2.14s\tremaining: 1m 44s\n",
      "10:\ttotal: 2.35s\tremaining: 1m 44s\n",
      "11:\ttotal: 2.58s\tremaining: 1m 45s\n",
      "12:\ttotal: 2.79s\tremaining: 1m 44s\n",
      "13:\ttotal: 3.01s\tremaining: 1m 44s\n",
      "14:\ttotal: 3.22s\tremaining: 1m 44s\n",
      "15:\ttotal: 3.43s\tremaining: 1m 43s\n",
      "16:\ttotal: 3.66s\tremaining: 1m 43s\n",
      "17:\ttotal: 3.87s\tremaining: 1m 43s\n",
      "18:\ttotal: 4.08s\tremaining: 1m 43s\n",
      "19:\ttotal: 4.29s\tremaining: 1m 42s\n",
      "20:\ttotal: 4.5s\tremaining: 1m 42s\n",
      "21:\ttotal: 4.72s\tremaining: 1m 42s\n",
      "22:\ttotal: 4.94s\tremaining: 1m 42s\n",
      "23:\ttotal: 5.16s\tremaining: 1m 42s\n",
      "24:\ttotal: 5.37s\tremaining: 1m 41s\n",
      "25:\ttotal: 5.38s\tremaining: 1m 38s\n",
      "26:\ttotal: 5.6s\tremaining: 1m 38s\n",
      "27:\ttotal: 5.81s\tremaining: 1m 37s\n",
      "28:\ttotal: 6.02s\tremaining: 1m 37s\n",
      "29:\ttotal: 6.24s\tremaining: 1m 37s\n",
      "30:\ttotal: 6.45s\tremaining: 1m 37s\n",
      "31:\ttotal: 6.67s\tremaining: 1m 37s\n",
      "32:\ttotal: 6.88s\tremaining: 1m 37s\n",
      "33:\ttotal: 7.13s\tremaining: 1m 37s\n",
      "34:\ttotal: 7.35s\tremaining: 1m 37s\n",
      "35:\ttotal: 7.56s\tremaining: 1m 37s\n",
      "36:\ttotal: 7.78s\tremaining: 1m 37s\n",
      "37:\ttotal: 7.99s\tremaining: 1m 37s\n",
      "38:\ttotal: 8.2s\tremaining: 1m 36s\n",
      "39:\ttotal: 8.41s\tremaining: 1m 36s\n",
      "40:\ttotal: 8.62s\tremaining: 1m 36s\n",
      "41:\ttotal: 8.85s\tremaining: 1m 36s\n",
      "42:\ttotal: 9.05s\tremaining: 1m 36s\n",
      "43:\ttotal: 9.26s\tremaining: 1m 35s\n",
      "44:\ttotal: 9.47s\tremaining: 1m 35s\n",
      "45:\ttotal: 9.68s\tremaining: 1m 35s\n",
      "46:\ttotal: 9.91s\tremaining: 1m 35s\n",
      "47:\ttotal: 10.1s\tremaining: 1m 35s\n",
      "48:\ttotal: 10.3s\tremaining: 1m 35s\n",
      "49:\ttotal: 10.5s\tremaining: 1m 34s\n",
      "50:\ttotal: 10.8s\tremaining: 1m 34s\n",
      "51:\ttotal: 11s\tremaining: 1m 34s\n",
      "52:\ttotal: 11.2s\tremaining: 1m 34s\n",
      "53:\ttotal: 11.4s\tremaining: 1m 34s\n",
      "54:\ttotal: 11.6s\tremaining: 1m 34s\n",
      "55:\ttotal: 11.8s\tremaining: 1m 33s\n",
      "56:\ttotal: 12.1s\tremaining: 1m 33s\n",
      "57:\ttotal: 12.3s\tremaining: 1m 33s\n",
      "58:\ttotal: 12.5s\tremaining: 1m 33s\n",
      "59:\ttotal: 12.7s\tremaining: 1m 33s\n",
      "60:\ttotal: 12.9s\tremaining: 1m 33s\n",
      "61:\ttotal: 13.2s\tremaining: 1m 32s\n",
      "62:\ttotal: 13.4s\tremaining: 1m 32s\n",
      "63:\ttotal: 13.6s\tremaining: 1m 32s\n",
      "64:\ttotal: 13.8s\tremaining: 1m 32s\n",
      "65:\ttotal: 14.1s\tremaining: 1m 32s\n",
      "66:\ttotal: 14.3s\tremaining: 1m 32s\n",
      "67:\ttotal: 14.5s\tremaining: 1m 32s\n",
      "68:\ttotal: 14.7s\tremaining: 1m 31s\n",
      "69:\ttotal: 14.9s\tremaining: 1m 31s\n",
      "70:\ttotal: 15.2s\tremaining: 1m 31s\n",
      "71:\ttotal: 15.4s\tremaining: 1m 31s\n",
      "72:\ttotal: 15.6s\tremaining: 1m 31s\n",
      "73:\ttotal: 15.8s\tremaining: 1m 31s\n",
      "74:\ttotal: 16s\tremaining: 1m 30s\n",
      "75:\ttotal: 16.2s\tremaining: 1m 30s\n",
      "76:\ttotal: 16.4s\tremaining: 1m 30s\n",
      "77:\ttotal: 16.7s\tremaining: 1m 30s\n",
      "78:\ttotal: 16.9s\tremaining: 1m 29s\n",
      "79:\ttotal: 17.1s\tremaining: 1m 29s\n",
      "80:\ttotal: 17.3s\tremaining: 1m 29s\n",
      "81:\ttotal: 17.5s\tremaining: 1m 29s\n",
      "82:\ttotal: 17.7s\tremaining: 1m 29s\n",
      "83:\ttotal: 17.9s\tremaining: 1m 28s\n",
      "84:\ttotal: 18.2s\tremaining: 1m 28s\n",
      "85:\ttotal: 18.4s\tremaining: 1m 28s\n",
      "86:\ttotal: 18.6s\tremaining: 1m 28s\n",
      "87:\ttotal: 18.8s\tremaining: 1m 28s\n",
      "88:\ttotal: 19s\tremaining: 1m 27s\n",
      "89:\ttotal: 19.2s\tremaining: 1m 27s\n",
      "90:\ttotal: 19.6s\tremaining: 1m 27s\n",
      "91:\ttotal: 19.8s\tremaining: 1m 28s\n",
      "92:\ttotal: 20.1s\tremaining: 1m 28s\n",
      "93:\ttotal: 20.4s\tremaining: 1m 28s\n",
      "94:\ttotal: 20.6s\tremaining: 1m 27s\n",
      "95:\ttotal: 20.9s\tremaining: 1m 27s\n",
      "96:\ttotal: 21.1s\tremaining: 1m 27s\n",
      "97:\ttotal: 21.3s\tremaining: 1m 27s\n",
      "98:\ttotal: 21.5s\tremaining: 1m 27s\n",
      "99:\ttotal: 21.7s\tremaining: 1m 26s\n",
      "100:\ttotal: 22s\tremaining: 1m 26s\n",
      "101:\ttotal: 22.2s\tremaining: 1m 26s\n",
      "102:\ttotal: 22.4s\tremaining: 1m 26s\n",
      "103:\ttotal: 22.6s\tremaining: 1m 26s\n",
      "104:\ttotal: 22.8s\tremaining: 1m 25s\n",
      "105:\ttotal: 23s\tremaining: 1m 25s\n",
      "106:\ttotal: 23.2s\tremaining: 1m 25s\n",
      "107:\ttotal: 23.5s\tremaining: 1m 25s\n",
      "108:\ttotal: 23.7s\tremaining: 1m 24s\n",
      "109:\ttotal: 23.9s\tremaining: 1m 24s\n",
      "110:\ttotal: 24.1s\tremaining: 1m 24s\n",
      "111:\ttotal: 24.3s\tremaining: 1m 24s\n",
      "112:\ttotal: 24.5s\tremaining: 1m 23s\n",
      "113:\ttotal: 24.8s\tremaining: 1m 23s\n",
      "114:\ttotal: 25s\tremaining: 1m 23s\n",
      "115:\ttotal: 25.2s\tremaining: 1m 23s\n",
      "116:\ttotal: 25.4s\tremaining: 1m 23s\n",
      "117:\ttotal: 25.6s\tremaining: 1m 22s\n",
      "118:\ttotal: 25.9s\tremaining: 1m 22s\n",
      "119:\ttotal: 26.1s\tremaining: 1m 22s\n",
      "120:\ttotal: 26.4s\tremaining: 1m 22s\n",
      "121:\ttotal: 26.6s\tremaining: 1m 22s\n",
      "122:\ttotal: 26.8s\tremaining: 1m 22s\n",
      "123:\ttotal: 27s\tremaining: 1m 21s\n",
      "124:\ttotal: 27.2s\tremaining: 1m 21s\n",
      "125:\ttotal: 27.4s\tremaining: 1m 21s\n",
      "126:\ttotal: 27.7s\tremaining: 1m 21s\n",
      "127:\ttotal: 27.9s\tremaining: 1m 21s\n",
      "128:\ttotal: 28.1s\tremaining: 1m 20s\n",
      "129:\ttotal: 28.3s\tremaining: 1m 20s\n",
      "130:\ttotal: 28.6s\tremaining: 1m 20s\n",
      "131:\ttotal: 28.8s\tremaining: 1m 20s\n",
      "132:\ttotal: 29.1s\tremaining: 1m 20s\n",
      "133:\ttotal: 29.3s\tremaining: 1m 20s\n",
      "134:\ttotal: 29.5s\tremaining: 1m 19s\n",
      "135:\ttotal: 29.7s\tremaining: 1m 19s\n",
      "136:\ttotal: 29.9s\tremaining: 1m 19s\n",
      "137:\ttotal: 30.2s\tremaining: 1m 19s\n",
      "138:\ttotal: 30.4s\tremaining: 1m 18s\n",
      "139:\ttotal: 30.6s\tremaining: 1m 18s\n",
      "140:\ttotal: 30.8s\tremaining: 1m 18s\n",
      "141:\ttotal: 31s\tremaining: 1m 18s\n",
      "142:\ttotal: 31.2s\tremaining: 1m 18s\n",
      "143:\ttotal: 31.5s\tremaining: 1m 17s\n",
      "144:\ttotal: 31.7s\tremaining: 1m 17s\n",
      "145:\ttotal: 31.9s\tremaining: 1m 17s\n",
      "146:\ttotal: 32.1s\tremaining: 1m 17s\n",
      "147:\ttotal: 32.3s\tremaining: 1m 16s\n",
      "148:\ttotal: 32.5s\tremaining: 1m 16s\n",
      "149:\ttotal: 32.7s\tremaining: 1m 16s\n",
      "150:\ttotal: 33s\tremaining: 1m 16s\n",
      "151:\ttotal: 33.2s\tremaining: 1m 15s\n",
      "152:\ttotal: 33.4s\tremaining: 1m 15s\n",
      "153:\ttotal: 33.6s\tremaining: 1m 15s\n",
      "154:\ttotal: 33.8s\tremaining: 1m 15s\n",
      "155:\ttotal: 34s\tremaining: 1m 15s\n",
      "156:\ttotal: 34.2s\tremaining: 1m 14s\n",
      "157:\ttotal: 34.4s\tremaining: 1m 14s\n",
      "158:\ttotal: 34.6s\tremaining: 1m 14s\n",
      "159:\ttotal: 34.9s\tremaining: 1m 14s\n",
      "160:\ttotal: 35.1s\tremaining: 1m 13s\n",
      "161:\ttotal: 35.3s\tremaining: 1m 13s\n",
      "162:\ttotal: 35.5s\tremaining: 1m 13s\n",
      "163:\ttotal: 35.7s\tremaining: 1m 13s\n",
      "164:\ttotal: 35.9s\tremaining: 1m 12s\n",
      "165:\ttotal: 36.2s\tremaining: 1m 12s\n",
      "166:\ttotal: 36.4s\tremaining: 1m 12s\n",
      "167:\ttotal: 36.6s\tremaining: 1m 12s\n",
      "168:\ttotal: 36.8s\tremaining: 1m 12s\n",
      "169:\ttotal: 37.1s\tremaining: 1m 11s\n",
      "170:\ttotal: 37.3s\tremaining: 1m 11s\n",
      "171:\ttotal: 37.5s\tremaining: 1m 11s\n",
      "172:\ttotal: 37.7s\tremaining: 1m 11s\n",
      "173:\ttotal: 37.9s\tremaining: 1m 11s\n",
      "174:\ttotal: 38.2s\tremaining: 1m 10s\n",
      "175:\ttotal: 38.5s\tremaining: 1m 10s\n",
      "176:\ttotal: 38.7s\tremaining: 1m 10s\n",
      "177:\ttotal: 38.9s\tremaining: 1m 10s\n",
      "178:\ttotal: 39.2s\tremaining: 1m 10s\n",
      "179:\ttotal: 39.4s\tremaining: 1m 10s\n",
      "180:\ttotal: 39.6s\tremaining: 1m 9s\n",
      "181:\ttotal: 39.8s\tremaining: 1m 9s\n",
      "182:\ttotal: 40.1s\tremaining: 1m 9s\n",
      "183:\ttotal: 40.3s\tremaining: 1m 9s\n",
      "184:\ttotal: 40.5s\tremaining: 1m 8s\n",
      "185:\ttotal: 40.7s\tremaining: 1m 8s\n",
      "186:\ttotal: 40.9s\tremaining: 1m 8s\n",
      "187:\ttotal: 41.2s\tremaining: 1m 8s\n",
      "188:\ttotal: 41.4s\tremaining: 1m 8s\n",
      "189:\ttotal: 41.6s\tremaining: 1m 7s\n",
      "190:\ttotal: 41.9s\tremaining: 1m 7s\n",
      "191:\ttotal: 42.1s\tremaining: 1m 7s\n",
      "192:\ttotal: 42.3s\tremaining: 1m 7s\n",
      "193:\ttotal: 42.5s\tremaining: 1m 7s\n",
      "194:\ttotal: 42.7s\tremaining: 1m 6s\n",
      "195:\ttotal: 42.9s\tremaining: 1m 6s\n",
      "196:\ttotal: 43.2s\tremaining: 1m 6s\n",
      "197:\ttotal: 43.4s\tremaining: 1m 6s\n",
      "198:\ttotal: 43.6s\tremaining: 1m 5s\n",
      "199:\ttotal: 43.8s\tremaining: 1m 5s\n",
      "200:\ttotal: 44.1s\tremaining: 1m 5s\n",
      "201:\ttotal: 44.3s\tremaining: 1m 5s\n",
      "202:\ttotal: 44.5s\tremaining: 1m 5s\n",
      "203:\ttotal: 44.7s\tremaining: 1m 4s\n",
      "204:\ttotal: 44.9s\tremaining: 1m 4s\n",
      "205:\ttotal: 45.2s\tremaining: 1m 4s\n",
      "206:\ttotal: 45.4s\tremaining: 1m 4s\n",
      "207:\ttotal: 45.6s\tremaining: 1m 4s\n",
      "208:\ttotal: 45.8s\tremaining: 1m 3s\n",
      "209:\ttotal: 46.1s\tremaining: 1m 3s\n",
      "210:\ttotal: 46.3s\tremaining: 1m 3s\n",
      "211:\ttotal: 46.5s\tremaining: 1m 3s\n",
      "212:\ttotal: 46.7s\tremaining: 1m 2s\n",
      "213:\ttotal: 47s\tremaining: 1m 2s\n",
      "214:\ttotal: 47.2s\tremaining: 1m 2s\n",
      "215:\ttotal: 47.4s\tremaining: 1m 2s\n",
      "216:\ttotal: 47.6s\tremaining: 1m 2s\n",
      "217:\ttotal: 47.9s\tremaining: 1m 1s\n",
      "218:\ttotal: 48.1s\tremaining: 1m 1s\n",
      "219:\ttotal: 48.3s\tremaining: 1m 1s\n",
      "220:\ttotal: 48.5s\tremaining: 1m 1s\n",
      "221:\ttotal: 48.7s\tremaining: 1m 1s\n",
      "222:\ttotal: 48.9s\tremaining: 1m\n",
      "223:\ttotal: 49.2s\tremaining: 1m\n",
      "224:\ttotal: 49.4s\tremaining: 1m\n",
      "225:\ttotal: 49.6s\tremaining: 1m\n",
      "226:\ttotal: 49.8s\tremaining: 59.9s\n",
      "227:\ttotal: 50s\tremaining: 59.7s\n",
      "228:\ttotal: 50.2s\tremaining: 59.4s\n",
      "229:\ttotal: 50.4s\tremaining: 59.2s\n",
      "230:\ttotal: 50.7s\tremaining: 59s\n",
      "231:\ttotal: 50.9s\tremaining: 58.8s\n",
      "232:\ttotal: 51.1s\tremaining: 58.6s\n",
      "233:\ttotal: 51.3s\tremaining: 58.4s\n",
      "234:\ttotal: 51.6s\tremaining: 58.1s\n",
      "235:\ttotal: 51.8s\tremaining: 57.9s\n",
      "236:\ttotal: 52s\tremaining: 57.7s\n",
      "237:\ttotal: 52.2s\tremaining: 57.5s\n",
      "238:\ttotal: 52.4s\tremaining: 57.3s\n",
      "239:\ttotal: 52.7s\tremaining: 57s\n",
      "240:\ttotal: 52.9s\tremaining: 56.8s\n",
      "241:\ttotal: 53.1s\tremaining: 56.6s\n",
      "242:\ttotal: 53.3s\tremaining: 56.4s\n",
      "243:\ttotal: 53.5s\tremaining: 56.1s\n",
      "244:\ttotal: 53.7s\tremaining: 55.9s\n",
      "245:\ttotal: 53.9s\tremaining: 55.7s\n",
      "246:\ttotal: 54.2s\tremaining: 55.5s\n",
      "247:\ttotal: 54.4s\tremaining: 55.3s\n",
      "248:\ttotal: 54.6s\tremaining: 55s\n",
      "249:\ttotal: 54.8s\tremaining: 54.8s\n",
      "250:\ttotal: 55.1s\tremaining: 54.6s\n",
      "251:\ttotal: 55.4s\tremaining: 54.5s\n",
      "252:\ttotal: 55.7s\tremaining: 54.4s\n",
      "253:\ttotal: 55.9s\tremaining: 54.1s\n",
      "254:\ttotal: 56.1s\tremaining: 53.9s\n",
      "255:\ttotal: 56.3s\tremaining: 53.7s\n",
      "256:\ttotal: 56.6s\tremaining: 53.5s\n",
      "257:\ttotal: 56.8s\tremaining: 53.2s\n",
      "258:\ttotal: 57s\tremaining: 53s\n",
      "259:\ttotal: 57.2s\tremaining: 52.8s\n",
      "260:\ttotal: 57.4s\tremaining: 52.6s\n",
      "261:\ttotal: 57.6s\tremaining: 52.3s\n",
      "262:\ttotal: 57.8s\tremaining: 52.1s\n",
      "263:\ttotal: 58s\tremaining: 51.9s\n",
      "264:\ttotal: 58.2s\tremaining: 51.7s\n",
      "265:\ttotal: 58.5s\tremaining: 51.4s\n",
      "266:\ttotal: 58.7s\tremaining: 51.2s\n",
      "267:\ttotal: 58.9s\tremaining: 51s\n",
      "268:\ttotal: 59.1s\tremaining: 50.8s\n",
      "269:\ttotal: 59.3s\tremaining: 50.5s\n",
      "270:\ttotal: 59.6s\tremaining: 50.3s\n",
      "271:\ttotal: 59.8s\tremaining: 50.1s\n",
      "272:\ttotal: 60s\tremaining: 49.9s\n",
      "273:\ttotal: 1m\tremaining: 49.7s\n",
      "274:\ttotal: 1m\tremaining: 49.4s\n",
      "275:\ttotal: 1m\tremaining: 49.2s\n",
      "276:\ttotal: 1m\tremaining: 49s\n",
      "277:\ttotal: 1m 1s\tremaining: 48.8s\n",
      "278:\ttotal: 1m 1s\tremaining: 48.6s\n",
      "279:\ttotal: 1m 1s\tremaining: 48.3s\n",
      "280:\ttotal: 1m 1s\tremaining: 48.1s\n",
      "281:\ttotal: 1m 1s\tremaining: 47.9s\n",
      "282:\ttotal: 1m 2s\tremaining: 47.7s\n",
      "283:\ttotal: 1m 2s\tremaining: 47.5s\n",
      "284:\ttotal: 1m 2s\tremaining: 47.2s\n",
      "285:\ttotal: 1m 2s\tremaining: 47s\n",
      "286:\ttotal: 1m 3s\tremaining: 46.8s\n",
      "287:\ttotal: 1m 3s\tremaining: 46.6s\n",
      "288:\ttotal: 1m 3s\tremaining: 46.3s\n",
      "289:\ttotal: 1m 3s\tremaining: 46.1s\n",
      "290:\ttotal: 1m 3s\tremaining: 45.9s\n",
      "291:\ttotal: 1m 4s\tremaining: 45.7s\n",
      "292:\ttotal: 1m 4s\tremaining: 45.4s\n",
      "293:\ttotal: 1m 4s\tremaining: 45.2s\n",
      "294:\ttotal: 1m 4s\tremaining: 45s\n",
      "295:\ttotal: 1m 4s\tremaining: 44.8s\n",
      "296:\ttotal: 1m 5s\tremaining: 44.5s\n",
      "297:\ttotal: 1m 5s\tremaining: 44.3s\n",
      "298:\ttotal: 1m 5s\tremaining: 44.1s\n",
      "299:\ttotal: 1m 5s\tremaining: 43.9s\n",
      "300:\ttotal: 1m 6s\tremaining: 43.7s\n",
      "301:\ttotal: 1m 6s\tremaining: 43.4s\n",
      "302:\ttotal: 1m 6s\tremaining: 43.2s\n",
      "303:\ttotal: 1m 6s\tremaining: 43s\n",
      "304:\ttotal: 1m 6s\tremaining: 42.8s\n",
      "305:\ttotal: 1m 7s\tremaining: 42.6s\n",
      "306:\ttotal: 1m 7s\tremaining: 42.3s\n",
      "307:\ttotal: 1m 7s\tremaining: 42.1s\n",
      "308:\ttotal: 1m 7s\tremaining: 41.9s\n",
      "309:\ttotal: 1m 8s\tremaining: 41.7s\n",
      "310:\ttotal: 1m 8s\tremaining: 41.5s\n",
      "311:\ttotal: 1m 8s\tremaining: 41.2s\n",
      "312:\ttotal: 1m 8s\tremaining: 41s\n",
      "313:\ttotal: 1m 8s\tremaining: 40.8s\n",
      "314:\ttotal: 1m 9s\tremaining: 40.6s\n",
      "315:\ttotal: 1m 9s\tremaining: 40.3s\n",
      "316:\ttotal: 1m 9s\tremaining: 40.1s\n",
      "317:\ttotal: 1m 9s\tremaining: 39.9s\n",
      "318:\ttotal: 1m 9s\tremaining: 39.7s\n",
      "319:\ttotal: 1m 10s\tremaining: 39.5s\n",
      "320:\ttotal: 1m 10s\tremaining: 39.2s\n",
      "321:\ttotal: 1m 10s\tremaining: 39s\n",
      "322:\ttotal: 1m 10s\tremaining: 38.8s\n",
      "323:\ttotal: 1m 10s\tremaining: 38.6s\n",
      "324:\ttotal: 1m 11s\tremaining: 38.3s\n",
      "325:\ttotal: 1m 11s\tremaining: 38.1s\n",
      "326:\ttotal: 1m 11s\tremaining: 37.9s\n",
      "327:\ttotal: 1m 11s\tremaining: 37.7s\n",
      "328:\ttotal: 1m 12s\tremaining: 37.5s\n",
      "329:\ttotal: 1m 12s\tremaining: 37.3s\n",
      "330:\ttotal: 1m 12s\tremaining: 36.9s\n",
      "331:\ttotal: 1m 12s\tremaining: 36.7s\n",
      "332:\ttotal: 1m 12s\tremaining: 36.5s\n",
      "333:\ttotal: 1m 12s\tremaining: 36.3s\n",
      "334:\ttotal: 1m 13s\tremaining: 36s\n",
      "335:\ttotal: 1m 13s\tremaining: 35.8s\n",
      "336:\ttotal: 1m 13s\tremaining: 35.6s\n",
      "337:\ttotal: 1m 13s\tremaining: 35.4s\n",
      "338:\ttotal: 1m 14s\tremaining: 35.2s\n",
      "339:\ttotal: 1m 14s\tremaining: 34.9s\n",
      "340:\ttotal: 1m 14s\tremaining: 34.7s\n",
      "341:\ttotal: 1m 14s\tremaining: 34.5s\n",
      "342:\ttotal: 1m 14s\tremaining: 34.3s\n",
      "343:\ttotal: 1m 15s\tremaining: 34s\n",
      "344:\ttotal: 1m 15s\tremaining: 33.8s\n",
      "345:\ttotal: 1m 15s\tremaining: 33.6s\n",
      "346:\ttotal: 1m 15s\tremaining: 33.4s\n",
      "347:\ttotal: 1m 15s\tremaining: 33.2s\n",
      "348:\ttotal: 1m 16s\tremaining: 33s\n",
      "349:\ttotal: 1m 16s\tremaining: 32.7s\n",
      "350:\ttotal: 1m 16s\tremaining: 32.5s\n",
      "351:\ttotal: 1m 16s\tremaining: 32.3s\n",
      "352:\ttotal: 1m 17s\tremaining: 32.1s\n",
      "353:\ttotal: 1m 17s\tremaining: 31.9s\n",
      "354:\ttotal: 1m 17s\tremaining: 31.7s\n",
      "355:\ttotal: 1m 17s\tremaining: 31.4s\n",
      "356:\ttotal: 1m 17s\tremaining: 31.2s\n",
      "357:\ttotal: 1m 18s\tremaining: 31s\n",
      "358:\ttotal: 1m 18s\tremaining: 30.8s\n",
      "359:\ttotal: 1m 18s\tremaining: 30.6s\n",
      "360:\ttotal: 1m 18s\tremaining: 30.3s\n",
      "361:\ttotal: 1m 18s\tremaining: 30.1s\n",
      "362:\ttotal: 1m 19s\tremaining: 29.9s\n",
      "363:\ttotal: 1m 19s\tremaining: 29.7s\n",
      "364:\ttotal: 1m 19s\tremaining: 29.5s\n",
      "365:\ttotal: 1m 19s\tremaining: 29.2s\n",
      "366:\ttotal: 1m 20s\tremaining: 29s\n",
      "367:\ttotal: 1m 20s\tremaining: 28.8s\n",
      "368:\ttotal: 1m 20s\tremaining: 28.6s\n",
      "369:\ttotal: 1m 20s\tremaining: 28.4s\n",
      "370:\ttotal: 1m 20s\tremaining: 28.2s\n",
      "371:\ttotal: 1m 21s\tremaining: 27.9s\n",
      "372:\ttotal: 1m 21s\tremaining: 27.7s\n",
      "373:\ttotal: 1m 21s\tremaining: 27.5s\n",
      "374:\ttotal: 1m 21s\tremaining: 27.3s\n",
      "375:\ttotal: 1m 22s\tremaining: 27.1s\n",
      "376:\ttotal: 1m 22s\tremaining: 26.8s\n",
      "377:\ttotal: 1m 22s\tremaining: 26.6s\n",
      "378:\ttotal: 1m 22s\tremaining: 26.4s\n",
      "379:\ttotal: 1m 22s\tremaining: 26.2s\n",
      "380:\ttotal: 1m 23s\tremaining: 26s\n",
      "381:\ttotal: 1m 23s\tremaining: 25.7s\n",
      "382:\ttotal: 1m 23s\tremaining: 25.5s\n",
      "383:\ttotal: 1m 23s\tremaining: 25.3s\n",
      "384:\ttotal: 1m 23s\tremaining: 25.1s\n",
      "385:\ttotal: 1m 24s\tremaining: 24.9s\n",
      "386:\ttotal: 1m 24s\tremaining: 24.6s\n",
      "387:\ttotal: 1m 24s\tremaining: 24.4s\n",
      "388:\ttotal: 1m 24s\tremaining: 24.2s\n",
      "389:\ttotal: 1m 25s\tremaining: 24s\n",
      "390:\ttotal: 1m 25s\tremaining: 23.8s\n",
      "391:\ttotal: 1m 25s\tremaining: 23.6s\n",
      "392:\ttotal: 1m 25s\tremaining: 23.3s\n",
      "393:\ttotal: 1m 25s\tremaining: 23.1s\n",
      "394:\ttotal: 1m 26s\tremaining: 22.9s\n",
      "395:\ttotal: 1m 26s\tremaining: 22.7s\n",
      "396:\ttotal: 1m 26s\tremaining: 22.5s\n",
      "397:\ttotal: 1m 26s\tremaining: 22.2s\n",
      "398:\ttotal: 1m 27s\tremaining: 22s\n",
      "399:\ttotal: 1m 27s\tremaining: 21.8s\n",
      "400:\ttotal: 1m 27s\tremaining: 21.6s\n",
      "401:\ttotal: 1m 27s\tremaining: 21.4s\n",
      "402:\ttotal: 1m 27s\tremaining: 21.2s\n",
      "403:\ttotal: 1m 28s\tremaining: 20.9s\n",
      "404:\ttotal: 1m 28s\tremaining: 20.7s\n",
      "405:\ttotal: 1m 28s\tremaining: 20.5s\n",
      "406:\ttotal: 1m 28s\tremaining: 20.3s\n",
      "407:\ttotal: 1m 28s\tremaining: 20.1s\n",
      "408:\ttotal: 1m 29s\tremaining: 19.9s\n",
      "409:\ttotal: 1m 29s\tremaining: 19.6s\n",
      "410:\ttotal: 1m 29s\tremaining: 19.4s\n",
      "411:\ttotal: 1m 29s\tremaining: 19.2s\n",
      "412:\ttotal: 1m 30s\tremaining: 19s\n",
      "413:\ttotal: 1m 30s\tremaining: 18.8s\n",
      "414:\ttotal: 1m 30s\tremaining: 18.5s\n",
      "415:\ttotal: 1m 30s\tremaining: 18.3s\n",
      "416:\ttotal: 1m 30s\tremaining: 18.1s\n",
      "417:\ttotal: 1m 31s\tremaining: 17.9s\n",
      "418:\ttotal: 1m 31s\tremaining: 17.7s\n",
      "419:\ttotal: 1m 31s\tremaining: 17.4s\n",
      "420:\ttotal: 1m 31s\tremaining: 17.2s\n",
      "421:\ttotal: 1m 32s\tremaining: 17s\n",
      "422:\ttotal: 1m 32s\tremaining: 16.8s\n",
      "423:\ttotal: 1m 32s\tremaining: 16.6s\n",
      "424:\ttotal: 1m 32s\tremaining: 16.4s\n",
      "425:\ttotal: 1m 32s\tremaining: 16.1s\n",
      "426:\ttotal: 1m 33s\tremaining: 15.9s\n",
      "427:\ttotal: 1m 33s\tremaining: 15.7s\n",
      "428:\ttotal: 1m 33s\tremaining: 15.5s\n",
      "429:\ttotal: 1m 33s\tremaining: 15.3s\n",
      "430:\ttotal: 1m 33s\tremaining: 15s\n",
      "431:\ttotal: 1m 34s\tremaining: 14.8s\n",
      "432:\ttotal: 1m 34s\tremaining: 14.6s\n",
      "433:\ttotal: 1m 34s\tremaining: 14.4s\n",
      "434:\ttotal: 1m 34s\tremaining: 14.2s\n",
      "435:\ttotal: 1m 35s\tremaining: 13.9s\n",
      "436:\ttotal: 1m 35s\tremaining: 13.7s\n",
      "437:\ttotal: 1m 35s\tremaining: 13.5s\n",
      "438:\ttotal: 1m 35s\tremaining: 13.3s\n",
      "439:\ttotal: 1m 35s\tremaining: 13.1s\n",
      "440:\ttotal: 1m 36s\tremaining: 12.9s\n",
      "441:\ttotal: 1m 36s\tremaining: 12.6s\n",
      "442:\ttotal: 1m 36s\tremaining: 12.4s\n",
      "443:\ttotal: 1m 36s\tremaining: 12.2s\n",
      "444:\ttotal: 1m 36s\tremaining: 12s\n",
      "445:\ttotal: 1m 37s\tremaining: 11.8s\n",
      "446:\ttotal: 1m 37s\tremaining: 11.5s\n",
      "447:\ttotal: 1m 37s\tremaining: 11.3s\n",
      "448:\ttotal: 1m 37s\tremaining: 11.1s\n",
      "449:\ttotal: 1m 38s\tremaining: 10.9s\n",
      "450:\ttotal: 1m 38s\tremaining: 10.7s\n",
      "451:\ttotal: 1m 38s\tremaining: 10.5s\n",
      "452:\ttotal: 1m 38s\tremaining: 10.3s\n",
      "453:\ttotal: 1m 39s\tremaining: 10s\n",
      "454:\ttotal: 1m 39s\tremaining: 9.82s\n",
      "455:\ttotal: 1m 39s\tremaining: 9.6s\n",
      "456:\ttotal: 1m 39s\tremaining: 9.38s\n",
      "457:\ttotal: 1m 39s\tremaining: 9.16s\n",
      "458:\ttotal: 1m 40s\tremaining: 8.95s\n",
      "459:\ttotal: 1m 40s\tremaining: 8.73s\n",
      "460:\ttotal: 1m 40s\tremaining: 8.51s\n",
      "461:\ttotal: 1m 40s\tremaining: 8.29s\n",
      "462:\ttotal: 1m 41s\tremaining: 8.07s\n",
      "463:\ttotal: 1m 41s\tremaining: 7.85s\n",
      "464:\ttotal: 1m 41s\tremaining: 7.63s\n",
      "465:\ttotal: 1m 41s\tremaining: 7.42s\n",
      "466:\ttotal: 1m 41s\tremaining: 7.2s\n",
      "467:\ttotal: 1m 42s\tremaining: 6.98s\n",
      "468:\ttotal: 1m 42s\tremaining: 6.76s\n",
      "469:\ttotal: 1m 42s\tremaining: 6.54s\n",
      "470:\ttotal: 1m 42s\tremaining: 6.32s\n",
      "471:\ttotal: 1m 42s\tremaining: 6.11s\n",
      "472:\ttotal: 1m 43s\tremaining: 5.89s\n",
      "473:\ttotal: 1m 43s\tremaining: 5.67s\n",
      "474:\ttotal: 1m 43s\tremaining: 5.45s\n",
      "475:\ttotal: 1m 43s\tremaining: 5.23s\n",
      "476:\ttotal: 1m 44s\tremaining: 5.02s\n",
      "477:\ttotal: 1m 44s\tremaining: 4.8s\n",
      "478:\ttotal: 1m 44s\tremaining: 4.58s\n",
      "479:\ttotal: 1m 44s\tremaining: 4.36s\n",
      "480:\ttotal: 1m 44s\tremaining: 4.14s\n",
      "481:\ttotal: 1m 45s\tremaining: 3.92s\n",
      "482:\ttotal: 1m 45s\tremaining: 3.71s\n",
      "483:\ttotal: 1m 45s\tremaining: 3.49s\n",
      "484:\ttotal: 1m 45s\tremaining: 3.27s\n",
      "485:\ttotal: 1m 45s\tremaining: 3.05s\n",
      "486:\ttotal: 1m 46s\tremaining: 2.83s\n",
      "487:\ttotal: 1m 46s\tremaining: 2.62s\n",
      "488:\ttotal: 1m 46s\tremaining: 2.4s\n",
      "489:\ttotal: 1m 46s\tremaining: 2.18s\n",
      "490:\ttotal: 1m 47s\tremaining: 1.96s\n",
      "491:\ttotal: 1m 47s\tremaining: 1.74s\n",
      "492:\ttotal: 1m 47s\tremaining: 1.52s\n",
      "493:\ttotal: 1m 47s\tremaining: 1.31s\n",
      "494:\ttotal: 1m 47s\tremaining: 1.09s\n",
      "495:\ttotal: 1m 48s\tremaining: 872ms\n",
      "496:\ttotal: 1m 48s\tremaining: 654ms\n",
      "497:\ttotal: 1m 48s\tremaining: 436ms\n",
      "498:\ttotal: 1m 48s\tremaining: 218ms\n",
      "499:\ttotal: 1m 48s\tremaining: 0us\n",
      "0:\ttotal: 226ms\tremaining: 1m 52s\n",
      "1:\ttotal: 442ms\tremaining: 1m 50s\n",
      "2:\ttotal: 686ms\tremaining: 1m 53s\n",
      "3:\ttotal: 911ms\tremaining: 1m 53s\n",
      "4:\ttotal: 1.11s\tremaining: 1m 50s\n",
      "5:\ttotal: 1.35s\tremaining: 1m 50s\n",
      "6:\ttotal: 1.55s\tremaining: 1m 49s\n",
      "7:\ttotal: 1.77s\tremaining: 1m 48s\n",
      "8:\ttotal: 1.97s\tremaining: 1m 47s\n",
      "9:\ttotal: 2.18s\tremaining: 1m 46s\n",
      "10:\ttotal: 2.4s\tremaining: 1m 46s\n",
      "11:\ttotal: 2.61s\tremaining: 1m 46s\n",
      "12:\ttotal: 2.84s\tremaining: 1m 46s\n",
      "13:\ttotal: 3.04s\tremaining: 1m 45s\n",
      "14:\ttotal: 3.25s\tremaining: 1m 45s\n",
      "15:\ttotal: 3.47s\tremaining: 1m 45s\n",
      "16:\ttotal: 3.68s\tremaining: 1m 44s\n",
      "17:\ttotal: 3.9s\tremaining: 1m 44s\n",
      "18:\ttotal: 4.11s\tremaining: 1m 43s\n",
      "19:\ttotal: 4.32s\tremaining: 1m 43s\n",
      "20:\ttotal: 4.55s\tremaining: 1m 43s\n",
      "21:\ttotal: 4.76s\tremaining: 1m 43s\n",
      "22:\ttotal: 5s\tremaining: 1m 43s\n",
      "23:\ttotal: 5.21s\tremaining: 1m 43s\n",
      "24:\ttotal: 5.43s\tremaining: 1m 43s\n",
      "25:\ttotal: 5.67s\tremaining: 1m 43s\n",
      "26:\ttotal: 5.89s\tremaining: 1m 43s\n",
      "27:\ttotal: 6.14s\tremaining: 1m 43s\n",
      "28:\ttotal: 6.35s\tremaining: 1m 43s\n",
      "29:\ttotal: 6.59s\tremaining: 1m 43s\n",
      "30:\ttotal: 6.8s\tremaining: 1m 42s\n",
      "31:\ttotal: 7.02s\tremaining: 1m 42s\n",
      "32:\ttotal: 7.24s\tremaining: 1m 42s\n",
      "33:\ttotal: 7.45s\tremaining: 1m 42s\n",
      "34:\ttotal: 7.68s\tremaining: 1m 41s\n",
      "35:\ttotal: 7.89s\tremaining: 1m 41s\n",
      "36:\ttotal: 8.11s\tremaining: 1m 41s\n",
      "37:\ttotal: 8.33s\tremaining: 1m 41s\n",
      "38:\ttotal: 8.55s\tremaining: 1m 41s\n",
      "39:\ttotal: 8.79s\tremaining: 1m 41s\n",
      "40:\ttotal: 9s\tremaining: 1m 40s\n",
      "41:\ttotal: 9.23s\tremaining: 1m 40s\n",
      "42:\ttotal: 9.45s\tremaining: 1m 40s\n",
      "43:\ttotal: 9.67s\tremaining: 1m 40s\n",
      "44:\ttotal: 9.9s\tremaining: 1m 40s\n",
      "45:\ttotal: 10.1s\tremaining: 1m 39s\n",
      "46:\ttotal: 10.3s\tremaining: 1m 39s\n",
      "47:\ttotal: 10.6s\tremaining: 1m 39s\n",
      "48:\ttotal: 10.8s\tremaining: 1m 39s\n",
      "49:\ttotal: 11s\tremaining: 1m 39s\n",
      "50:\ttotal: 11.2s\tremaining: 1m 38s\n",
      "51:\ttotal: 11.5s\tremaining: 1m 38s\n",
      "52:\ttotal: 11.7s\tremaining: 1m 38s\n",
      "53:\ttotal: 11.9s\tremaining: 1m 38s\n",
      "54:\ttotal: 12.1s\tremaining: 1m 38s\n",
      "55:\ttotal: 12.3s\tremaining: 1m 37s\n",
      "56:\ttotal: 12.6s\tremaining: 1m 37s\n",
      "57:\ttotal: 12.8s\tremaining: 1m 37s\n",
      "58:\ttotal: 13s\tremaining: 1m 37s\n",
      "59:\ttotal: 13.2s\tremaining: 1m 36s\n",
      "60:\ttotal: 13.4s\tremaining: 1m 36s\n",
      "61:\ttotal: 13.6s\tremaining: 1m 36s\n",
      "62:\ttotal: 13.8s\tremaining: 1m 35s\n",
      "63:\ttotal: 14.1s\tremaining: 1m 35s\n",
      "64:\ttotal: 14.3s\tremaining: 1m 35s\n",
      "65:\ttotal: 14.5s\tremaining: 1m 35s\n",
      "66:\ttotal: 14.7s\tremaining: 1m 35s\n",
      "67:\ttotal: 14.9s\tremaining: 1m 34s\n",
      "68:\ttotal: 15.1s\tremaining: 1m 34s\n",
      "69:\ttotal: 15.3s\tremaining: 1m 34s\n",
      "70:\ttotal: 15.6s\tremaining: 1m 34s\n",
      "71:\ttotal: 15.8s\tremaining: 1m 33s\n",
      "72:\ttotal: 16s\tremaining: 1m 33s\n",
      "73:\ttotal: 16.2s\tremaining: 1m 33s\n",
      "74:\ttotal: 16.5s\tremaining: 1m 33s\n",
      "75:\ttotal: 16.7s\tremaining: 1m 33s\n",
      "76:\ttotal: 16.9s\tremaining: 1m 32s\n",
      "77:\ttotal: 17.1s\tremaining: 1m 32s\n",
      "78:\ttotal: 17.3s\tremaining: 1m 32s\n",
      "79:\ttotal: 17.6s\tremaining: 1m 32s\n",
      "80:\ttotal: 17.8s\tremaining: 1m 32s\n",
      "81:\ttotal: 18s\tremaining: 1m 31s\n",
      "82:\ttotal: 18.2s\tremaining: 1m 31s\n",
      "83:\ttotal: 18.4s\tremaining: 1m 31s\n",
      "84:\ttotal: 18.7s\tremaining: 1m 31s\n",
      "85:\ttotal: 18.9s\tremaining: 1m 30s\n",
      "86:\ttotal: 19.1s\tremaining: 1m 30s\n",
      "87:\ttotal: 19.3s\tremaining: 1m 30s\n",
      "88:\ttotal: 19.5s\tremaining: 1m 30s\n",
      "89:\ttotal: 19.7s\tremaining: 1m 29s\n",
      "90:\ttotal: 19.9s\tremaining: 1m 29s\n",
      "91:\ttotal: 20.2s\tremaining: 1m 29s\n",
      "92:\ttotal: 20.4s\tremaining: 1m 29s\n",
      "93:\ttotal: 20.6s\tremaining: 1m 28s\n",
      "94:\ttotal: 20.8s\tremaining: 1m 28s\n",
      "95:\ttotal: 21s\tremaining: 1m 28s\n",
      "96:\ttotal: 21.2s\tremaining: 1m 28s\n",
      "97:\ttotal: 21.5s\tremaining: 1m 28s\n",
      "98:\ttotal: 21.7s\tremaining: 1m 27s\n",
      "99:\ttotal: 21.9s\tremaining: 1m 27s\n",
      "100:\ttotal: 22.1s\tremaining: 1m 27s\n",
      "101:\ttotal: 22.3s\tremaining: 1m 27s\n",
      "102:\ttotal: 22.5s\tremaining: 1m 26s\n",
      "103:\ttotal: 22.7s\tremaining: 1m 26s\n",
      "104:\ttotal: 23s\tremaining: 1m 26s\n",
      "105:\ttotal: 23.2s\tremaining: 1m 26s\n",
      "106:\ttotal: 23.4s\tremaining: 1m 25s\n",
      "107:\ttotal: 23.6s\tremaining: 1m 25s\n",
      "108:\ttotal: 23.8s\tremaining: 1m 25s\n",
      "109:\ttotal: 24s\tremaining: 1m 25s\n",
      "110:\ttotal: 24.2s\tremaining: 1m 24s\n",
      "111:\ttotal: 24.5s\tremaining: 1m 24s\n",
      "112:\ttotal: 24.7s\tremaining: 1m 24s\n",
      "113:\ttotal: 24.9s\tremaining: 1m 24s\n",
      "114:\ttotal: 25.1s\tremaining: 1m 24s\n",
      "115:\ttotal: 25.3s\tremaining: 1m 23s\n",
      "116:\ttotal: 25.6s\tremaining: 1m 23s\n",
      "117:\ttotal: 25.8s\tremaining: 1m 23s\n",
      "118:\ttotal: 26s\tremaining: 1m 23s\n",
      "119:\ttotal: 26.2s\tremaining: 1m 23s\n",
      "120:\ttotal: 26.4s\tremaining: 1m 22s\n",
      "121:\ttotal: 26.7s\tremaining: 1m 22s\n",
      "122:\ttotal: 26.9s\tremaining: 1m 22s\n",
      "123:\ttotal: 27.1s\tremaining: 1m 22s\n",
      "124:\ttotal: 27.3s\tremaining: 1m 21s\n",
      "125:\ttotal: 27.5s\tremaining: 1m 21s\n",
      "126:\ttotal: 27.7s\tremaining: 1m 21s\n",
      "127:\ttotal: 27.9s\tremaining: 1m 21s\n",
      "128:\ttotal: 28.2s\tremaining: 1m 20s\n",
      "129:\ttotal: 28.4s\tremaining: 1m 20s\n",
      "130:\ttotal: 28.6s\tremaining: 1m 20s\n",
      "131:\ttotal: 28.8s\tremaining: 1m 20s\n",
      "132:\ttotal: 29s\tremaining: 1m 20s\n",
      "133:\ttotal: 29.2s\tremaining: 1m 19s\n",
      "134:\ttotal: 29.4s\tremaining: 1m 19s\n",
      "135:\ttotal: 29.6s\tremaining: 1m 19s\n",
      "136:\ttotal: 29.9s\tremaining: 1m 19s\n",
      "137:\ttotal: 30.1s\tremaining: 1m 18s\n",
      "138:\ttotal: 30.3s\tremaining: 1m 18s\n",
      "139:\ttotal: 30.5s\tremaining: 1m 18s\n",
      "140:\ttotal: 30.7s\tremaining: 1m 18s\n",
      "141:\ttotal: 31s\tremaining: 1m 18s\n",
      "142:\ttotal: 31.2s\tremaining: 1m 17s\n",
      "143:\ttotal: 31.4s\tremaining: 1m 17s\n",
      "144:\ttotal: 31.6s\tremaining: 1m 17s\n",
      "145:\ttotal: 31.8s\tremaining: 1m 17s\n",
      "146:\ttotal: 32s\tremaining: 1m 16s\n",
      "147:\ttotal: 32.2s\tremaining: 1m 16s\n",
      "148:\ttotal: 32.4s\tremaining: 1m 16s\n",
      "149:\ttotal: 32.7s\tremaining: 1m 16s\n",
      "150:\ttotal: 32.9s\tremaining: 1m 15s\n",
      "151:\ttotal: 33.1s\tremaining: 1m 15s\n",
      "152:\ttotal: 33.3s\tremaining: 1m 15s\n",
      "153:\ttotal: 33.5s\tremaining: 1m 15s\n",
      "154:\ttotal: 33.8s\tremaining: 1m 15s\n",
      "155:\ttotal: 34s\tremaining: 1m 14s\n",
      "156:\ttotal: 34.2s\tremaining: 1m 14s\n",
      "157:\ttotal: 34.4s\tremaining: 1m 14s\n",
      "158:\ttotal: 34.6s\tremaining: 1m 14s\n",
      "159:\ttotal: 34.9s\tremaining: 1m 14s\n",
      "160:\ttotal: 35.1s\tremaining: 1m 13s\n",
      "161:\ttotal: 35.3s\tremaining: 1m 13s\n",
      "162:\ttotal: 35.5s\tremaining: 1m 13s\n",
      "163:\ttotal: 35.7s\tremaining: 1m 13s\n",
      "164:\ttotal: 35.9s\tremaining: 1m 12s\n",
      "165:\ttotal: 36.2s\tremaining: 1m 12s\n",
      "166:\ttotal: 36.4s\tremaining: 1m 12s\n",
      "167:\ttotal: 36.6s\tremaining: 1m 12s\n",
      "168:\ttotal: 36.8s\tremaining: 1m 12s\n",
      "169:\ttotal: 37s\tremaining: 1m 11s\n",
      "170:\ttotal: 37.3s\tremaining: 1m 11s\n",
      "171:\ttotal: 37.5s\tremaining: 1m 11s\n",
      "172:\ttotal: 37.7s\tremaining: 1m 11s\n",
      "173:\ttotal: 37.9s\tremaining: 1m 11s\n",
      "174:\ttotal: 38.1s\tremaining: 1m 10s\n",
      "175:\ttotal: 38.3s\tremaining: 1m 10s\n",
      "176:\ttotal: 38.5s\tremaining: 1m 10s\n",
      "177:\ttotal: 38.7s\tremaining: 1m 10s\n",
      "178:\ttotal: 39s\tremaining: 1m 9s\n",
      "179:\ttotal: 39.3s\tremaining: 1m 9s\n",
      "180:\ttotal: 39.5s\tremaining: 1m 9s\n",
      "181:\ttotal: 39.8s\tremaining: 1m 9s\n",
      "182:\ttotal: 40s\tremaining: 1m 9s\n",
      "183:\ttotal: 40.3s\tremaining: 1m 9s\n",
      "184:\ttotal: 40.5s\tremaining: 1m 9s\n",
      "185:\ttotal: 40.8s\tremaining: 1m 8s\n",
      "186:\ttotal: 41.1s\tremaining: 1m 8s\n",
      "187:\ttotal: 41.4s\tremaining: 1m 8s\n",
      "188:\ttotal: 41.6s\tremaining: 1m 8s\n",
      "189:\ttotal: 41.8s\tremaining: 1m 8s\n",
      "190:\ttotal: 42.1s\tremaining: 1m 8s\n",
      "191:\ttotal: 42.3s\tremaining: 1m 7s\n",
      "192:\ttotal: 42.6s\tremaining: 1m 7s\n",
      "193:\ttotal: 42.9s\tremaining: 1m 7s\n",
      "194:\ttotal: 43.1s\tremaining: 1m 7s\n",
      "195:\ttotal: 43.4s\tremaining: 1m 7s\n",
      "196:\ttotal: 43.6s\tremaining: 1m 7s\n",
      "197:\ttotal: 43.9s\tremaining: 1m 6s\n",
      "198:\ttotal: 44.1s\tremaining: 1m 6s\n",
      "199:\ttotal: 44.3s\tremaining: 1m 6s\n",
      "200:\ttotal: 44.5s\tremaining: 1m 6s\n",
      "201:\ttotal: 44.8s\tremaining: 1m 6s\n",
      "202:\ttotal: 45s\tremaining: 1m 5s\n",
      "203:\ttotal: 45.2s\tremaining: 1m 5s\n",
      "204:\ttotal: 45.4s\tremaining: 1m 5s\n",
      "205:\ttotal: 45.6s\tremaining: 1m 5s\n",
      "206:\ttotal: 45.8s\tremaining: 1m 4s\n",
      "207:\ttotal: 46s\tremaining: 1m 4s\n",
      "208:\ttotal: 46.3s\tremaining: 1m 4s\n",
      "209:\ttotal: 46.5s\tremaining: 1m 4s\n",
      "210:\ttotal: 46.7s\tremaining: 1m 3s\n",
      "211:\ttotal: 46.9s\tremaining: 1m 3s\n",
      "212:\ttotal: 47.1s\tremaining: 1m 3s\n",
      "213:\ttotal: 47.3s\tremaining: 1m 3s\n",
      "214:\ttotal: 47.5s\tremaining: 1m 3s\n",
      "215:\ttotal: 47.7s\tremaining: 1m 2s\n",
      "216:\ttotal: 48s\tremaining: 1m 2s\n",
      "217:\ttotal: 48.2s\tremaining: 1m 2s\n",
      "218:\ttotal: 48.4s\tremaining: 1m 2s\n",
      "219:\ttotal: 48.6s\tremaining: 1m 1s\n",
      "220:\ttotal: 48.8s\tremaining: 1m 1s\n",
      "221:\ttotal: 49s\tremaining: 1m 1s\n",
      "222:\ttotal: 49.2s\tremaining: 1m 1s\n",
      "223:\ttotal: 49.4s\tremaining: 1m\n",
      "224:\ttotal: 49.7s\tremaining: 1m\n",
      "225:\ttotal: 49.9s\tremaining: 1m\n",
      "226:\ttotal: 50.1s\tremaining: 1m\n",
      "227:\ttotal: 50.3s\tremaining: 1m\n",
      "228:\ttotal: 50.5s\tremaining: 59.8s\n",
      "229:\ttotal: 50.7s\tremaining: 59.6s\n",
      "230:\ttotal: 50.9s\tremaining: 59.3s\n",
      "231:\ttotal: 51.2s\tremaining: 59.1s\n",
      "232:\ttotal: 51.4s\tremaining: 58.9s\n",
      "233:\ttotal: 51.6s\tremaining: 58.6s\n",
      "234:\ttotal: 51.8s\tremaining: 58.4s\n",
      "235:\ttotal: 52s\tremaining: 58.1s\n",
      "236:\ttotal: 52.2s\tremaining: 57.9s\n",
      "237:\ttotal: 52.4s\tremaining: 57.7s\n",
      "238:\ttotal: 52.6s\tremaining: 57.4s\n",
      "239:\ttotal: 52.8s\tremaining: 57.2s\n",
      "240:\ttotal: 53s\tremaining: 57s\n",
      "241:\ttotal: 53.2s\tremaining: 56.7s\n",
      "242:\ttotal: 53.4s\tremaining: 56.5s\n",
      "243:\ttotal: 53.6s\tremaining: 56.2s\n",
      "244:\ttotal: 53.8s\tremaining: 56s\n",
      "245:\ttotal: 54s\tremaining: 55.8s\n",
      "246:\ttotal: 54.2s\tremaining: 55.5s\n",
      "247:\ttotal: 54.4s\tremaining: 55.3s\n",
      "248:\ttotal: 54.6s\tremaining: 55.1s\n",
      "249:\ttotal: 54.8s\tremaining: 54.8s\n",
      "250:\ttotal: 55s\tremaining: 54.6s\n",
      "251:\ttotal: 55.2s\tremaining: 54.4s\n",
      "252:\ttotal: 55.5s\tremaining: 54.1s\n",
      "253:\ttotal: 55.7s\tremaining: 53.9s\n",
      "254:\ttotal: 55.9s\tremaining: 53.7s\n",
      "255:\ttotal: 56.1s\tremaining: 53.4s\n",
      "256:\ttotal: 56.3s\tremaining: 53.2s\n",
      "257:\ttotal: 56.5s\tremaining: 53s\n",
      "258:\ttotal: 56.7s\tremaining: 52.7s\n",
      "259:\ttotal: 56.9s\tremaining: 52.5s\n",
      "260:\ttotal: 57.1s\tremaining: 52.3s\n",
      "261:\ttotal: 57.3s\tremaining: 52s\n",
      "262:\ttotal: 57.5s\tremaining: 51.8s\n",
      "263:\ttotal: 57.7s\tremaining: 51.6s\n",
      "264:\ttotal: 57.9s\tremaining: 51.3s\n",
      "265:\ttotal: 58.1s\tremaining: 51.1s\n",
      "266:\ttotal: 58.3s\tremaining: 50.9s\n",
      "267:\ttotal: 58.5s\tremaining: 50.7s\n",
      "268:\ttotal: 58.7s\tremaining: 50.4s\n",
      "269:\ttotal: 58.9s\tremaining: 50.2s\n",
      "270:\ttotal: 59.1s\tremaining: 50s\n",
      "271:\ttotal: 59.3s\tremaining: 49.7s\n",
      "272:\ttotal: 59.5s\tremaining: 49.5s\n",
      "273:\ttotal: 59.8s\tremaining: 49.3s\n",
      "274:\ttotal: 60s\tremaining: 49.1s\n",
      "275:\ttotal: 1m\tremaining: 48.8s\n",
      "276:\ttotal: 1m\tremaining: 48.6s\n",
      "277:\ttotal: 1m\tremaining: 48.4s\n",
      "278:\ttotal: 1m\tremaining: 48.2s\n",
      "279:\ttotal: 1m 1s\tremaining: 48s\n",
      "280:\ttotal: 1m 1s\tremaining: 47.8s\n",
      "281:\ttotal: 1m 1s\tremaining: 47.6s\n",
      "282:\ttotal: 1m 1s\tremaining: 47.4s\n",
      "283:\ttotal: 1m 1s\tremaining: 47.1s\n",
      "284:\ttotal: 1m 2s\tremaining: 46.9s\n",
      "285:\ttotal: 1m 2s\tremaining: 46.7s\n",
      "286:\ttotal: 1m 2s\tremaining: 46.5s\n",
      "287:\ttotal: 1m 2s\tremaining: 46.2s\n",
      "288:\ttotal: 1m 3s\tremaining: 46s\n",
      "289:\ttotal: 1m 3s\tremaining: 45.8s\n",
      "290:\ttotal: 1m 3s\tremaining: 45.6s\n",
      "291:\ttotal: 1m 3s\tremaining: 45.4s\n",
      "292:\ttotal: 1m 4s\tremaining: 45.2s\n",
      "293:\ttotal: 1m 4s\tremaining: 45s\n",
      "294:\ttotal: 1m 4s\tremaining: 44.8s\n",
      "295:\ttotal: 1m 4s\tremaining: 44.6s\n",
      "296:\ttotal: 1m 5s\tremaining: 44.4s\n",
      "297:\ttotal: 1m 5s\tremaining: 44.2s\n",
      "298:\ttotal: 1m 5s\tremaining: 44s\n",
      "299:\ttotal: 1m 5s\tremaining: 43.8s\n",
      "300:\ttotal: 1m 5s\tremaining: 43.6s\n",
      "301:\ttotal: 1m 6s\tremaining: 43.4s\n",
      "302:\ttotal: 1m 6s\tremaining: 43.2s\n",
      "303:\ttotal: 1m 6s\tremaining: 42.9s\n",
      "304:\ttotal: 1m 6s\tremaining: 42.8s\n",
      "305:\ttotal: 1m 7s\tremaining: 42.6s\n",
      "306:\ttotal: 1m 7s\tremaining: 42.4s\n",
      "307:\ttotal: 1m 7s\tremaining: 42.4s\n",
      "308:\ttotal: 1m 8s\tremaining: 42.2s\n",
      "309:\ttotal: 1m 8s\tremaining: 42s\n",
      "310:\ttotal: 1m 8s\tremaining: 41.8s\n",
      "311:\ttotal: 1m 9s\tremaining: 41.7s\n",
      "312:\ttotal: 1m 9s\tremaining: 41.6s\n",
      "313:\ttotal: 1m 9s\tremaining: 41.4s\n",
      "314:\ttotal: 1m 10s\tremaining: 41.3s\n",
      "315:\ttotal: 1m 10s\tremaining: 41.1s\n",
      "316:\ttotal: 1m 10s\tremaining: 41s\n",
      "317:\ttotal: 1m 11s\tremaining: 40.8s\n",
      "318:\ttotal: 1m 11s\tremaining: 40.6s\n",
      "319:\ttotal: 1m 11s\tremaining: 40.4s\n",
      "320:\ttotal: 1m 12s\tremaining: 40.2s\n",
      "321:\ttotal: 1m 12s\tremaining: 40s\n",
      "322:\ttotal: 1m 12s\tremaining: 39.8s\n",
      "323:\ttotal: 1m 12s\tremaining: 39.6s\n",
      "324:\ttotal: 1m 13s\tremaining: 39.3s\n",
      "325:\ttotal: 1m 13s\tremaining: 39.1s\n",
      "326:\ttotal: 1m 13s\tremaining: 38.9s\n",
      "327:\ttotal: 1m 13s\tremaining: 38.7s\n",
      "328:\ttotal: 1m 14s\tremaining: 38.5s\n",
      "329:\ttotal: 1m 14s\tremaining: 38.3s\n",
      "330:\ttotal: 1m 14s\tremaining: 38.1s\n",
      "331:\ttotal: 1m 14s\tremaining: 37.9s\n",
      "332:\ttotal: 1m 15s\tremaining: 37.7s\n",
      "333:\ttotal: 1m 15s\tremaining: 37.5s\n",
      "334:\ttotal: 1m 15s\tremaining: 37.3s\n",
      "335:\ttotal: 1m 15s\tremaining: 37.1s\n",
      "336:\ttotal: 1m 16s\tremaining: 36.9s\n",
      "337:\ttotal: 1m 16s\tremaining: 36.7s\n",
      "338:\ttotal: 1m 16s\tremaining: 36.5s\n",
      "339:\ttotal: 1m 17s\tremaining: 36.3s\n",
      "340:\ttotal: 1m 17s\tremaining: 36.1s\n",
      "341:\ttotal: 1m 17s\tremaining: 35.9s\n",
      "342:\ttotal: 1m 17s\tremaining: 35.7s\n",
      "343:\ttotal: 1m 18s\tremaining: 35.5s\n",
      "344:\ttotal: 1m 18s\tremaining: 35.2s\n",
      "345:\ttotal: 1m 18s\tremaining: 35s\n",
      "346:\ttotal: 1m 19s\tremaining: 34.9s\n",
      "347:\ttotal: 1m 19s\tremaining: 34.7s\n",
      "348:\ttotal: 1m 19s\tremaining: 34.5s\n",
      "349:\ttotal: 1m 20s\tremaining: 34.3s\n",
      "350:\ttotal: 1m 20s\tremaining: 34.1s\n",
      "351:\ttotal: 1m 20s\tremaining: 33.9s\n",
      "352:\ttotal: 1m 21s\tremaining: 33.8s\n",
      "353:\ttotal: 1m 21s\tremaining: 33.6s\n",
      "354:\ttotal: 1m 21s\tremaining: 33.4s\n",
      "355:\ttotal: 1m 22s\tremaining: 33.2s\n",
      "356:\ttotal: 1m 22s\tremaining: 33s\n",
      "357:\ttotal: 1m 22s\tremaining: 32.8s\n",
      "358:\ttotal: 1m 23s\tremaining: 32.6s\n",
      "359:\ttotal: 1m 23s\tremaining: 32.4s\n",
      "360:\ttotal: 1m 23s\tremaining: 32.2s\n",
      "361:\ttotal: 1m 24s\tremaining: 32.1s\n",
      "362:\ttotal: 1m 24s\tremaining: 31.9s\n",
      "363:\ttotal: 1m 24s\tremaining: 31.7s\n",
      "364:\ttotal: 1m 25s\tremaining: 31.5s\n",
      "365:\ttotal: 1m 25s\tremaining: 31.3s\n",
      "366:\ttotal: 1m 25s\tremaining: 31.1s\n",
      "367:\ttotal: 1m 26s\tremaining: 30.9s\n",
      "368:\ttotal: 1m 26s\tremaining: 30.7s\n",
      "369:\ttotal: 1m 26s\tremaining: 30.5s\n",
      "370:\ttotal: 1m 27s\tremaining: 30.3s\n",
      "371:\ttotal: 1m 27s\tremaining: 30.1s\n",
      "372:\ttotal: 1m 27s\tremaining: 29.9s\n",
      "373:\ttotal: 1m 28s\tremaining: 29.7s\n",
      "374:\ttotal: 1m 28s\tremaining: 29.5s\n",
      "375:\ttotal: 1m 28s\tremaining: 29.3s\n",
      "376:\ttotal: 1m 28s\tremaining: 29s\n",
      "377:\ttotal: 1m 29s\tremaining: 28.8s\n",
      "378:\ttotal: 1m 29s\tremaining: 28.6s\n",
      "379:\ttotal: 1m 29s\tremaining: 28.4s\n",
      "380:\ttotal: 1m 30s\tremaining: 28.2s\n",
      "381:\ttotal: 1m 30s\tremaining: 28s\n",
      "382:\ttotal: 1m 30s\tremaining: 27.8s\n",
      "383:\ttotal: 1m 31s\tremaining: 27.6s\n",
      "384:\ttotal: 1m 31s\tremaining: 27.4s\n",
      "385:\ttotal: 1m 32s\tremaining: 27.2s\n",
      "386:\ttotal: 1m 32s\tremaining: 27s\n",
      "387:\ttotal: 1m 32s\tremaining: 26.7s\n",
      "388:\ttotal: 1m 32s\tremaining: 26.5s\n",
      "389:\ttotal: 1m 33s\tremaining: 26.3s\n",
      "390:\ttotal: 1m 33s\tremaining: 26s\n",
      "391:\ttotal: 1m 33s\tremaining: 25.8s\n",
      "392:\ttotal: 1m 33s\tremaining: 25.6s\n",
      "393:\ttotal: 1m 34s\tremaining: 25.3s\n",
      "394:\ttotal: 1m 34s\tremaining: 25.1s\n",
      "395:\ttotal: 1m 34s\tremaining: 24.8s\n",
      "396:\ttotal: 1m 34s\tremaining: 24.6s\n",
      "397:\ttotal: 1m 35s\tremaining: 24.4s\n",
      "398:\ttotal: 1m 35s\tremaining: 24.1s\n",
      "399:\ttotal: 1m 35s\tremaining: 23.9s\n",
      "400:\ttotal: 1m 35s\tremaining: 23.7s\n",
      "401:\ttotal: 1m 36s\tremaining: 23.4s\n",
      "402:\ttotal: 1m 36s\tremaining: 23.2s\n",
      "403:\ttotal: 1m 36s\tremaining: 22.9s\n",
      "404:\ttotal: 1m 36s\tremaining: 22.7s\n",
      "405:\ttotal: 1m 37s\tremaining: 22.5s\n",
      "406:\ttotal: 1m 37s\tremaining: 22.2s\n",
      "407:\ttotal: 1m 37s\tremaining: 22s\n",
      "408:\ttotal: 1m 37s\tremaining: 21.8s\n",
      "409:\ttotal: 1m 38s\tremaining: 21.5s\n",
      "410:\ttotal: 1m 38s\tremaining: 21.3s\n",
      "411:\ttotal: 1m 38s\tremaining: 21.1s\n",
      "412:\ttotal: 1m 38s\tremaining: 20.8s\n",
      "413:\ttotal: 1m 39s\tremaining: 20.6s\n",
      "414:\ttotal: 1m 39s\tremaining: 20.4s\n",
      "415:\ttotal: 1m 39s\tremaining: 20.1s\n",
      "416:\ttotal: 1m 39s\tremaining: 19.9s\n",
      "417:\ttotal: 1m 40s\tremaining: 19.6s\n",
      "418:\ttotal: 1m 40s\tremaining: 19.4s\n",
      "419:\ttotal: 1m 40s\tremaining: 19.2s\n",
      "420:\ttotal: 1m 40s\tremaining: 18.9s\n",
      "421:\ttotal: 1m 41s\tremaining: 18.7s\n",
      "422:\ttotal: 1m 41s\tremaining: 18.5s\n",
      "423:\ttotal: 1m 41s\tremaining: 18.2s\n",
      "424:\ttotal: 1m 41s\tremaining: 18s\n",
      "425:\ttotal: 1m 42s\tremaining: 17.7s\n",
      "426:\ttotal: 1m 42s\tremaining: 17.5s\n",
      "427:\ttotal: 1m 42s\tremaining: 17.3s\n",
      "428:\ttotal: 1m 42s\tremaining: 17s\n",
      "429:\ttotal: 1m 43s\tremaining: 16.8s\n",
      "430:\ttotal: 1m 43s\tremaining: 16.6s\n",
      "431:\ttotal: 1m 43s\tremaining: 16.3s\n",
      "432:\ttotal: 1m 43s\tremaining: 16.1s\n",
      "433:\ttotal: 1m 44s\tremaining: 15.8s\n",
      "434:\ttotal: 1m 44s\tremaining: 15.6s\n",
      "435:\ttotal: 1m 44s\tremaining: 15.4s\n",
      "436:\ttotal: 1m 45s\tremaining: 15.1s\n",
      "437:\ttotal: 1m 45s\tremaining: 14.9s\n",
      "438:\ttotal: 1m 45s\tremaining: 14.7s\n",
      "439:\ttotal: 1m 45s\tremaining: 14.4s\n",
      "440:\ttotal: 1m 46s\tremaining: 14.2s\n",
      "441:\ttotal: 1m 46s\tremaining: 14s\n",
      "442:\ttotal: 1m 46s\tremaining: 13.7s\n",
      "443:\ttotal: 1m 46s\tremaining: 13.5s\n",
      "444:\ttotal: 1m 47s\tremaining: 13.2s\n",
      "445:\ttotal: 1m 47s\tremaining: 13s\n",
      "446:\ttotal: 1m 47s\tremaining: 12.8s\n",
      "447:\ttotal: 1m 48s\tremaining: 12.5s\n",
      "448:\ttotal: 1m 48s\tremaining: 12.3s\n",
      "449:\ttotal: 1m 48s\tremaining: 12.1s\n",
      "450:\ttotal: 1m 48s\tremaining: 11.8s\n",
      "451:\ttotal: 1m 49s\tremaining: 11.6s\n",
      "452:\ttotal: 1m 49s\tremaining: 11.3s\n",
      "453:\ttotal: 1m 49s\tremaining: 11.1s\n",
      "454:\ttotal: 1m 49s\tremaining: 10.9s\n",
      "455:\ttotal: 1m 50s\tremaining: 10.6s\n",
      "456:\ttotal: 1m 50s\tremaining: 10.4s\n",
      "457:\ttotal: 1m 50s\tremaining: 10.1s\n",
      "458:\ttotal: 1m 50s\tremaining: 9.9s\n",
      "459:\ttotal: 1m 51s\tremaining: 9.66s\n",
      "460:\ttotal: 1m 51s\tremaining: 9.42s\n",
      "461:\ttotal: 1m 51s\tremaining: 9.18s\n",
      "462:\ttotal: 1m 51s\tremaining: 8.94s\n",
      "463:\ttotal: 1m 52s\tremaining: 8.7s\n",
      "464:\ttotal: 1m 52s\tremaining: 8.46s\n",
      "465:\ttotal: 1m 52s\tremaining: 8.22s\n",
      "466:\ttotal: 1m 52s\tremaining: 7.98s\n",
      "467:\ttotal: 1m 53s\tremaining: 7.74s\n",
      "468:\ttotal: 1m 53s\tremaining: 7.5s\n",
      "469:\ttotal: 1m 53s\tremaining: 7.25s\n",
      "470:\ttotal: 1m 53s\tremaining: 7.01s\n",
      "471:\ttotal: 1m 54s\tremaining: 6.78s\n",
      "472:\ttotal: 1m 54s\tremaining: 6.54s\n",
      "473:\ttotal: 1m 54s\tremaining: 6.3s\n",
      "474:\ttotal: 1m 55s\tremaining: 6.06s\n",
      "475:\ttotal: 1m 55s\tremaining: 5.82s\n",
      "476:\ttotal: 1m 55s\tremaining: 5.58s\n",
      "477:\ttotal: 1m 56s\tremaining: 5.34s\n",
      "478:\ttotal: 1m 56s\tremaining: 5.1s\n",
      "479:\ttotal: 1m 56s\tremaining: 4.85s\n",
      "480:\ttotal: 1m 56s\tremaining: 4.61s\n",
      "481:\ttotal: 1m 57s\tremaining: 4.37s\n",
      "482:\ttotal: 1m 57s\tremaining: 4.13s\n",
      "483:\ttotal: 1m 57s\tremaining: 3.88s\n",
      "484:\ttotal: 1m 57s\tremaining: 3.64s\n",
      "485:\ttotal: 1m 58s\tremaining: 3.4s\n",
      "486:\ttotal: 1m 58s\tremaining: 3.16s\n",
      "487:\ttotal: 1m 58s\tremaining: 2.92s\n",
      "488:\ttotal: 1m 58s\tremaining: 2.67s\n",
      "489:\ttotal: 1m 59s\tremaining: 2.43s\n",
      "490:\ttotal: 1m 59s\tremaining: 2.19s\n",
      "491:\ttotal: 1m 59s\tremaining: 1.95s\n",
      "492:\ttotal: 1m 59s\tremaining: 1.7s\n",
      "493:\ttotal: 2m\tremaining: 1.46s\n",
      "494:\ttotal: 2m\tremaining: 1.22s\n",
      "495:\ttotal: 2m\tremaining: 974ms\n",
      "496:\ttotal: 2m 1s\tremaining: 730ms\n",
      "497:\ttotal: 2m 1s\tremaining: 487ms\n",
      "498:\ttotal: 2m 1s\tremaining: 244ms\n",
      "499:\ttotal: 2m 1s\tremaining: 0us\n",
      "0.7582420419975087\n",
      "0.7384916359722621\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in kf.split(X_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe72 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', CatBoostClassifier(iterations=500,\n",
    "                             learning_rate=0.02,\n",
    "                             depth=12,\n",
    "                             eval_metric='AUC',\n",
    "                             bagging_temperature = 0.2,\n",
    "                             od_type='Iter',\n",
    "                             od_wait=100))\n",
    "    ])\n",
    "    pipe72.fit(X_train, y_train)\n",
    "    y_predicted=pipe72.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))\n",
    "# print(np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "digital-offering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8357831188907928\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_new) \n",
    "    y_predicted=pipe72.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-employer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "consistent-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(sampling_strategy=0.5)\n",
    "rus = RandomUnderSampler(sampling_strategy=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "noble-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ros, y_ros = ros.fit_resample(X_new, y_new)\n",
    "X_comb, y_comb = rus.fit_resample(X_ros, y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fiscal-quality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 66461, 1: 33230})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "arabic-sector",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972507046952549\n",
      "0.9968328839842586\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in kf.split(X_comb):\n",
    "    X_train, X_test = X_comb.iloc[train_idx], X_comb.iloc[test_idx]\n",
    "    y_train, y_test = y_comb.iloc[train_idx], y_comb.iloc[test_idx]\n",
    "    \n",
    "    pipe8 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                        n_estimators=10))\n",
    "    ])\n",
    "    pipe8.fit(X_train, y_train)\n",
    "    y_predicted=pipe8.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))\n",
    "# print(np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "chicken-official",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9880622332261007\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_new) \n",
    "    y_predicted=pipe8.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-cabin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-orleans",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "selective-guard",
   "metadata": {},
   "source": [
    "### Lets try SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "quick-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "social-mixture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 66461, 1: 4974})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(y_new)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "valued-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = imblearn.pipeline.Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "demographic-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote, y_smote = pipeline.fit_resample(X_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "physical-ceiling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 13292, 1: 6646})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(y_smote)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "statewide-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7501360121943943\n",
      "0.6018239840331392\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in kf.split(X_smote):\n",
    "    X_train, X_test = X_smote.iloc[train_idx], X_smote.iloc[test_idx]\n",
    "    y_train, y_test = y_smote.iloc[train_idx], y_smote.iloc[test_idx]\n",
    "    \n",
    "    pipe6 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                        n_estimators=10))\n",
    "    ])\n",
    "    pipe6.fit(X_train, y_train.values.ravel())\n",
    "    y_predicted=pipe6.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "worst-manor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9083991070270396\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_new) \n",
    "    y_predicted=pipe6.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-bennett",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-arrest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-simulation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dutch-service",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7773541562952422\n",
      "0.6512334749874402\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in kf.split(X_smote):\n",
    "    X_train, X_test = X_smote.iloc[train_idx], X_smote.iloc[test_idx]\n",
    "    y_train, y_test = y_smote.iloc[train_idx], y_smote.iloc[test_idx]\n",
    "    \n",
    "    pipe6 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier',RandomForestClassifier())\n",
    "    ])\n",
    "    pipe6.fit(X_train, y_train.values.ravel())\n",
    "    y_predicted=pipe6.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "electrical-silence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9323260607770602\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_new) \n",
    "    y_predicted=pipe6.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-spouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-indonesian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "excessive-springfield",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:12:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:12:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:14:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:14:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:14:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7653641612490674\n",
      "0.745056984143311\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in kf.split(X_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe9 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', BaggingClassifier(base_estimator=XGBClassifier(),\n",
    "                                        n_estimators=10))\n",
    "    ])\n",
    "    pipe9.fit(X_train, y_train)\n",
    "    y_predicted=pipe9.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))\n",
    "# print(np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "responsible-national",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819894573393763\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_new) \n",
    "    y_predicted=pipe9.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-pipeline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-bowling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-protest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "infinite-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "desirable-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['credit_line_utilization'] = test['credit_line_utilization'].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "micro-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = IterativeImputer(random_state=0)\n",
    "X_imputed = imp_mean.fit_transform(test.iloc[:, 1:])\n",
    "X_imputed = pd.DataFrame(X_imputed)\n",
    "X_imputed.columns = columns\n",
    "test = X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "sublime-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = pipe71.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "extended-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Predicted':test_prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "productive-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.set_index(pd.Index(np.arange(1, 48109))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-annotation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "contrary-frequency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48103</th>\n",
       "      <td>48104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48104</th>\n",
       "      <td>48105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48105</th>\n",
       "      <td>48106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48106</th>\n",
       "      <td>48107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48107</th>\n",
       "      <td>48108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48108 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  Predicted\n",
       "0          1          0\n",
       "1          2          1\n",
       "2          3          0\n",
       "3          4          0\n",
       "4          5          0\n",
       "...      ...        ...\n",
       "48103  48104          0\n",
       "48104  48105          0\n",
       "48105  48106          0\n",
       "48106  48107          0\n",
       "48107  48108          0\n",
       "\n",
       "[48108 rows x 2 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "chronic-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-hardware",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-collection",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
