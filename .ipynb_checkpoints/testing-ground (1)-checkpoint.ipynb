{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve, \\\n",
    "roc_auc_score,roc_curve,recall_score,classification_report, f1_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "import imblearn\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'number_dependent_family_members', 'monthly_income',\n",
       "       'number_of_credit_lines', 'real_estate_loans',\n",
       "       'ratio_debt_payment_to_income', 'credit_line_utilization',\n",
       "       'number_of_previous_late_payments_up_to_59_days',\n",
       "       'number_of_previous_late_payments_up_to_89_days',\n",
       "       'number_of_previous_late_payments_90_days_or_more'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df['credit_line_utilization'] = df['credit_line_utilization'].str.replace(',', '.').astype(float)\n",
    "columns = df.iloc[:, 1:-1].columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 67148, 1: 5013})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df[columns], df.iloc[:, -1]\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler()\n",
    "X_rus, y_rus = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 5013, 1: 5013})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7545486715811405\n",
      "0.7361038878418461\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_rus, y_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe9 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', RobustScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ])\n",
    "    pipe9.fit(X_train, y_train)\n",
    "    y_predicted=pipe9.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8845991064554972\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=pipe9.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_rus, y_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe10 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', VotingClassifier(estimators=[\n",
    "            ('forest50', RandomForestClassifier(n_estimators=50)),\n",
    "            ('forest75', RandomForestClassifier(n_estimators=75)),\n",
    "            ('forest100', RandomForestClassifier(n_estimators=100)),\n",
    "            ('forest125', RandomForestClassifier(n_estimators=125)),\n",
    "            ('forest150', RandomForestClassifier(n_estimators=150)),\n",
    "        ], voting='hard'))\n",
    "    ])\n",
    "    pipe10.fit(X_train, y_train)\n",
    "    y_predicted=pipe10.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=pipe10.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA GridSearch PolynomialFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_rus, y_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    pipe12 = Pipeline(steps=[\n",
    "            ('preprocessing', ColumnTransformer(transformers=[\n",
    "                ('numeric', Pipeline(steps=[\n",
    "                    ('impute', SimpleImputer(strategy='mean')),\n",
    "                    ('scale', StandardScaler())\n",
    "                ]), columns),\n",
    "            ])),\n",
    "            ('classifier', BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=20))\n",
    "        ])\n",
    "    params = {\n",
    "        'classifier__n_estimators': [80, 100, 120],\n",
    "    }\n",
    "\n",
    "    RF_gs = GridSearchCV(pipe12, param_grid=params, scoring='roc_auc', cv=3)\n",
    "    RF_gs.fit(X_train, y_train)\n",
    "    y_predicted=RF_gs.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "#     recall.append(recall_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=RF_gs.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_rus, y_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe14 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='median')),\n",
    "                ('scale', StandardScaler()),\n",
    "                ('poly', PolynomialFeatures())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', VotingClassifier(estimators=[\n",
    "            ('forest50', RandomForestClassifier(n_estimators=50)),\n",
    "            ('forest75', RandomForestClassifier(n_estimators=75)),\n",
    "            ('forest100', RandomForestClassifier(n_estimators=100)),\n",
    "            ('forest125', RandomForestClassifier(n_estimators=125)),\n",
    "            ('forest150', RandomForestClassifier(n_estimators=150)),\n",
    "        ], voting='hard'))\n",
    "    ])\n",
    "    pipe14.fit(X_train, y_train)\n",
    "    y_predicted=pipe14.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=pipe14.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_rus, y_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe15 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='median')),\n",
    "                ('scale', StandardScaler()),\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('pca', PCA()),\n",
    "        ('classifier', VotingClassifier(estimators=[\n",
    "            ('forest75', RandomForestClassifier(n_estimators=75)),\n",
    "            ('forest100', RandomForestClassifier(n_estimators=100)),\n",
    "            ('forest125', RandomForestClassifier(n_estimators=125)),\n",
    "            ('forest150', RandomForestClassifier(n_estimators=150)),\n",
    "        ], voting='hard'))\n",
    "    ])\n",
    "    pipe15.fit(X_train, y_train)\n",
    "    y_predicted=pipe15.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=pipe15.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_impute = SimpleImputer(strategy='mean')\n",
    "X_imputed = simple_impute.fit_transform(X_rus)\n",
    "X_imputed = pd.DataFrame(X_imputed)\n",
    "X_imputed.columns = columns\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_reducer = umap.UMAP(n_components=2)\n",
    "train_embedding = umap_reducer.fit_transform(X_imputed[columns])\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(train_embedding[:, 0], train_embedding[:, 1], s=4, c=y_rus)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "simple_impute = SimpleImputer(strategy='mean')\n",
    "X_imputed = simple_impute.fit_transform(X_rus)\n",
    "X_imputed = pd.DataFrame(X_imputed)\n",
    "X_imputed.columns = columns\n",
    "iso = IsolationForest()\n",
    "yhat = iso.fit_predict(X_imputed)\n",
    "mask = yhat != -1\n",
    "X_iso, y_iso = X_imputed[mask], y_rus[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_impute = SimpleImputer(strategy='mean')\n",
    "X_imputed = simple_impute.fit_transform(X_rus)\n",
    "X_imputed = pd.DataFrame(X_imputed)\n",
    "X_imputed.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsolationForest()\n",
    "ocs = OneClassSVM()\n",
    "y_iso = iso.fit_predict(X_imputed)\n",
    "y_ocs = ocs.fit_predict(X_imputed)\n",
    "\n",
    "m_iso = y_iso != -1\n",
    "m_ocs = y_ocs != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iso, y_iso = X_imputed[m_iso], y_rus[m_iso]\n",
    "X_ocs, y_ocs = X_imputed[m_ocs], y_rus[m_ocs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_iso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_iso, y_iso):\n",
    "    X_train, X_test = X_iso.iloc[train_idx], X_iso.iloc[test_idx]\n",
    "    y_train, y_test = y_iso.iloc[train_idx], y_iso.iloc[test_idx]\n",
    "    \n",
    "    pipe20 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ])\n",
    "    pipe20.fit(X_train, y_train)\n",
    "    y_predicted=pipe20.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_iso, y_iso):\n",
    "    X_train, X_test = X_iso.iloc[train_idx], X_iso.iloc[test_idx]\n",
    "    y_train, y_test = y_iso.iloc[train_idx], y_iso.iloc[test_idx]\n",
    "    \n",
    "    pipe22 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=30))\n",
    "    ])\n",
    "    pipe22.fit(X_train, y_train)\n",
    "    y_predicted=pipe22.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=pipe22.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = pd.concat([X_rus, y_rus], axis=1).corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    pipe30 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', XGBClassifier())\n",
    "    ])\n",
    "    pipe30.fit(X_train, y_train)\n",
    "    y_predicted=pipe30.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ClassifierChain || pipe model series 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5 import show_weights\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_rus, y_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe40 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', (LGBMClassifier()))\n",
    "    ])\n",
    "    pipe40.fit(X_train, y_train)\n",
    "    y_predicted=pipe40.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_rus, y_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe41 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', (XGBClassifier()))\n",
    "    ])\n",
    "    pipe41.fit(X_train, y_train)\n",
    "    y_predicted=pipe41.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_rus, y_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe40 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=20))\n",
    "    ])\n",
    "    pipe40.fit(X_train, y_train)\n",
    "    y_predicted=pipe40.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_rus, y_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe42 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', (CatBoostClassifier()))\n",
    "    ])\n",
    "    pipe42.fit(X_train, y_train)\n",
    "    y_predicted=pipe42.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_rus, y_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe43 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', RobustScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', GradientBoostingClassifier(n_estimators=200, learning_rate=0.5,max_depth=1, random_state=0))\n",
    "    ])\n",
    "    pipe43.fit(X_train, y_train)\n",
    "    y_predicted=pipe43.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=8, random_state=1, shuffle=True)\n",
    "# create model\n",
    "# model = DecisionTreeClassifier()\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipe9, X_rus, y_rus, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy:',np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=pipe43.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction || pipe version 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(SimpleImputer(strategy='mean').fit_transform(X_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=8, random_state=1, shuffle=True)\n",
    "# create model\n",
    "model = DecisionTreeClassifier()\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipe9, X_rus, y_rus, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy:',np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_pca, y_rus):\n",
    "    X_train, X_test = X_pca[train_idx], X_pca[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe40 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', (LGBMClassifier()))\n",
    "    ])\n",
    "    pipe40.fit(X_train, y_train)\n",
    "    y_predicted=pipe40.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/iba-ml1-mid-project/test.csv')\n",
    "test['credit_line_utilization'] = test['credit_line_utilization'].str.replace(',', '.').astype(float)\n",
    "test_prediction = pipe9z.predict(test.iloc[:, 1:])\n",
    "submission = pd.DataFrame({'Predicted':test_prediction})\n",
    "submission = submission.set_index(pd.Index(np.arange(1, 48109))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission9z.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(pipe40, scoring = 'roc_auc'\n",
    ",random_state=101).fit(X_test, y_test)\n",
    "show_weights(perm, feature_names = list(X_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier removed || Pipe 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "simple_impute = SimpleImputer(strategy='mean')\n",
    "X_imputed = simple_impute.fit_transform(X)\n",
    "X_imputed = pd.DataFrame(X_imputed)\n",
    "X_imputed.columns = columns\n",
    "iso = IsolationForest()\n",
    "yhat = iso.fit_predict(X_imputed)\n",
    "mask = yhat != -1\n",
    "X_iso, y_iso = X_imputed[mask], y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72161, 10)\n",
      "(68522, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_imputed.shape)\n",
    "print(X_iso.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 64803, 1: 3719})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 12960, 1: 6480})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = imblearn.pipeline.Pipeline(steps=steps)\n",
    "X_smt, y_smt = pipeline.fit_resample(X_iso, y_iso)\n",
    "Counter(y_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7872685185185186\n",
      "0.655246913580247\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_smt, y_smt):\n",
    "    X_train, X_test = X_smt.iloc[train_idx], X_smt.iloc[test_idx]\n",
    "    y_train, y_test = y_smt.iloc[train_idx], y_smt.iloc[test_idx]\n",
    "    \n",
    "    pipe60 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ])\n",
    "    pipe60.fit(X_train, y_train)\n",
    "    y_predicted=pipe60.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.870678989434556\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=pipe60.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7890817901234568\n",
      "0.6558641975308641\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_smt, y_smt):\n",
    "    X_train, X_test = X_smt.iloc[train_idx], X_smt.iloc[test_idx]\n",
    "    y_train, y_test = y_smt.iloc[train_idx], y_smt.iloc[test_idx]\n",
    "    \n",
    "    pipe61 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', VotingClassifier(estimators=[\n",
    "            ('forest50', RandomForestClassifier(n_estimators=50)),\n",
    "            ('forest75', RandomForestClassifier(n_estimators=75)),\n",
    "            ('forest100', RandomForestClassifier(n_estimators=100)),\n",
    "            ('forest125', RandomForestClassifier(n_estimators=125)),\n",
    "            ('forest150', RandomForestClassifier(n_estimators=150)),\n",
    "        ], voting='hard'))\n",
    "    ])\n",
    "    pipe61.fit(X_train, y_train)\n",
    "    y_predicted=pipe61.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8720802072247047\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=pipe61.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-14ee104e1501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     ])\n\u001b[1;32m     22\u001b[0m     \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe62\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#     pipe62.fit(X_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my_predicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit()\n",
    "roc = []\n",
    "recall = []\n",
    "for train_idx, test_idx in sss.split(X_smt, y_smt):\n",
    "    X_train, X_test = X_smt.iloc[train_idx], X_smt.iloc[test_idx]\n",
    "    y_train, y_test = y_smt.iloc[train_idx], y_smt.iloc[test_idx]\n",
    "    \n",
    "    param_grid = {\n",
    "        'pca__n_components': [2, 4, 5, 9],\n",
    "        'classifier__n_estimators': [80, 100, 150, 200, 300],\n",
    "    }\n",
    "    pipe62 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('pca', PCA()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ])\n",
    "    search = GridSearchCV(pipe62, param_grid, n_jobs=-1)\n",
    "    search.fit(X_train, y_train)\n",
    "#     pipe62.fit(X_train, y_train)\n",
    "    y_predicted=search.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))\n",
    "print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=search.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7473096804361591\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus)\n",
    "\n",
    "param_grid = {\n",
    "#     'classifier__n_estimators': [100, 200],\n",
    "#     'tfidf__norm': ['l1','l2']\n",
    "}\n",
    "pipe63 = Pipeline(steps=[\n",
    "    ('preprocessing', ColumnTransformer(transformers=[\n",
    "        ('numeric', Pipeline(steps=[\n",
    "            ('impute', KNNImputer()),\n",
    "            ('scale', StandardScaler())\n",
    "        ]), columns),\n",
    "    ])),\n",
    "#     ('tfidf', TfidfTransformer(norm='l1')),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=200))\n",
    "])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "search1 = GridSearchCV(pipe63, param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
    "search1.fit(X_train, y_train)\n",
    "#     pipe62.fit(X_train, y_train)\n",
    "y_predicted=search1.predict(X_test)\n",
    "print(roc_auc_score(y_test, y_predicted))\n",
    "# recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "# print(np.mean(roc))\n",
    "# print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8617556211303784\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=search1.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7489661045211368\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus)\n",
    "\n",
    "param_grid = {\n",
    "#     'classifier__n_estimators': [100, 200],\n",
    "#     'tfidf__norm': ['l1','l2']\n",
    "    'pca__n_components': [1, 5]\n",
    "}\n",
    "pipe64= Pipeline(steps=[\n",
    "    ('preprocessing', ColumnTransformer(transformers=[\n",
    "        ('numeric', Pipeline(steps=[\n",
    "            ('impute', IterativeImputer()),\n",
    "            ('scale', RobustScaler())\n",
    "        ]), columns),\n",
    "    ])),\n",
    "    ('pca', PCA()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=200))\n",
    "])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "search2 = GridSearchCV(pipe64, param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
    "search2.fit(X_train, y_train)\n",
    "#     pipe62.fit(X_train, y_train)\n",
    "y_predicted=search2.predict(X_test)\n",
    "print(roc_auc_score(y_test, y_predicted))\n",
    "# recall.append(recall_score(y_test, y_predicted))\n",
    "    \n",
    "# print(np.mean(roc))\n",
    "# print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.857025058899645\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=search2.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "?PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7305330582722086\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "recall = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus)\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100,150],\n",
    "    'pca__n_components': [6, 9],\n",
    "#     'classifier__learning_rate': [0.01, 0.2, 1],\n",
    "#     \"classifier__min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "#     \"classifier__min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"preprocessing__numeric__impute__n_neighbors\": [10, 15]   \n",
    "}\n",
    "\n",
    "pipe65= Pipeline(steps=[\n",
    "    ('preprocessing', ColumnTransformer(transformers=[\n",
    "        ('numeric', Pipeline(steps=[\n",
    "            ('impute', KNNImputer()),\n",
    "            ('scale', StandardScaler())\n",
    "        ]), columns),\n",
    "    ])),\n",
    "    ('pca', PCA()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "search3 = GridSearchCV(pipe65, param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
    "search3.fit(X_train, y_train)\n",
    "#     pipe62.fit(X_train, y_train)\n",
    "y_predicted=search3.predict(X_test)\n",
    "print(roc_auc_score(y_test, y_predicted))\n",
    "# recall.append(recall_score(y_test, y_predicted))\n",
    "\n",
    "# print(np.mean(roc))\n",
    "# print(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8434533855175476\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=search3.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__n_estimators': 150,\n",
       " 'pca__n_components': 9,\n",
       " 'preprocessing__numeric__impute__n_neighbors': 15}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 64803, 1: 3719})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(sampling_strategy=0.5)\n",
    "rus = RandomUnderSampler(sampling_strategy=0.8)\n",
    "\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "X_comb, y_comb = rus.fit_resample(X_ros, y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 67148, 1: 33574})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7385787362428768\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedKFold()\n",
    "roc = []\n",
    "for train_idx, test_idx in sss.split(X_rus, y_rus):\n",
    "    X_train, X_test = X_rus.iloc[train_idx], X_rus.iloc[test_idx]\n",
    "    y_train, y_test = y_rus.iloc[train_idx], y_rus.iloc[test_idx]\n",
    "    \n",
    "    pipe65 = Pipeline(steps=[\n",
    "        ('preprocessing', ColumnTransformer(transformers=[\n",
    "            ('numeric', Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='mean')),\n",
    "                ('scale', StandardScaler())\n",
    "            ]), columns),\n",
    "        ])),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=200))\n",
    "    ])\n",
    "    pipe65.fit(X_train, y_train)\n",
    "    y_predicted=pipe65.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "    \n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9098356093932098\n"
     ]
    }
   ],
   "source": [
    "roc = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    y_predicted=pipe65.predict(X_test)\n",
    "    roc.append(roc_auc_score(y_test, y_predicted))\n",
    "print(np.mean(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/iba-ml1-mid-project/test.csv')\n",
    "test['credit_line_utilization'] = test['credit_line_utilization'].str.replace(',', '.').astype(float)\n",
    "test_prediction = pipe65.predict(test.iloc[:, 1:])\n",
    "submission = pd.DataFrame({'Predicted':test_prediction})\n",
    "submission = submission.set_index(pd.Index(np.arange(1, 48109))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission65z.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
